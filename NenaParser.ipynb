{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "# Gozáli and Nozali\n",
    "\n",
    "text_id: A8\n",
    "informant: Nanəs Bənyamən\n",
    "place: ʾƐn-Nune\n",
    "\n",
    "(0) bla bla /\n",
    "bla bla bla //\n",
    "bla.\n",
    "\n",
    "(1) ë *ʾána* šmíyənwa xa-tunìθa| y-amríwala Gozáli ʾu-Nozàli,| šə́mma díya yáʿni\n",
    "tuníθət Gozáli ʾu-Nozàli.| dáx ʾiwáwa ʾàyya?| ʾi-mšárəxwa tuníθa y-amrìwa|\n",
    "(2) ʾíθwa-w lìθwa| bíš m-álaha gòṛa| líθwa gòṛa| hič-nàša.| bas-ʾíθwa xá malkà|\n",
    "ʾíθwale xa-bròna.| ʾáw malkà| rába bắyewale ʾaw-bróne dìye.| ʾu-ṭábʿan màlka|\n",
    "bróne díye páyəš šàwpe díye.| ʾíman-t málka ʾi-màyəθ,| ʾíman-t páyəš gòṛa| bróna\n",
    "díye šáqəl šáwpe dìye| bar-d-àw.|\n",
    "\n",
    "(3) ʾɛ́-ga xa-yóma málka dmíxa-wewa b-lɛ̀le,| dmìxa wéwa,| ʾu-xzéle b-xə́lme dìye|\n",
    "ʾíθ xa-náša gu-d-áy mðìta| biš-făqíra m-kúlla nàša.| rába făqìra-wewa\n",
    "ʾawwa-náša.| málka xzéle b-xə́lme dìye| mə́ra ʾáwwa náša făqìra| ṱ-awéle xá bronà|\n",
    "ʾáw páyəš málka šàwpət brònux.| lɛ́-y-awe brónux màlka.|\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "# Gozáli and Nozali\n",
    "\n",
    "text_id: A8\n",
    "informant: Nanəs Bənyamən\n",
    "place: ʾƐn-Nune\n",
    "\n",
    "(1) a-word... (a-comment) (GK: lalala) bla\n",
    "(2) also words.\n",
    "\n",
    "(4) new paragraph.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '# Gozáli and Nozali\\n'\n",
      " '\\n'\n",
      " 'text_id: A8\\n'\n",
      " 'informant: Nanəs Bənyamən\\n'\n",
      " 'place: ʾƐn-Nune\\n'\n",
      " '\\n'\n",
      " '(1) a-word... (a-comment) (GK: lalala) bla\\n'\n",
      " '(2) also words.\\n'\n",
      " '\\n'\n",
      " '(4) new paragraph.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('SPACE', '\\n'),\n",
       " ('TITLE', ('title', 'Gozáli and Nozali')),\n",
       " ('NEWLINES', '\\n\\n'),\n",
       " ('ATTRIBUTE', ('text_id', 'A8')),\n",
       " ('SPACE', '\\n'),\n",
       " ('ATTRIBUTE', ('informant', 'Nanəs Bənyamən')),\n",
       " ('SPACE', '\\n'),\n",
       " ('ATTRIBUTE', ('place', 'ʾƐn-Nune')),\n",
       " ('NEWLINES', '\\n\\n'),\n",
       " ('(', '('),\n",
       " ('DIGITS', '1'),\n",
       " (')', ')'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTERS', 'a'),\n",
       " ('HYPHEN', '-'),\n",
       " ('LETTERS', 'word'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('SPACE', ' '),\n",
       " ('COMMENT', '(a-comment)'),\n",
       " ('SPACE', ' '),\n",
       " ('LPAREN_COMMENT', '(GK: '),\n",
       " ('LETTERS', 'lalala'),\n",
       " (')', ')'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTERS', 'bla'),\n",
       " ('SPACE', '\\n'),\n",
       " ('(', '('),\n",
       " ('DIGITS', '2'),\n",
       " (')', ')'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTERS', 'also'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTERS', 'words'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('NEWLINES', '\\n\\n'),\n",
       " ('(', '('),\n",
       " ('DIGITS', '4'),\n",
       " (')', ')'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTERS', 'new'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTERS', 'paragraph'),\n",
       " ('PUNCTUATION', '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "from sly import Lexer\n",
    "\n",
    "class NenaLexer(Lexer):\n",
    "    \n",
    "    # set of token names\n",
    "    tokens = {\n",
    "        TITLE, ATTRIBUTE, LETTERS, NEWLINES, SPACE,\n",
    "        #LINE_ID, \n",
    "        PUNCTUATION, HYPHEN, #ASTERISK,\n",
    "        #LPAREN, LBRACKET, RPAREN, RBRACKET,\n",
    "        LPAREN_COMMENT, LBRACKET_COMMENT, DIGITS,\n",
    "        LANG_MARKER, #LINE_BREAK, VERSE_BREAK,\n",
    "        COMMENT,\n",
    "    }\n",
    "    \n",
    "    literals = {'*', '(', ')', '{', '}', '[', ']', '/'}\n",
    "\n",
    "    # Title starts with pound sign. Returns 2-tuple (key, value).\n",
    "    @_(r'(?m)^\\# .*$')\n",
    "    def TITLE(self, t):\n",
    "        t.value = ('title', t.value[2:])\n",
    "        return t\n",
    "\n",
    "    # Attribute starts key and colon. Returns 2-tuple (key, value).\n",
    "    @_(r'(?m)^[a-z][a-z0-9_]+: .*$')\n",
    "    def ATTRIBUTE(self, t):\n",
    "        t.value = tuple(t.value.split(': '))\n",
    "        return t\n",
    "    # How to get combined Unicode characters to be recognized?\n",
    "    # Matching only Unicode points of letters with pre-combined\n",
    "    # marks can be done with the 'word' class '\\w', but it\n",
    "    # includes digits and underscore. To remove those, negate\n",
    "    # the inverted word class along with digits and underscore:\n",
    "    # '[^\\W\\d_]. But that does not include separate combining\n",
    "    # marks, or the '+' sign.\n",
    "    # One solution would be unicodedata.normalize('NFC', data),\n",
    "    # except that not all combinations have pre-combined Unicode\n",
    "    # points.\n",
    "    # Another solution is to use an external regex engine such as\n",
    "    # `regex` (`pip install regex`), which has better Unicode\n",
    "    # support. However, I would like to avoid extra dependencies.\n",
    "    # Another (less elegant) solution is to make the '+' symbol\n",
    "    # and the combining characters [\\u0300-\\u036F] each its own\n",
    "    # token, which the parser will have to parse into morphemes\n",
    "    # and words.\n",
    "    # Another (also less elegant) solution is to use a 'negative\n",
    "    # lookbehind assertion' for the negation of digits and '_':\n",
    "    # https://stackoverflow.com/a/12349464/9230612\n",
    "    # That is what we will use here. r'(?!\\d_)[\\w\\u0300-\\u036F]+'\n",
    "    # Because combining marks can never appear before the first\n",
    "    # letter, and because some dialects have a '+' sign at the\n",
    "    # beginning of some words, we prefix an optional '+' symbol\n",
    "    # and an obligatory '[^\\W\\d_]' before the negative lookbehind.\n",
    "    LETTERS = r'[+]?[^\\W\\d_](?!\\d_)[\\w\\u0300-\\u036F+]*'\n",
    "    # Newlines: boundaries of paragraphs and metadata are marked\n",
    "    # with two newlines (meaning an empty line). The empty line\n",
    "    # may contain whitespace.\n",
    "    NEWLINES = r'\\n\\s*\\n'\n",
    "    # Space is any successive number of whitespace symbols.\n",
    "    SPACE = r'\\s+'\n",
    "    # One or more digits, not starting with zero\n",
    "    DIGITS = r'[1-9][0-9]*'\n",
    "    # Line id is any number of digits surrounded by round brackets\n",
    "#     LINE_ID = r'\\([0-9]+\\)'  # TODO convert to int?\n",
    "    # Punctuation is any normal punctuation symbol and vertical bar.\n",
    "    PUNCTUATION = r'[.,?!:;|–]'\n",
    "    # There are two different hyphens, a single one and a double one.\n",
    "    # The double one is the 'equals' sign.\n",
    "    HYPHEN = r'[-=]'\n",
    "    # Language markers are ASCII letter strings surrounded by\n",
    "    # angle brackets.\n",
    "    LANG_MARKER = r'<[A-Za-z]+>'\n",
    "    # A special comment starts with an opening bracket, capital initials\n",
    "    # and a colon.\n",
    "    LPAREN_COMMENT = r'\\([A-Za-z]+: '\n",
    "    LBRACKET_COMMENT = r'\\[[A-Za-z]+: '\n",
    "    # A regular comment is text (at least one character not being a digit)\n",
    "    # which may not contain a colon (otherwise it becomes a special comment/interruption)\n",
    "    COMMENT = r'\\([^:)]*[^:)\\d]+[^:)]*\\)'\n",
    "\n",
    "# print text for reference\n",
    "pprint.pprint(text)\n",
    "\n",
    "# demonstration of output results of lexer, to be used by parser below\n",
    "lexer = NenaLexer()\n",
    "[(tok.type, tok.value) for tok in lexer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '# Gozáli and Nozali\\n'\n",
      " '\\n'\n",
      " 'text_id: A8\\n'\n",
      " 'informant: Nanəs Bənyamən\\n'\n",
      " 'place: ʾƐn-Nune\\n'\n",
      " '\\n'\n",
      " '(1) a-word... (a-comment) (GK: lalala) bla\\n'\n",
      " '(2) also words.\\n'\n",
      " '\\n'\n",
      " '(4) new paragraph.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Token 'LANG_MARKER' defined, but not used\n",
      "WARNING: There is 1 unused token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('title', 'Gozáli and Nozali'),\n",
       "  ('text_id', 'A8'),\n",
       "  ('informant', 'Nanəs Bənyamən'),\n",
       "  ('place', 'ʾƐn-Nune')],\n",
       " [[(1,\n",
       "    [{'word': ['a', '-', 'word'], 'trailer': '... '},\n",
       "     {'comment': 'a-comment'},\n",
       "     {'word': ['lalala'], 'trailer': ' ', 'speaker': 'GK'},\n",
       "     {'word': ['bla'], 'trailer': ' '}]),\n",
       "   (2,\n",
       "    [{'word': ['also'], 'trailer': ' '},\n",
       "     {'word': ['words'], 'trailer': '.'}])],\n",
       "  [(4,\n",
       "    [{'word': ['new'], 'trailer': ' '},\n",
       "     {'word': ['paragraph'], 'trailer': '.'}])]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sly import Parser\n",
    "\n",
    "class NenaParser(Parser):\n",
    "#     debugfile = 'parser.out'\n",
    "\n",
    "    # Get the token list from the lexer (required)\n",
    "    tokens = NenaLexer.tokens\n",
    "    \n",
    "    @_('heading NEWLINES paragraphs')\n",
    "    def text(self, p):\n",
    "        return (p.heading, p.paragraphs)\n",
    "    \n",
    "    @_('SPACE TITLE NEWLINES attributes',\n",
    "       'TITLE NEWLINES attributes')\n",
    "    def heading(self, p):\n",
    "        return [p.TITLE] + p.attributes\n",
    "    \n",
    "    @_('ATTRIBUTE SPACE attributes')\n",
    "    def attributes(self, p):\n",
    "        return [p.ATTRIBUTE] + p.attributes\n",
    "            \n",
    "    @_('ATTRIBUTE')\n",
    "    def attributes(self, p):\n",
    "        return [p.ATTRIBUTE]\n",
    "    \n",
    "    @_('paragraphs NEWLINES paragraph')\n",
    "    def paragraphs(self, p):\n",
    "        return p.paragraphs + [p.paragraph]\n",
    "    \n",
    "    @_('paragraph')\n",
    "    def paragraphs(self, p):\n",
    "        return [p.paragraph]\n",
    "    \n",
    "    # paragraph\n",
    "    @_('paragraph line')\n",
    "    def paragraph(self, p):\n",
    "        return p.paragraph + [p.line]\n",
    "    \n",
    "    # lines\n",
    "    @_('line')\n",
    "    def paragraph(self, p):\n",
    "        return [p.line]\n",
    "    \n",
    "    # line\n",
    "    @_('line_id line_elements')\n",
    "    def line(self, p):\n",
    "        return (p.line_id, p.line_elements)\n",
    "    \n",
    "    # line_id\n",
    "    @_('\"(\" DIGITS \")\" SPACE')\n",
    "    def line_id(self, p):\n",
    "        return int(p.DIGITS)\n",
    "\n",
    "    # line_elements\n",
    "    @_('line_elements line_element')\n",
    "    def line_elements(self, p):\n",
    "        return p.line_elements + p.line_element\n",
    "\n",
    "    @_('line_element')\n",
    "    def line_elements(self, p):\n",
    "        return p.line_element\n",
    "\n",
    "    # line_element\n",
    "    @_('full_word')\n",
    "    def line_element(self, p):\n",
    "        return [p.full_word]\n",
    "\n",
    "    @_('comment')\n",
    "    def line_element(self, p):\n",
    "        return [p.comment]\n",
    "    \n",
    "    @_('interruption')\n",
    "    def line_element(self, p):\n",
    "        return p.interruption\n",
    "    \n",
    "    # comment\n",
    "    @_('COMMENT SPACE',\n",
    "       'COMMENT')\n",
    "    def comment(self, p):\n",
    "        return {'comment': p.COMMENT[1:-1]}\n",
    "        \n",
    "    # interruption\n",
    "    @_('LPAREN_COMMENT full_words \")\" SPACE',\n",
    "       'LBRACKET_COMMENT full_words \"]\" SPACE')\n",
    "    def interruption(self, p):\n",
    "        speaker = p[0][1:-2]\n",
    "        for fw in p.full_words:\n",
    "            fw.update({'speaker': speaker})\n",
    "        if not p.full_words[-1]['trailer'].endswith(' '):\n",
    "            p.full_words[-1]['trailer'] += ' '\n",
    "        return p.full_words\n",
    "    \n",
    "    # full_words\n",
    "    @_('full_words full_word')\n",
    "    def full_words(self, p):\n",
    "        return p.full_words + p.full_word\n",
    "        \n",
    "    @_('full_word')\n",
    "    def full_words(self, p):\n",
    "        return [p.full_word]\n",
    "\n",
    "    # full_word\n",
    "    @_('word trailer')\n",
    "    def full_word(self, p):\n",
    "        return {'word': p.word, 'trailer': p.trailer}\n",
    "\n",
    "    @_('word')\n",
    "    def full_word(self, p):\n",
    "        return {'word': p.word, 'trailer': ''}\n",
    "    \n",
    "    # word\n",
    "    @_('word HYPHEN morpheme')\n",
    "    def word(self, p):\n",
    "        return p.word + [p.HYPHEN, p.morpheme]\n",
    "    \n",
    "    @_('morpheme')    \n",
    "    def word(self, p):\n",
    "        return [p.morpheme]\n",
    "    \n",
    "    # morpheme\n",
    "    @_('LETTERS')\n",
    "    def morpheme(self, p):\n",
    "        return p.LETTERS\n",
    "    \n",
    "    # trailer\n",
    "    @_('trailer PUNCTUATION')\n",
    "    def trailer(self, p):\n",
    "        return p.trailer + p.PUNCTUATION\n",
    "\n",
    "    @_('trailer SPACE')\n",
    "    def trailer(self, p):\n",
    "        return p.trailer + ' '\n",
    "    \n",
    "    @_('PUNCTUATION')\n",
    "    def trailer(self, p):\n",
    "        return p.PUNCTUATION\n",
    "\n",
    "    @_('SPACE')\n",
    "    def trailer(self, p):\n",
    "        return ' '\n",
    "\n",
    "pprint.pprint(text)\n",
    "\n",
    "# demonstration of output results of parser, to be used by generate_TF loop\n",
    "parser = NenaParser()\n",
    "parser.parse(lexer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- implement 'foreign' marker `*`\n",
    "- implement language marker `<Marker>`\n",
    "- implement line and verse breaks `/` and `//`\n",
    "\n",
    "QUESTIONS\n",
    "\n",
    "Some questions require answers for implementation. They need not be definitive answers for now, but they should be motivated somehow (even if the motivation is 'random choice'), so it will be clear later why it is done in one way or another.\n",
    "\n",
    "- How to store hyphen? Now it is stored as a character in a word occuring between morphemes (I think).\n",
    "  \n",
    "  Should it be the trailer of the morpheme?\n",
    "\n",
    "\n",
    "- How to split sentences?\n",
    "\n",
    "  Now sentences are split on .?! and subsentences on ,\n",
    "  There are other symbols: ;:– and even .. ... ..., .... ..... (If I recall correctly). Should those split\n",
    "  sentences or subsentences?\n",
    "\n",
    "\n",
    "- What to do with poetic line breaks and sentence/paragraph boundaries?\n",
    "\n",
    "  I think a 'poem' should not be divided into paragraphs. I suggest that a line break '/' is a subsentence division, and a verse break '//' a sentence division (even when in the source it is followed by an empty line). If there is a verse number in between, that automatically starts a new sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
