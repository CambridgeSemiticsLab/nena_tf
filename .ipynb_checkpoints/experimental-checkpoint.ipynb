{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Corpus\n",
    "\n",
    "In this notebook, we experiment with producing a TF resource for the Christian Urmi NENA dialect. The text itself comes from Geoffrey Khan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, collections\n",
    "from IPython.display import display, HTML\n",
    "from tf.fabric import Fabric\n",
    "with open('christian_urmi.txt', 'r') as infile:\n",
    "    urmi = infile.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Text-Fabric Resource\n",
    "\n",
    "Text-Fabric is a format and tool for the storage, annotation, and analysis of text corpora. The Text-Fabric data model is explained in depth [in its docs](https://annotation.github.io/text-fabric/Model/Data-Model/).\n",
    "\n",
    "Herein we follow a fairly standard approach to convert a plain-text file into a TF resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Up Node Feature and Oslot Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateKey(dictionary):\n",
    "    '''\n",
    "    Auto increments a key from a dictionary.\n",
    "    '''\n",
    "    return max(dictionary.keys(), default=0)+1\n",
    "\n",
    "raw_node_features = collections.defaultdict(lambda:collections.defaultdict(set))\n",
    "raw_oslots = collections.defaultdict(lambda:collections.defaultdict(set))\n",
    "slot = 0\n",
    "\n",
    "this_sentence = 1 # for first iteration since only sentence ends are marked\n",
    "\n",
    "for line in urmi.split('\\n'):\n",
    "    \n",
    "    # mark book beginnings, their \"code\" and title\n",
    "    if line.startswith('# '): # book code\n",
    "        this_book = iterateKey(raw_oslots['book'])\n",
    "        raw_node_features['book_code'][this_book] = line.split()[-1].strip()\n",
    "        continue\n",
    "    elif line.startswith('## '): # book title\n",
    "        raw_node_features['book_title'][this_book] = line.split()[-1].strip()\n",
    "        continue\n",
    "                \n",
    "    # map slots to objects and features:\n",
    "    for token in line.split():\n",
    "        \n",
    "        if re.match('.*\\(\\d*\\)', token): # line start\n",
    "            this_line = iterateKey(raw_oslots['line'])\n",
    "            raw_node_features['line'][this_line] = token\n",
    "            continue\n",
    "            \n",
    "        # everything up to this point is a valid slot\n",
    "        # iterate slot up by 1\n",
    "        slot += 1\n",
    "            \n",
    "        # record sentence boundaries\n",
    "        if re.match('.*\\.\\|', token): # end of sentence\n",
    "            raw_oslots['sentence'][this_sentence].add(slot)\n",
    "            this_sentence = iterateKey(raw_oslots['sentence']) # get incremented, new sentence ID\n",
    "        else: # beginning/within sentence\n",
    "            raw_oslots['sentence'][this_sentence].add(slot)\n",
    "            \n",
    "        raw_node_features['trans'][slot] = token\n",
    "        raw_oslots['book'][this_book].add(slot)\n",
    "        raw_oslots['line'][this_line].add(slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindex Objects Above Slot Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "otype2feature = {'book':{'book_code', 'book_title'},\n",
    "                 'line':{'line'},\n",
    "                 'sentence':{}}\n",
    "\n",
    "node_features = collections.defaultdict(lambda:collections.defaultdict())\n",
    "node_features['trans'] = raw_node_features['trans'] # add slot features\n",
    "for slot in node_features['trans']:\n",
    "    node_features['otype'][slot] = 'word'\n",
    "    \n",
    "edge_features = collections.defaultdict(lambda:collections.defaultdict(set)) # oslots will go here\n",
    "\n",
    "onode = max(raw_node_features['trans']) # max slot, incremented +1 in loop\n",
    "\n",
    "for otype in raw_oslots.keys():\n",
    "    for oID, slots in raw_oslots[otype].items():\n",
    "        \n",
    "        # make new object node number\n",
    "        onode += 1\n",
    "        node_features['otype'][onode] = otype\n",
    "        \n",
    "        # remap node features to node number\n",
    "        for feat in otype2feature[otype]:\n",
    "            node_features[feat][onode] = raw_node_features[feat][oID]\n",
    "        edge_features['oslot'][onode] = raw_oslots[otype][oID]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to TF Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otext = '''\n",
    "\n",
    "@sectionTypes=book,line\n",
    "@sectionFeatures=book_code,line\n",
    "@fmt:text-orig-full={trans}\n",
    "\n",
    "'''\n",
    "\n",
    "meta = {'':{'author': 'Geoffrey Khan and Cody Kingham'},\n",
    "        ''\n",
    "       }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
