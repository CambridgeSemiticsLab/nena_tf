{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/logo.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/dans.png\" width=\"128\"/>\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with using\n",
    "[Text-Fabric](https://annotation.github.io/text-fabric/) for coding in NENA, a Neo Aramaic Corpus maintained at\n",
    "Cambridge University.\n",
    "\n",
    "Familiarity with the underlying\n",
    "[data model](https://annotation.github.io/text-fabric/tf/about/datamodel.html)\n",
    "is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Text-Fabric\n",
    "\n",
    "### Python\n",
    "\n",
    "You need to have Python on your system. Most systems have it out of the box,\n",
    "but alas, that is python2 and we need at least python **3.6**.\n",
    "\n",
    "Install it from [python.org](https://www.python.org) or from\n",
    "[Anaconda](https://www.anaconda.com/download).\n",
    "\n",
    "### TF itself\n",
    "\n",
    "```\n",
    "pip3 install text-fabric\n",
    "```\n",
    "\n",
    "### Jupyter notebook\n",
    "\n",
    "You need [Jupyter](http://jupyter.org).\n",
    "\n",
    "If it is not already installed:\n",
    "\n",
    "```\n",
    "pip3 install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip\n",
    "If you cloned the repository containing this tutorial,\n",
    "first copy its parent directory to somewhere outside your clone of the repo,\n",
    "before computing with this it.\n",
    "\n",
    "If you pull changes from the repository later, it will not conflict with\n",
    "your computations.\n",
    "\n",
    "Where you put your tutorial directory is up to you.\n",
    "It will work from any directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookbook\n",
    "\n",
    "This tutorial and its sister tutorials are meant to showcase most of things TF can do.\n",
    "\n",
    "But we also have a [cookbook](cookbook) with a set of focused recipes on tricky things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Text-Fabric will fetch the data set for you from github, and check for updates.\n",
    "\n",
    "The data will be stored in the `text-fabric-data` in your home directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "The data of the corpus is organized in features.\n",
    "They are *columns* of data.\n",
    "Think of the corpus as a gigantic spreadsheet, where row 1 corresponds to the\n",
    "first sign, row 2 to the second sign, and so on, for all ~ 1.5 M signs,\n",
    "followed by ~ 500 K word nodes and yet another 200 K nodes of other types.\n",
    "\n",
    "The information which reading each sign has, constitutes a column in that spreadsheet.\n",
    "The DSS corpus contains > 50 columns.\n",
    "\n",
    "Instead of putting that information in one big table, the data is organized in separate columns.\n",
    "We call those columns **features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:16.202764Z",
     "start_time": "2018-05-18T09:17:16.197546Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incantation\n",
    "\n",
    "The simplest way to get going is by this *incantation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:17.537171Z",
     "start_time": "2018-05-18T09:17:17.517809Z"
    }
   },
   "outputs": [],
   "source": [
    "from tf.app import use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the very last version, use `hot`.\n",
    "\n",
    "For the latest release, use `latest`.\n",
    "\n",
    "If you have cloned the repos (TF app and data), use `clone`.\n",
    "\n",
    "If you do not want/need to upgrade, leave out the checkout specifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b title=\"local github\">TF-app:</b> <span title=\"repo clone offline under ~/github\">~/github/annotation/app-nena/code</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local github\">data:</b> <span title=\"repo clone offline under ~/github\">~/github/CambridgeSemiticsLab/nena_tf/tf/0.02</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Text-Fabric:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/cheatsheet.html\" title=\"text-fabric-api\">Text-Fabric API 8.3.0</a>, <a target=\"_blank\" href=\"https://github.com/annotation/app-nena\" title=\"nena TF-app\">app-nena</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br><b>Data:</b> <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md.md\" title=\"provenance of Northeastern Neo-Aramaic Text Corpus\">NENA_TF</a>, <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/transcription.md\" title=\"NENA transcription script\">Character table</a>, <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#\" title=\"NENA_TF feature documentation\">Feature docs</a><br><b>Features:</b><br><details><summary><b>Northeastern Neo-Aramaic Text Corpus</b></summary><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#class\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/class.tf\">class</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#comment\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/comment.tf\">comment</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#dialect\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/dialect.tf\">dialect</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#end\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/end.tf\">end</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#foreign\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/foreign.tf\">foreign</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#full\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/full.tf\">full</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#full_end\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/full_end.tf\">full_end</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#fuzzy\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/fuzzy.tf\">fuzzy</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#fuzzy_end\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/fuzzy_end.tf\">fuzzy_end</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#gloss\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/gloss.tf\">gloss</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#grm_desc\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/grm_desc.tf\">grm_desc</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#informant\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/informant.tf\">informant</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lang\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/lang.tf\">lang</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lemma\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/lemma.tf\">lemma</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lemma_form\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/lemma_form.tf\">lemma_form</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lite\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/lite.tf\">lite</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lite_end\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/lite_end.tf\">lite_end</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#number\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/number.tf\">number</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#otype\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/otype.tf\">otype</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#place\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/place.tf\">place</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#speaker\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/speaker.tf\">speaker</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/text.tf\">text</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text_id\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/text_id.tf\">text_id</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text_lite\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/text_lite.tf\">text_lite</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text_norm\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/text_norm.tf\">text_norm</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#title\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/title.tf\">title</a><br><b><i><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#oslots\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/0.02/oslots.tf\">oslots</a></i></b><br></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/server/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/server/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/server/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/server/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/server/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/server/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/server/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 0.1rem;\n",
       "    margin: 0.1rem;\n",
       "    direction: ltr;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1rem 0rem;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".section {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--section);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  0.5rem 0.1rem 0.1rem 0.1rem;\n",
       "    margin: 0.8rem 0.1rem 0.1rem 0.1rem;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    display: inline-block;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 0.2rem;\n",
       "    margin-left: 0.1rem;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 0.2rem;\n",
       "    margin-right: 0.1rem;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -1.2rem;\n",
       "    margin-left: 1rem;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3rem;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 0.1rem;\n",
       "    margin-left: 0.1rem;\n",
       "    padding: 0.1rem 0.1rem;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 2rem;\n",
       "\tpadding: 1rem;\n",
       "\tborder: 0.1rem solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--section:            hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         0.15rem;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "  --border-width-nul:   0.1rem;\n",
       "  --border-width0:      0.1rem;\n",
       "  --border-width1:      0.15rem;\n",
       "  --border-width2:      0.2rem;\n",
       "  --border-width3:      0.3rem;\n",
       "  --border-width4:      0.25rem;\n",
       "  --border-width-plain: 0.1rem;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 0.2rem ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 0.2rem ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.3rem;\n",
       "  padding: 0.2rem;\n",
       "  margin: 0.2rem;\n",
       "}\n",
       "\n",
       "span.plain {\n",
       "  display: inline-block;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "}\n",
       ".speaker {\n",
       "    vertical-align: super;\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #884400;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Text-Fabric API:</b> names <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/cheatsheet.html\" title=\"doc\">N F E L T S C TF</a> directly usable</div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = use(\"nena:clone\", checkout=\"clone\", hoist=globals())\n",
    "# A = use('nena:hot', checkout='hot', hoist=globals())\n",
    "# A = use('nena:latest', checkout='latest', hoist=globals())\n",
    "# A = use('nena', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see which features have been loaded, and if you click on a feature name, you find its documentation.\n",
    "If you hover over a name, you see where the feature is located on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "The result of the incantation is that we have a bunch of special variables at our disposal\n",
    "that give us access to the text and data of the corpus.\n",
    "\n",
    "At this point it is helpful to throw a quick glance at the text-fabric API documentation\n",
    "(see the links under **API Members** above).\n",
    "\n",
    "The most essential thing for now is that we can use `F` to access the data in the features\n",
    "we've loaded.\n",
    "But there is more, such as `N`, which helps us to walk over the text, as we see in a minute.\n",
    "\n",
    "The **API members** above show you exactly which new names have been inserted in your namespace.\n",
    "If you click on these names, you go to the API documentation for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Text-Fabric contains a flexible search engine, that does not only work for the data,\n",
    "of this corpus, but also for other corpora and data that you add to corpora.\n",
    "\n",
    "**Search is the quickest way to come up-to-speed with your data, without too much programming.**\n",
    "\n",
    "Jump to the dedicated [search](search.ipynb) search tutorial first, to whet your appetite.\n",
    "\n",
    "The real power of search lies in the fact that it is integrated in a programming environment.\n",
    "You can use programming to:\n",
    "\n",
    "* compose dynamic queries\n",
    "* process query results\n",
    "\n",
    "Therefore, the rest of this tutorial is still important when you want to tap that power.\n",
    "If you continue here, you learn all the basics of data-navigation with Text-Fabric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting\n",
    "\n",
    "In order to get acquainted with the data, we start with the simple task of counting.\n",
    "\n",
    "## Count all nodes\n",
    "We use the\n",
    "[`N.walk()` generator](https://annotation.github.io/text-fabric/tf/core/nodes.html#tf.core.nodes.Nodes.walk)\n",
    "to walk through the nodes.\n",
    "\n",
    "We compared the TF data to a gigantic spreadsheet, where the rows correspond to the signs.\n",
    "In Text-Fabric, we call the rows `slots`, because they are the textual positions that can be filled with signs.\n",
    "\n",
    "We also mentioned that there are also other textual objects.\n",
    "They are the clusters, lines, faces and documents.\n",
    "They also correspond to rows in the big spreadsheet.\n",
    "\n",
    "In Text-Fabric we call all these rows *nodes*, and the `N()` generator\n",
    "carries us through those nodes in the textual order.\n",
    "\n",
    "Just one extra thing: the `info` statements generate timed messages.\n",
    "If you use them instead of `print` you'll get a sense of the amount of time that\n",
    "the various processing steps typically need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:43.894153Z",
     "start_time": "2018-05-18T09:17:43.597128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Counting nodes ...\n",
      "  0.12s 833532 nodes\n"
     ]
    }
   ],
   "source": [
    "A.indent(reset=True)\n",
    "A.info(\"Counting nodes ...\")\n",
    "\n",
    "i = 0\n",
    "for n in N.walk():\n",
    "    i += 1\n",
    "\n",
    "A.info(\"{} nodes\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see it: a bit less than 1M nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are those nodes?\n",
    "Every node has a type, like sign, or line, face.\n",
    "But what exactly are they?\n",
    "\n",
    "Text-Fabric has two special features, `otype` and `oslots`, that must occur in every Text-Fabric data set.\n",
    "`otype` tells you for each node its type, and you can ask for the number of `slot`s in the text.\n",
    "\n",
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:47.820323Z",
     "start_time": "2018-05-18T09:17:47.812328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'letter'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.slotType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:48.549430Z",
     "start_time": "2018-05-18T09:17:48.543371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539381"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxSlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:49.251302Z",
     "start_time": "2018-05-18T09:17:49.244467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833532"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:49.922863Z",
     "start_time": "2018-05-18T09:17:49.916078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dialect',\n",
       " 'text',\n",
       " 'paragraph',\n",
       " 'line',\n",
       " 'sentence',\n",
       " 'subsentence',\n",
       " 'inton',\n",
       " 'stress',\n",
       " 'word',\n",
       " 'letter')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:51.782779Z",
     "start_time": "2018-05-18T09:17:51.774167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('dialect', 269690.5, 539382, 539383),\n",
       " ('text', 4280.8015873015875, 713259, 713384),\n",
       " ('paragraph', 1536.6980056980058, 577912, 578262),\n",
       " ('line', 212.02083333333334, 575368, 577911),\n",
       " ('sentence', 32.28473095109834, 578263, 594969),\n",
       " ('subsentence', 21.991315692909854, 688732, 713258),\n",
       " ('inton', 14.989467541129391, 539384, 575367),\n",
       " ('stress', 5.752660992726264, 594970, 688731),\n",
       " ('word', 4.489304857342611, 713385, 833532),\n",
       " ('letter', 1, 1, 539381))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.levels.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting: above you see all the textual objects, with the average size of their objects,\n",
    "the node where they start, and the node where they end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count individual object types\n",
    "This is an intuitive way to count the number of nodes in each type.\n",
    "Note in passing, how we use the `indent` in conjunction with `info` to produce neat timed\n",
    "and indented progress messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:57.806821Z",
     "start_time": "2018-05-18T09:17:57.558523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s counting objects ...\n",
      "   |     0.00s       2 dialects\n",
      "   |     0.00s     126 texts\n",
      "   |     0.00s     351 paragraphs\n",
      "   |     0.00s    2544 lines\n",
      "   |     0.00s   16707 sentences\n",
      "   |     0.00s   24527 subsentences\n",
      "   |     0.00s   35984 intons\n",
      "   |     0.01s   93762 stresss\n",
      "   |     0.01s  120148 words\n",
      "   |     0.06s  539381 letters\n",
      "  0.10s Done\n"
     ]
    }
   ],
   "source": [
    "A.indent(reset=True)\n",
    "A.info(\"counting objects ...\")\n",
    "\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "\n",
    "    A.indent(level=1, reset=True)\n",
    "\n",
    "    for n in F.otype.s(otype):\n",
    "        i += 1\n",
    "\n",
    "    A.info(\"{:>7} {}s\".format(i, otype))\n",
    "\n",
    "A.indent(level=0)\n",
    "A.info(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing textual objects\n",
    "\n",
    "You can use the A API (the extra power) to display cuneiform text.\n",
    "\n",
    "See the [display](display.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature statistics\n",
    "\n",
    "`F`\n",
    "gives access to all features.\n",
    "Every feature has a method\n",
    "`freqList()`\n",
    "to generate a frequency list of its values, higher frequencies first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Dawið ʾAdam', 21184),\n",
       " ('Yulia Davudi', 19189),\n",
       " ('Yuwarəš Xošăba Kena', 10124),\n",
       " ('Manya Givoyev', 6746),\n",
       " ('Yuwəl Yuḥanna', 5953),\n",
       " ('Nanəs Bənyamən', 5424),\n",
       " ('Yosəp bet Yosəp', 5255),\n",
       " ('Yonan Petrus', 4665),\n",
       " ('Natan Khoshaba', 4502),\n",
       " ('Merab Badalov', 3479),\n",
       " ('Arsen Mikhaylov', 3336),\n",
       " ('Xošebo ʾOdišo', 3281),\n",
       " ('Alice Bet-Yosəp', 3221),\n",
       " ('Nancy George', 3131),\n",
       " ('Awiko Sulaqa', 3096),\n",
       " ('Maryam Gwirgis', 2954),\n",
       " ('Bənyamən Bənyamən', 2598),\n",
       " ('Mišayel Barčəm', 1818),\n",
       " ('Nadia Aloverdova', 1754),\n",
       " ('Frederic Ayyubkhan', 1615),\n",
       " ('Victor Orshan', 1426),\n",
       " ('Sophia Danielova', 1109),\n",
       " ('Blandina Barwari', 1030),\n",
       " ('Dawið Gwərgəs', 865),\n",
       " ('Jacob Petrus', 795),\n",
       " ('Gwərgəs Dawið', 658),\n",
       " ('Dawid Adam', 492),\n",
       " ('Kena Kena', 174),\n",
       " ('Nawiya ʾOdišo', 102),\n",
       " ('GK', 101),\n",
       " ('Leya ʾOraha', 71))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.speaker.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words and morphemes have the feature `foreign`. We can count them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('True', 534),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.foreign.freqList(\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.foreign.freqList(\"morpheme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word matters\n",
    "\n",
    "## Top 20 frequent words\n",
    "\n",
    "We count words by their lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1857 w, ʾu-\n",
      " 1322 xa, xaʾa\n",
      "  960 ṱ\n",
      "  859 b-\n",
      "  749 gu-\n",
      "  742 la\n",
      "  621 t\n",
      "  590 l-\n",
      "  529 ʾana\n",
      "  498 mən, m-\n",
      "  429 diya\n",
      "  349 naša\n",
      "  342 ʾawwa\n",
      "  339 malka\n",
      "  338 ʾaw, ʾo\n",
      "  330 kul, ku, kulla\n",
      "  326 mo, mu, modi, maw, mawdi\n",
      "  319 qəm-\n",
      "  318 ʾaw\n",
      "  300 ṭla-, ta-\n"
     ]
    }
   ],
   "source": [
    "for (w, amount) in F.lemma.freqList()[0:20]:\n",
    "    print(f\"{amount:>5} {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word distribution\n",
    "\n",
    "Let's do a bit more fancy word stuff.\n",
    "\n",
    "### Hapaxes\n",
    "\n",
    "A hapax can be found by picking the words with frequency 1.\n",
    "\n",
    "We print 20 hapaxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes1 = sorted(lx for (lx, amount) in F.lemma.freqList() if amount == 1)\n",
    "len(hapaxes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bahər, bɛhər, bɛhɛri\n",
      "banaya, bannaya\n",
      "banda\n",
      "baxəra\n",
      "baʿd\n",
      "baṣora\n",
      "baṭila\n",
      "baṭman\n",
      "bdila\n",
      "boš\n",
      "briza\n",
      "bulbul\n",
      "burra\n",
      "busama\n",
      "bustana\n",
      "buxtən\n",
      "băṭaniya\n",
      "bšila\n",
      "bərra\n",
      "bəṣliṣa\n"
     ]
    }
   ],
   "source": [
    "for lx in hapaxes1[0:20]:\n",
    "    print(lx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small occurrence base\n",
    "\n",
    "The occurrence base of a word are the scrolls in which occurs.\n",
    "\n",
    "We compute the occurrence base of each word, based on lexemes according to the `glex` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s compiling occurrence base ...\n",
      "  2.71s 1174 entries\n"
     ]
    }
   ],
   "source": [
    "occurrenceBase1 = collections.defaultdict(set)\n",
    "\n",
    "A.indent(reset=True)\n",
    "A.info(\"compiling occurrence base ...\")\n",
    "for w in F.otype.s(\"word\"):\n",
    "    text = T.sectionFromNode(w)[1]\n",
    "    occurrenceBase1[F.lemma.v(w)].add(text)\n",
    "A.info(f\"{len(occurrenceBase1)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that took long!\n",
    "\n",
    "We looked up the text for each word.\n",
    "\n",
    "But there is another way:\n",
    "\n",
    "Start with texts, and iterate through their words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s compiling occurrence base ...\n",
      "  0.19s done\n",
      "  0.19s 1174 entries\n"
     ]
    }
   ],
   "source": [
    "occurrenceBase2 = collections.defaultdict(set)\n",
    "\n",
    "A.indent(reset=True)\n",
    "A.info(\"compiling occurrence base ...\")\n",
    "for s in F.otype.s(\"text\"):\n",
    "    text = F.title.v(s)\n",
    "    for w in L.d(s, otype=\"word\"):\n",
    "        occurrenceBase2[F.lemma.v(w)].add(text)\n",
    "A.info(\"done\")\n",
    "A.info(f\"{len(occurrenceBase2)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Are the results equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrenceBase1 == occurrenceBase2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrenceBase = occurrenceBase2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of how many words have how big occurrence bases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base size    1 :   531 words\n",
      "base size    2 :   199 words\n",
      "base size    3 :    85 words\n",
      "base size    4 :    65 words\n",
      "base size    5 :    35 words\n",
      "base size    6 :    25 words\n",
      "base size    8 :    19 words\n",
      "base size   10 :    19 words\n",
      "base size    7 :    17 words\n",
      "base size   12 :    15 words\n",
      "...\n",
      "base size   38 :     2 words\n",
      "base size   51 :     2 words\n",
      "base size   26 :     1 words\n",
      "base size   31 :     1 words\n",
      "base size   46 :     1 words\n",
      "base size   48 :     1 words\n",
      "base size   49 :     1 words\n",
      "base size   50 :     1 words\n",
      "base size   52 :     1 words\n",
      "base size  126 :     1 words\n"
     ]
    }
   ],
   "source": [
    "occurrenceSize = collections.Counter()\n",
    "\n",
    "for (w, scrolls) in occurrenceBase.items():\n",
    "    occurrenceSize[len(scrolls)] += 1\n",
    "\n",
    "occurrenceSize = sorted(\n",
    "    occurrenceSize.items(),\n",
    "    key=lambda x: (-x[1], x[0]),\n",
    ")\n",
    "\n",
    "for (size, amount) in occurrenceSize[0:10]:\n",
    "    print(f\"base size {size:>4} : {amount:>5} words\")\n",
    "print(\"...\")\n",
    "for (size, amount) in occurrenceSize[-10:]:\n",
    "    print(f\"base size {size:>4} : {amount:>5} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give the predicate *private* to those words whose occurrence base is a single text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privates = {w for (w, base) in occurrenceBase.items() if len(base) == 1}\n",
    "len(privates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peculiarity of texts\n",
    "\n",
    "As a final exercise with texts, lets make a list of all texts, and show their\n",
    "\n",
    "* total number of words\n",
    "* number of private words\n",
    "* the percentage of private words: a measure of the peculiarity of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:52.143337Z",
     "start_time": "2018-05-18T09:18:52.130385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found    0 empty texts\n",
      "Found   74 ordinary texts (i.e. without private words)\n"
     ]
    }
   ],
   "source": [
    "textList = []\n",
    "\n",
    "empty = set()\n",
    "ordinary = set()\n",
    "\n",
    "for d in F.otype.s(\"text\"):\n",
    "    text = F.title.v(d)\n",
    "    words = {F.lemma.v(w) for w in L.d(d, otype=\"word\")}\n",
    "    a = len(words)\n",
    "    if not a:\n",
    "        empty.add(text)\n",
    "        continue\n",
    "    o = len({w for w in words if w in privates})\n",
    "    if not o:\n",
    "        ordinary.add(text)\n",
    "        continue\n",
    "    p = 100 * o / a\n",
    "    textList.append((text, a, o, p))\n",
    "\n",
    "textList = sorted(textList, key=lambda e: (-e[3], -e[1], e[0]))\n",
    "\n",
    "print(f\"Found {len(empty):>4} empty texts\")\n",
    "print(f\"Found {len(ordinary):>4} ordinary texts (i.e. without private words)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:52.143337Z",
     "start_time": "2018-05-18T09:18:52.130385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                                               #all #own %own\n",
      "-----------------------------------\n",
      "Gozali and Nozali                                   331   64 19.3%\n",
      "The Crow and the Cheese                              29    5 17.2%\n",
      "The Story With No End                                54    7 13.0%\n",
      "The Fox and the Miller                              151   18 11.9%\n",
      "The Tale of Mămo and Zine                           271   30 11.1%\n",
      "The King With Forty Sons                            253   28 11.1%\n",
      "Tales From the 1001 Nights                          293   31 10.6%\n",
      "The Fox and the Stork                                38    4 10.5%\n",
      "The Tale of Farxo and Səttiya                       270   27 10.0%\n",
      "The Priest and the Mullah                            82    8  9.8%\n",
      "šošət Xere                                           98    9  9.2%\n",
      "Baby Leliθa                                         166   15  9.0%\n",
      "The Crafty Hireling                                 189   17  9.0%\n",
      "The Man Who Wanted to Work                          151   13  8.6%\n",
      "A Tale of Two Kings                                 108    9  8.3%\n",
      "The Battle With Yuwanəs the Armenian                122   10  8.2%\n",
      "The Wise Daughter of the King                        98    8  8.2%\n",
      "The Fox and the Lion                                 37    3  8.1%\n",
      "Man Is Treacherous                                   62    5  8.1%\n",
      "A Tale of a Prince and a Princess                   213   17  8.0%\n",
      "...\n",
      "The Leliθa From č̭āl                                 79    5  6.3%\n",
      "The Daughter of the King                            176   11  6.2%\n",
      "The Selfish Neighbour                                48    3  6.2%\n",
      "A Man Called Čuxo                                   145    9  6.2%\n",
      "The Tale of Parizada, Warda and Nargis              244   15  6.1%\n",
      "The Wise Young Man                                  175   10  5.7%\n",
      "The Monk Who Wanted to Know When He Would Die        92    5  5.4%\n",
      "A Hundred Gold Coins                                 96    5  5.2%\n",
      "Qaṭina Rescues His Nephew From Leliθa                81    4  4.9%\n",
      "The Scorpion and the Snake                           61    3  4.9%\n",
      "I Am Worth the Same as a Blind Wolf                 107    5  4.7%\n",
      "Measure for Measure                                  44    2  4.5%\n",
      "The Brother of Giants                               119    5  4.2%\n",
      "The Tale of Nasimo                                  101    4  4.0%\n",
      "The Monk and the Angel                              129    4  3.1%\n",
      "The Wise Snake                                      112    3  2.7%\n",
      "The Cat and the Mice                                 39    1  2.6%\n",
      "The Man Who Cried Wolf                               58    1  1.7%\n",
      "The Cooking Pot                                      69    1  1.4%\n",
      "The Giant’s Cave                                     72    1  1.4%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"{:<50}{:>5}{:>5}{:>5}\\n{}\".format(\n",
    "        \"text\",\n",
    "        \"#all\",\n",
    "        \"#own\",\n",
    "        \"%own\",\n",
    "        \"-\" * 35,\n",
    "    )\n",
    ")\n",
    "\n",
    "for x in textList[0:20]:\n",
    "    print(\"{:<50} {:>4} {:>4} {:>4.1f}%\".format(*x))\n",
    "print(\"...\")\n",
    "for x in textList[-20:]:\n",
    "    print(\"{:<50} {:>4} {:>4} {:>4.1f}%\".format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locality API\n",
    "We travel upwards and downwards, forwards and backwards through the nodes.\n",
    "The Locality-API (`L`) provides functions: `u()` for going up, and `d()` for going down,\n",
    "`n()` for going to next nodes and `p()` for going to previous nodes.\n",
    "\n",
    "These directions are indirect notions: nodes are just numbers, but by means of the\n",
    "`oslots` feature they are linked to slots. One node *contains* an other node, if the one is linked to a set of slots that contains the set of slots that the other is linked to.\n",
    "And one if next or previous to an other, if its slots follow or precede the slots of the other one.\n",
    "\n",
    "`L.u(node)` **Up** is going to nodes that embed `node`.\n",
    "\n",
    "`L.d(node)` **Down** is the opposite direction, to those that are contained in `node`.\n",
    "\n",
    "`L.n(node)` **Next** are the next *adjacent* nodes, i.e. nodes whose first slot comes immediately after the last slot of `node`.\n",
    "\n",
    "`L.p(node)` **Previous** are the previous *adjacent* nodes, i.e. nodes whose last slot comes immediately before the first slot of `node`.\n",
    "\n",
    "All these functions yield nodes of all possible otypes.\n",
    "By passing an optional parameter, you can restrict the results to nodes of that type.\n",
    "\n",
    "The result are ordered according to the order of things in the text.\n",
    "\n",
    "The functions return always a tuple, even if there is just one node in the result.\n",
    "\n",
    "## Going up\n",
    "We go from the first word to the scroll it contains.\n",
    "Note the `[0]` at the end. You expect one scroll, yet `L` returns a tuple.\n",
    "To get the only element of that tuple, you need to do that `[0]`.\n",
    "\n",
    "If you are like me, you keep forgetting it, and that will lead to weird error messages later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:55.410034Z",
     "start_time": "2018-05-18T09:18:55.404051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713259\n"
     ]
    }
   ],
   "source": [
    "firstText = L.u(1, otype=\"text\")[0]\n",
    "print(firstText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see all the containing objects of letter 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:56.772513Z",
     "start_time": "2018-05-18T09:18:56.766324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter 3 is contained in dialect 539382\n",
      "letter 3 is contained in text 713259\n",
      "letter 3 is contained in paragraph 577912\n",
      "letter 3 is contained in line 575368\n",
      "letter 3 is contained in sentence 578263\n",
      "letter 3 is contained in subsentence 688732\n",
      "letter 3 is contained in inton 539384\n",
      "letter 3 is contained in stress 594970\n",
      "letter 3 is contained in word 713386\n"
     ]
    }
   ],
   "source": [
    "s = 3\n",
    "for otype in F.otype.all:\n",
    "    if otype == F.otype.slotType:\n",
    "        continue\n",
    "    up = L.u(s, otype=otype)\n",
    "    upNode = \"x\" if len(up) == 0 else up[0]\n",
    "    print(\"letter {} is contained in {} {}\".format(s, otype, upNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going next\n",
    "Let's go to the next nodes of the first text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:58.821681Z",
     "start_time": "2018-05-18T09:18:58.814893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2004: letter        first slot=2004  , last slot=2004  \n",
      " 713868: word          first slot=2004  , last slot=2004  \n",
      " 595313: stress        first slot=2004  , last slot=2012  \n",
      " 539513: inton         first slot=2004  , last slot=2029  \n",
      " 688836: subsentence   first slot=2004  , last slot=2029  \n",
      " 578331: sentence      first slot=2004  , last slot=2029  \n",
      " 575380: line          first slot=2004  , last slot=2183  \n",
      " 577913: paragraph     first slot=2004  , last slot=6497  \n",
      " 713260: text          first slot=2004  , last slot=6497  \n"
     ]
    }
   ],
   "source": [
    "afterFirstText = L.n(firstText)\n",
    "for n in afterFirstText:\n",
    "    print(\n",
    "        \"{:>7}: {:<13} first slot={:<6}, last slot={:<6}\".format(\n",
    "            n,\n",
    "            F.otype.v(n),\n",
    "            E.oslots.s(n)[0],\n",
    "            E.oslots.s(n)[-1],\n",
    "        )\n",
    "    )\n",
    "secondText = L.n(firstText, otype=\"text\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going previous\n",
    "\n",
    "And let's see what is right before the second text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:00.163973Z",
     "start_time": "2018-05-18T09:19:00.154857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 713259: text          first slot=1     , last slot=2003  \n",
      " 577912: paragraph     first slot=1     , last slot=2003  \n",
      " 575379: line          first slot=1855  , last slot=2003  \n",
      " 578330: sentence      first slot=1985  , last slot=2003  \n",
      " 688835: subsentence   first slot=1985  , last slot=2003  \n",
      " 539512: inton         first slot=1985  , last slot=2003  \n",
      " 595312: stress        first slot=1992  , last slot=2003  \n",
      " 713867: word          first slot=1996  , last slot=2003  \n",
      "   2003: letter        first slot=2003  , last slot=2003  \n"
     ]
    }
   ],
   "source": [
    "for n in L.p(secondText):\n",
    "    print(\n",
    "        \"{:>7}: {:<13} first slot={:<6}, last slot={:<6}\".format(\n",
    "            n,\n",
    "            F.otype.v(n),\n",
    "            E.oslots.s(n)[0],\n",
    "            E.oslots.s(n)[-1],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go to the lines of the first text, and just count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:02.530705Z",
     "start_time": "2018-05-18T09:19:02.475279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "lines = L.d(firstText, otype=\"line\")\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text API\n",
    "\n",
    "So far, we have mainly seen nodes and their numbers, and the names of node types.\n",
    "You would almost forget that we are dealing with text.\n",
    "So let's try to see some text.\n",
    "\n",
    "In the same way as `F` gives access to feature data,\n",
    "`T` gives access to the text.\n",
    "That is also feature data, but you can tell Text-Fabric which features are specifically\n",
    "carrying the text, and in return Text-Fabric offers you\n",
    "a Text API: `T`.\n",
    "\n",
    "## Formats\n",
    "DSS text can be represented in a number of ways:\n",
    "\n",
    "* `orig`: unicode\n",
    "* `trans`: ETCBC transcription\n",
    "* `source`: as in Abegg's data files\n",
    "\n",
    "All three can be represented in two flavours:\n",
    "\n",
    "* `full`: all glyphs, but no bracketings and flags\n",
    "* `extra`: everything\n",
    "\n",
    "If you wonder where the information about text formats is stored:\n",
    "not in the program text-fabric, but in the data set.\n",
    "It has a feature `otext`, which specifies the formats and which features\n",
    "must be used to produce them. `otext` is the third special feature in a TF data set,\n",
    "next to `otype` and `oslots`.\n",
    "It is an optional feature.\n",
    "If it is absent, there will be no `T` API.\n",
    "\n",
    "Here is a list of all available formats in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text-orig-full': 'word',\n",
       " 'text-orig-lite': 'word',\n",
       " 'text-trans-full': 'word',\n",
       " 'text-trans-fuzzy': 'word',\n",
       " 'text-trans-lite': 'word',\n",
       " 'layout-orig-full': 'word',\n",
       " 'layout-orig-lite': 'word',\n",
       " 'layout-trans-full': 'word',\n",
       " 'layout-trans-fuzzy': 'word',\n",
       " 'layout-trans-lite': 'word'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the formats\n",
    "\n",
    "The ` T.text()` function is central to get text representations of nodes. Its most basic usage is\n",
    "\n",
    "```python\n",
    "T.text(nodes, fmt=fmt)\n",
    "```\n",
    "where `nodes` is a list or iterable of nodes, usually word nodes, and `fmt` is the name of a format.\n",
    "If you leave out `fmt`, the default `text-orig-full` is chosen.\n",
    "\n",
    "The result is the text in that format for all nodes specified:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see for each format in the list above its intended level of operation: `letter` or `word`.\n",
    "\n",
    "If TF formats a node according to a defined text-format, it will descend to constituent nodes and represent those\n",
    "constituent nodes.\n",
    "\n",
    "In this case, no formats specify the `word` level as the descend type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not specify a format, the **default** format is used (`text-orig-full`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine a portion of text material:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575541"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineNode = T.nodeFromSection((\"Barwar\", \"Gozali and Nozali\", 8))\n",
    "lineNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "line ('Barwar', 'Gozali and Nozali', 8) with\n",
      "  166 letters\n",
      "    0 morphemes\n",
      "   40 words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "letters = L.d(lineNode, otype=\"letter\")\n",
    "morphemes = L.d(lineNode, otype=\"morpheme\")\n",
    "words = L.d(lineNode, otype=\"word\")\n",
    "print(\n",
    "    f\"\"\"\n",
    "line {T.sectionFromNode(lineNode)} with\n",
    "  {len(letters):>3} letters\n",
    "  {len(morphemes):>3} morphemes\n",
    "  {len(words):>3} words\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(letters[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(morphemes[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hadíya mù wídle?ˈ mə́re ṭlá polìseˈ mə́re só l-bɛ́θət '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(words[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole text in all formats in a few seconds\n",
    "Part of the pleasure of working with computers is that they can crunch massive amounts of data.\n",
    "\n",
    "We print the text in all formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:27.839331Z",
     "start_time": "2018-05-18T09:19:18.526400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s writing plain text of all texts in all text formats\n",
      "  1.59s done 5 formats\n",
      "text-orig-full\n",
      "xá-ga xèta,ˈ mállah naṣràdin,ˈ xázəx mòdi wíða.ˈ gu-bɛ̀θa wéwa,ˈ har-zála-w θàya.ˈ zála-w θàya,ˈ mára ya-ʾàlaha,ˈ yawə̀tliˈ ʾə́mma dàwe.ˈ ʾən-hàwaˈ ʾə́č̣č̣i-u ʾə́č̣č̣a maqəlbə̀nna.ˈ ʾu-ʾən-hàwaˈ ʾə́mma-w-xà-ži,ˈ la-băyə̀nna.ˈ de-šùqla.ˈ ʾə̀mma gắrəg háwa drə́st.ˈ \n",
      "b-álaha hóle zála-w θàya,ˈ ʾíθwale xá-šwawa huðàya,ˈ maṣóθe ʾə́lle dìye.ˈ mə́re xázəx ʾáwwa dū̀s-ile.ˈ qɛ́mən mjarbə̀nne.ˈ síqa l-gàre,ˈ də́ryɛle ʾə́č̣č̣i-u ʾə́č̣č̣a dáwe gu-ða-kìsta,ˈ də́rya b-kàwele.ˈ ʾá báxta hàyyo!ˈ hóle ʾaláha qəm-mšadə̀rrən.ˈ \n",
      "muθɛ́θɛla màjma.ˈ msúrqəlla píšela mnáyəlla l-xà-xa.ˈ plíṭla ʾə́č̣č̣i-u ʾə̀č̣č̣a.ˈ trè,ˈ trè,ˈ ʾə́č̣č̣i-u ʾə̀č̣č̣a.ˈ ʾə̀ṣra,ˈ ʾə̀ṣra,ˈ hàr-ʾəč̣č̣i-u ʾə́č̣č̣a.ˈ klèla,ˈ ʾámər báxta dū̀s-ile.ˈ ʾaláha là-xaləṭ.ˈ ʾə́č̣č̣i-u ʾə̀č̣č̣a,ˈ ʾáxči ʾána max-xšàwti,ˈ ʾáyya kìstaˈ hóle mxožə́bnəlla max-xà.ˈ ha-šqùl,ˈ máttula tămàha.ˈ \n",
      "huðáya l-gàreˈ šwirɛ́le l-pàlga,ˈ yába ʾànən mšúdrəlla!ˈ ʾáy kálba ʾámər táma l-gàre maṣyóθe,ˈ bắyət šaqlə́tla ʾap-ʾànna.ˈ mrázgət gànux.ˈ tə́mməl ṱ-ásqəx kəs-qàzi.ˈ huðáya ʾə́č̣č̣i-u ʾə́č̣č̣a dáwe zìle mə́nne,ˈ ʾɛ́ka ṱ-áθya šə̀nθe?!ˈ hal-qedámta šə́nθe la-θèla.ˈ hár-wele zála-w θàya.ˈ \n",
      "málla múttəlle réše dmìxa.ˈ ṭlìya,ˈ kéfe basìmta,ˈ ʾu-dáwe xo-rèše.ˈ sáʾət ʾə́šta mbàdlaˈ ʾə́θyɛle huðáya wáða ṭəq-ṭəq-ṭə́q l-ṭằra.ˈ ʾu-qáre l-tằraˈ mòdila qə́ṣṣət?ˈ \n",
      "\n",
      "text-orig-lite\n",
      "xa-ga xeta,ˈ mallah naṣradin,ˈ xazəx modi wiða.ˈ gu-bɛθa wewa,ˈ har-zala-w θaya.ˈ zala-w θaya,ˈ mara ya-ʾalaha,ˈ yawətliˈ ʾəmma dawe.ˈ ʾən-hawaˈ ʾəč̣č̣i-u ʾəč̣č̣a maqəlbənna.ˈ ʾu-ʾən-hawaˈ ʾəmma-w-xa-ži,ˈ la-bayənna.ˈ de-šuqla.ˈ ʾəmma garəg hawa drəst.ˈ \n",
      "b-alaha hole zala-w θaya,ˈ ʾiθwale xa-šwawa huðaya,ˈ maṣoθe ʾəlle diye.ˈ məre xazəx ʾawwa dus-ile.ˈ qɛmən mjarbənne.ˈ siqa l-gare,ˈ dəryɛle ʾəč̣č̣i-u ʾəč̣č̣a dawe gu-ða-kista,ˈ dərya b-kawele.ˈ ʾa baxta hayyo!ˈ hole ʾalaha qəm-mšadərrən.ˈ \n",
      "muθɛθɛla majma.ˈ msurqəlla pišela mnayəlla l-xa-xa.ˈ pliṭla ʾəč̣č̣i-u ʾəč̣č̣a.ˈ tre,ˈ tre,ˈ ʾəč̣č̣i-u ʾəč̣č̣a.ˈ ʾəṣra,ˈ ʾəṣra,ˈ har-ʾəč̣č̣i-u ʾəč̣č̣a.ˈ klela,ˈ ʾamər baxta dus-ile.ˈ ʾalaha la-xaləṭ.ˈ ʾəč̣č̣i-u ʾəč̣č̣a,ˈ ʾaxči ʾana max-xšawti,ˈ ʾayya kistaˈ hole mxožəbnəlla max-xa.ˈ ha-šqul,ˈ mattula tamaha.ˈ \n",
      "huðaya l-gareˈ šwirɛle l-palga,ˈ yaba ʾanən mšudrəlla!ˈ ʾay kalba ʾamər tama l-gare maṣyoθe,ˈ bayət šaqlətla ʾap-ʾanna.ˈ mrazgət ganux.ˈ təmməl ṱ-asqəx kəs-qazi.ˈ huðaya ʾəč̣č̣i-u ʾəč̣č̣a dawe zile mənne,ˈ ʾɛka ṱ-aθya šənθe?!ˈ hal-qedamta šənθe la-θela.ˈ har-wele zala-w θaya.ˈ \n",
      "malla muttəlle reše dmixa.ˈ ṭliya,ˈ kefe basimta,ˈ ʾu-dawe xo-reše.ˈ saʾət ʾəšta mbadlaˈ ʾəθyɛle huðaya waða ṭəq-ṭəq-ṭəq l-ṭara.ˈ ʾu-qare l-taraˈ modila qəṣṣət?ˈ \n",
      "\n",
      "text-trans-full\n",
      "xa'-ga xe`ta,| ma'llah nas.ra`din,| xa'z9x mo`di wi'6a.| gu-b3`8a we'wa,| har-za'la-w 8a`ya.| za'la-w 8a`ya,| ma'ra ya-)a`laha,| yaw9`tli| )9'mma da`we.| )9n-ha`wa| )9'c.>c.>i-u )9'c.>c.>a maq9lb9`nna.| )u-)9n-ha`wa| )9'mma-w-xa`-z>i,| la-ba%y9`nna.| de-s>u`qla.| )9`mma ga%'r9g ha'wa dr9'st.| \n",
      "b-a'laha ho'le za'la-w 8a`ya,| )i'8wale xa'-s>wawa hu6a`ya,| mas.o'8e )9'lle di`ye.| m9're xa'z9x )a'wwa du_`s-ile.| q3'm9n mjarb9`nne.| si'qa l-ga`re,| d9'ry3le )9'c.>c.>i-u )9'c.>c.>a da'we gu-6a-ki`sta,| d9'rya b-ka`wele.| )a' ba'xta ha`yyo!| ho'le )ala'ha q9m-ms>ad9`rr9n.| \n",
      "mu83'83la ma`jma.| msu'rq9lla pi's>ela mna'y9lla l-xa`-xa.| pli'tla )9'c.>c.>i-u )9`c.>c.>a.| tre`,| tre`,| )9'c.>c.>i-u )9`c.>c.>a.| )9`s.ra,| )9`s.ra,| ha`r-)9c.>c.>i-u )9'c.>c.>a.| kle`la,| )a'm9r ba'xta du_`s-ile.| )ala'ha la`-xal9t.| )9'c.>c.>i-u )9`c.>c.>a,| )a'xc>i )a'na max-xs>a`wti,| )a'yya ki`sta| ho'le mxoz>9'bn9lla max-xa`.| ha-s>qu`l,| ma'ttula ta%ma`ha.| \n",
      "hu6a'ya l-ga`re| s>wir3'le l-pa`lga,| ya'ba )a`n9n ms>u'dr9lla!| )a'y ka'lba )a'm9r ta'ma l-ga`re mas.yo'8e,| ba%'y9t s>aql9'tla )ap-)a`nna.| mra'zg9t ga`nux.| t9'mm9l t<-a'sq9x k9s-qa`zi.| hu6a'ya )9'c.>c.>i-u )9'c.>c.>a da'we zi`le m9'nne,| )3'ka t<-a'8ya s>9`n8e?!| hal-qeda'mta s>9'n8e la-8e`la.| ha'r-wele za'la-w 8a`ya.| \n",
      "ma'lla mu'tt9lle re's>e dmi`xa.| tli`ya,| ke'fe basi`mta,| )u-da'we xo-re`s>e.| sa')9t )9's>ta mba`dla| )9'8y3le hu6a'ya wa'6a t9q-t9q-t9'q l-ta%`ra.| )u-qa're l-ta%`ra| mo`dila q9's.s.9t?| \n",
      "\n",
      "text-trans-fuzzy\n",
      "xa-ga xeta, mallah nasradin, xazix modi wida. gu-beta wewa, har-zala-w taya. zala-w taya, mara ya-alaha, yawitli imma dawe. in-hawa i55i-u i55a maqilbinna. u-in-hawa imma-w-xa-zi, la-bayinna. de-suqla. imma garig hawa drist. \n",
      "b-alaha hole zala-w taya, itwale xa-swawa hudaya, masote ille diye. mire xazix awwa dus-ile. qemin mjarbinne. siqa l-gare, diryele i55i-u i55a dawe gu-da-kista, dirya b-kawele. a baxta hayyo! hole alaha qim-msadirrin. \n",
      "mutetela majma. msurqilla pisela mnayilla l-xa-xa. plitla i55i-u i55a. tre, tre, i55i-u i55a. isra, isra, har-i55i-u i55a. klela, amir baxta dus-ile. alaha la-xalit. i55i-u i55a, ax5i ana max-xsawti, ayya kista hole mxozibnilla max-xa. ha-squl, mattula tamaha. \n",
      "hudaya l-gare swirele l-palga, yaba anin msudrilla! ay kalba amir tama l-gare masyote, bayit saqlitla ap-anna. mrazgit ganux. timmil t-asqix kis-qazi. hudaya i55i-u i55a dawe zile minne, eka t-atya sinte?! hal-qedamta sinte la-tela. har-wele zala-w taya. \n",
      "malla muttille rese dmixa. tliya, kefe basimta, u-dawe xo-rese. sait ista mbadla ityele hudaya wada tiq-tiq-tiq l-tara. u-qare l-tara modila qissit? \n",
      "\n",
      "text-trans-lite\n",
      "xa-ga xeta,| mallah naSradin,| xaz9x modi wi6a.| gu-b38a wewa,| har-zala-w 8aya.| zala-w 8aya,| mara ya-)alaha,| yaw9tli| )9mma dawe.| )9n-hawa| )9%%i-u )9%%a maq9lb9nna.| )u-)9n-hawa| )9mma-w-xa-7i,| la-b@y9nna.| de-$uqla.| )9mma g@r9g hawa dr9st.| \n",
      "b-alaha hole zala-w 8aya,| )i8wale xa-$wawa hu6aya,| maSo8e )9lle diye.| m9re xaz9x )awwa dus-ile.| q3m9n mjarb9nne.| siqa l-gare,| d9ry3le )9%%i-u )9%%a dawe gu-6a-kista,| d9rya b-kawele.| )a baxta hayyo!| hole )alaha q9m-m$ad9rr9n.| \n",
      "mu8383la majma.| msurq9lla pi$ela mnay9lla l-xa-xa.| pliTla )9%%i-u )9%%a.| tre,| tre,| )9%%i-u )9%%a.| )9Sra,| )9Sra,| har-)9%%i-u )9%%a.| klela,| )am9r baxta dus-ile.| )alaha la-xal9T.| )9%%i-u )9%%a,| )ax5i )ana max-x$awti,| )ayya kista| hole mxo79bn9lla max-xa.| ha-$qul,| mattula t@maha.| \n",
      "hu6aya l-gare| $wir3le l-palga,| yaba )an9n m$udr9lla!| )ay kalba )am9r tama l-gare maSyo8e,| b@y9t $aql9tla )ap-)anna.| mrazg9t ganux.| t9mm9l +-asq9x k9s-qazi.| hu6aya )9%%i-u )9%%a dawe zile m9nne,| )3ka +-a8ya $9n8e?!| hal-qedamta $9n8e la-8ela.| har-wele zala-w 8aya.| \n",
      "malla mutt9lle re$e dmixa.| Tliya,| kefe basimta,| )u-dawe xo-re$e.| sa)9t )9$ta mbadla| )98y3le hu6aya wa6a T9q-T9q-T9q l-T@ra.| )u-qare l-t@ra| modila q9SS9t?| \n",
      "\n"
     ]
    }
   ],
   "source": [
    "A.indent(reset=True)\n",
    "A.info(\"writing plain text of all texts in all text formats\")\n",
    "\n",
    "formats = T.formats\n",
    "\n",
    "text = collections.defaultdict(list)\n",
    "\n",
    "for ln in F.otype.s(\"line\"):\n",
    "    for fmt in formats:\n",
    "        if fmt.startswith(\"layout\"):\n",
    "            continue\n",
    "        text[fmt].append(T.text(ln, fmt=fmt, descend=True))\n",
    "\n",
    "A.info(\"done {} formats\".format(len(text)))\n",
    "\n",
    "for fmt in sorted(text):\n",
    "    print(\"{}\\n{}\\n\".format(fmt, \"\\n\".join(text[fmt][0:5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full plain text\n",
    "We write all formats to file, in your `Downloads` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:34.250294Z",
     "start_time": "2018-05-18T09:19:34.156658Z"
    }
   },
   "outputs": [],
   "source": [
    "for fmt in T.formats:\n",
    "    with open(\n",
    "        os.path.expanduser(f\"~/Downloads/{fmt}.txt\"),\n",
    "        \"w\",\n",
    "        # encoding='utf8',\n",
    "    ) as f:\n",
    "        f.write(\"\\n\".join(text[fmt]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(if this errors, uncomment the line with `encoding`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "\n",
    "A section in the NENA corpus is a dialect, a text or a line.\n",
    "Knowledge of sections is not baked into Text-Fabric.\n",
    "The config feature `otext.tf` may specify three section levels, and tell\n",
    "what the corresponding node types and features are.\n",
    "\n",
    "From that knowledge it can construct mappings from nodes to sections, e.g. from line\n",
    "nodes to tuples of the form:\n",
    "\n",
    "    (dialect name, text title, line number)\n",
    "\n",
    "You can get the section of a node as a tuple of relevant dialect, text, and line nodes.\n",
    "Or you can get it as a passage label, a string.\n",
    "\n",
    "You can ask for the passage corresponding to the first slot of a node, or the one corresponding to the last slot.\n",
    "\n",
    "Here are examples of getting the section that corresponds to a node and vice versa.\n",
    "\n",
    "**NB:** `sectionFromNode` always delivers a line specification, either from the\n",
    "first slot belonging to that node, or, if `lastSlot`, from the last slot\n",
    "belonging to that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "someNodes = (\n",
    "    F.otype.s(\"letter\")[100000],\n",
    "    F.otype.s(\"word\")[5000],\n",
    "    F.otype.s(\"inton\")[4000],\n",
    "    F.otype.s(\"stress\")[3000],\n",
    "    F.otype.s(\"line\")[1000],\n",
    "    F.otype.s(\"text\")[100],\n",
    "    F.otype.s(\"dialect\")[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:43.056511Z",
     "start_time": "2018-05-18T09:19:43.043552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100001 letter   - ((539382, 713280, 575961), (539382, 713280, 575961))\n",
      "    first: Barwar, The Daughter of the King, Ln. 14\n",
      "    last:  Barwar, The Daughter of the King, Ln. 14\n",
      " 718385 word     - ((539382, 713263, 575489), (539382, 713263, 575489))\n",
      "    first: Barwar, Baby Leliθa, Ln. 9\n",
      "    last:  Barwar, Baby Leliθa, Ln. 9\n",
      " 543384 inton    - ((539382, 713272, 575727), (539382, 713272, 575727))\n",
      "    first: Barwar, Tales From the 1001 Nights, Ln. 18\n",
      "    last:  Barwar, Tales From the 1001 Nights, Ln. 18\n",
      " 597970 stress   - ((539382, 713262, 575466), (539382, 713262, 575466))\n",
      "    first: Barwar, A Tale of a Prince and a Princess, Ln. 46\n",
      "    last:  Barwar, A Tale of a Prince and a Princess, Ln. 46\n",
      " 576368 line     - ((539382, 713300, 576368), (539382, 713300, 576368))\n",
      "    first: Barwar, The Tale of Farxo and Səttiya, Ln. 28\n",
      "    last:  Barwar, The Tale of Farxo and Səttiya, Ln. 28\n",
      " 713359 text     - ((539383, 713359), (539383, 713359, 577524))\n",
      "    first: Urmi_C, The Loan of a Cooking Pot\n",
      "    last:  Urmi_C, The Loan of a Cooking Pot, Ln. 5\n",
      " 539383 dialect  - ((539383,), (539383, 713384, 577911))\n",
      "    first: Urmi_C\n",
      "    last:  Urmi_C, Women Do Things Best, Ln. 19\n"
     ]
    }
   ],
   "source": [
    "for n in someNodes:\n",
    "    nType = F.otype.v(n)\n",
    "    d = f\"{n:>7} {nType}\"\n",
    "    first = A.sectionStrFromNode(n)\n",
    "    last = A.sectionStrFromNode(n, lastSlot=True, fillup=True)\n",
    "    tup = (\n",
    "        T.sectionTuple(n),\n",
    "        T.sectionTuple(n, lastSlot=True, fillup=True),\n",
    "    )\n",
    "    print(f\"{d:<16} - {tup}\")\n",
    "    print(f\"    first: {first}\")\n",
    "    print(f\"    last:  {last}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean caches\n",
    "\n",
    "Text-Fabric pre-computes data for you, so that it can be loaded faster.\n",
    "If the original data is updated, Text-Fabric detects it, and will recompute that data.\n",
    "\n",
    "But there are cases, when the algorithms of Text-Fabric have changed, without any changes in the data, that you might\n",
    "want to clear the cache of precomputed results.\n",
    "\n",
    "There are two ways to do that:\n",
    "\n",
    "* Locate the `.tf` directory of your dataset, and remove all `.tfx` files in it.\n",
    "  This might be a bit awkward to do, because the `.tf` directory is hidden on Unix-like systems.\n",
    "* Call `TF.clearCache()`, which does exactly the same.\n",
    "\n",
    "It is not handy to execute the following cell all the time, that's why I have commented it out.\n",
    "So if you really want to clear the cache, remove the comment sign below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "By now you have an impression how to compute around in the corpus.\n",
    "While this is still the beginning, I hope you already sense the power of unlimited programmatic access\n",
    "to all the bits and bytes in the data set.\n",
    "\n",
    "Here are a few directions for unleashing that power.\n",
    "\n",
    "* **[display](display.ipynb)** become an expert in creating pretty displays of your text structures\n",
    "* **[search](search.ipynb)** turbo charge your hand-coding with search templates\n",
    "* **[exportExcel](exportExcel.ipynb)** make tailor-made spreadsheets out of your results\n",
    "* **[share](share.ipynb)** draw in other people's data and let them use yours\n",
    "* **[similarLines](similarLines.ipynb)** spot the similarities between lines\n",
    "\n",
    "---\n",
    "\n",
    "See the [cookbook](cookbook) for recipes for small, concrete tasks.\n",
    "\n",
    "CC-BY Dirk Roorda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
