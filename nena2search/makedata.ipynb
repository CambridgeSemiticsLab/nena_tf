{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adopted-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-reader",
   "metadata": {},
   "source": [
    "Make plain text data, remembering the nodes that the text comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unusual-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from tf.app import use\n",
    "from tf.convert.recorder import Recorder\n",
    "from tf.core.helpers import specFromRanges, rangesFromSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numerical-politics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b title=\"local github\">TF-app:</b> <span title=\"repo clone offline under ~/github\">~/github/annotation/app-nena/code</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local github\">data:</b> <span title=\"repo clone offline under ~/github\">~/github/CambridgeSemiticsLab/nena_tf/tf/alpha</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Text-Fabric:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"text-fabric-api\">Text-Fabric API 8.4.13</a>, <a target=\"_blank\" href=\"https://github.com/annotation/app-nena\" title=\"nena TF-app\">app-nena v3</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br><b>Data:</b> <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md.md\" title=\"provenance of Northeastern Neo-Aramaic Text Corpus\">NENA_TF</a>, <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/transcription.md\" title=\"NENA transcription script\">Character table</a>, <a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#\" title=\"NENA_TF feature documentation\">Feature docs</a><br><b>Features:</b><br><details><summary><b>Northeastern Neo-Aramaic Text Corpus</b></summary><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#dialect\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/dialect.tf\">dialect</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#full\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/full.tf\">full</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#full_end\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/full_end.tf\">full_end</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#fuzzy\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/fuzzy.tf\">fuzzy</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#fuzzy_end\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/fuzzy_end.tf\">fuzzy_end</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#gloss\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/gloss.tf\">gloss</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#gn\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/gn.tf\">gn</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lang\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/lang.tf\">lang</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lemma\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/lemma.tf\">lemma</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#line_number\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/line_number.tf\">line_number</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lite\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/lite.tf\">lite</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#lite_end\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/lite_end.tf\">lite_end</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#n_parses\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/n_parses.tf\">n_parses</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#nu\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/nu.tf\">nu</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#nu_class\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/nu_class.tf\">nu_class</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#otype\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/otype.tf\">otype</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#phonation\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/phonation.tf\">phonation</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#phonetic_class\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/phonetic_class.tf\">phonetic_class</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#phonetic_manner\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/phonetic_manner.tf\">phonetic_manner</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#phonetic_place\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/phonetic_place.tf\">phonetic_place</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#place\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/place.tf\">place</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#pos\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/pos.tf\">pos</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#speaker\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/speaker.tf\">speaker</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#speakers\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/speakers.tf\">speakers</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#st\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/st.tf\">st</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#tense\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/tense.tf\">tense</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/text.tf\">text</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text_end\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/text_end.tf\">text_end</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text_id\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/text_id.tf\">text_id</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text_nostress\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/text_nostress.tf\">text_nostress</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#text_nostress_end\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/text_nostress_end.tf\">text_nostress_end</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#title\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/title.tf\">title</a><br><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#variable\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/variable.tf\">variable</a><br><b><i><a target=\"_blank\" href=\"https://github.com/CambridgeSemiticsLab/nena_tf/blob/master/docs/features.md#oslots\" title=\"~/github/CambridgeSemiticsLab/nena_tf/tf/alpha/oslots.tf\">oslots</a></i></b><br></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Gentium Plus\";\n",
       "  src: local('Gentium Plus'), local('GentiumPlus'),\n",
       "    url('/server/static/fonts/GentiumPlus-R.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/GentiumPlus-R.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/server/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/server/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/server/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/server/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/server/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/server/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/server/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".ubd {\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".col {\n",
       "   display: inline-block;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 2px;\n",
       "    margin: 2px;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -2px 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 2px 0px;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".tfsechead {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--tfsechead);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  10px 2px 2px 2px;\n",
       "    margin: 16px 2px 2px 2px;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    display: inline-block;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 4px;\n",
       "    margin-left: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 4px;\n",
       "    margin-right: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -24px;\n",
       "    margin-left: 20px;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 6px;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 2px;\n",
       "    margin-left: 2px;\n",
       "    padding: 2px 2px;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 40px;\n",
       "\tpadding: 20px;\n",
       "\tborder: 2px solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--tfsechead:          hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         3px;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "  --border-width-nul:   2px;\n",
       "  --border-width0:      2px;\n",
       "  --border-width1:      3px;\n",
       "  --border-width2:      4px;\n",
       "  --border-width3:      6px;\n",
       "  --border-width4:      5px;\n",
       "  --border-width-plain: 2px;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 2px;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 4px ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 4px ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 6px;\n",
       "  padding: 4px;\n",
       "  margin: 4px;\n",
       "}\n",
       "\n",
       "span.plain {\n",
       "  display: inline-block;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "}\n",
       ".speaker {\n",
       "    vertical-align: super;\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #884400;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Text-Fabric API:</b> names <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"doc\">N F E L T S C TF</a> directly usable</div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = use(\"nena:clone\", checkout=\"clone\", hoist=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adolescent-diabetes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2 dialect      nodes average 269689 chars\n",
      "   126 text         nodes average   4281 chars\n",
      "   350 paragraph    nodes average   1541 chars\n",
      "  2544 line         nodes average    212 chars\n",
      " 16326 sentence     nodes average     33 chars\n",
      " 24497 subsentence  nodes average     22 chars\n",
      " 36444 inton        nodes average     15 chars\n",
      " 93766 stress       nodes average      6 chars\n",
      "120151 word         nodes average      4 chars\n",
      "539378 letter       nodes average      1 chars\n"
     ]
    }
   ],
   "source": [
    "for (tp, av, start, end) in C.levels.data:\n",
    "    print(f\"{end - start + 1:>6} {tp:<12} nodes average {int(round(av)):>6} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-harbor",
   "metadata": {},
   "source": [
    "# Generate full layered data\n",
    "\n",
    "We use the `full` transcription.\n",
    "\n",
    "We remember nodes of the types *letter*, *word*, *sentence*, *line*, and *text*.\n",
    "\n",
    "We store the positions by node type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "primary-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "GH = os.path.expanduser(\"~/github\")\n",
    "ORG = \"CambridgeSemiticsLab\"\n",
    "REPO = \"nena_tf\"\n",
    "REL = \"nena2search/app\"\n",
    "OUTPUT = f\"{GH}/{ORG}/{REPO}/{REL}\"\n",
    "DEBUG_OUTPUT = f\"{GH}/{ORG}/{REPO}/_local\"\n",
    "TEST_TEXTS_DIR = f\"{DEBUG_OUTPUT}/texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "acceptable-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "PH_ABSENT = \"z\"\n",
    "CH_ABSENT = \"¿\"\n",
    "\n",
    "CONFIG = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "medium-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG[\"word\"] = dict(\n",
    "    word=dict(\n",
    "        layers=dict(\n",
    "            lang=dict(\n",
    "                feature=\"lang\",\n",
    "                map={x[0]: i + 1 for (i, x) in enumerate(F.lang.freqList())},\n",
    "                default=0,\n",
    "                pos=None,\n",
    "            ),\n",
    "            speaker=dict(\n",
    "                feature=\"speaker\",\n",
    "                map={x[0]: i + 1 for (i, x) in enumerate(F.speaker.freqList())},\n",
    "                default=0,\n",
    "                show=True,\n",
    "                pos=None,\n",
    "            ),\n",
    "            full=dict(\n",
    "                feature=\"full\",\n",
    "                map=None,\n",
    "                default=CH_ABSENT,\n",
    "                pos=None,\n",
    "                show=True,\n",
    "                example=\"mu83\",\n",
    "            ),\n",
    "            cls=dict(\n",
    "                feature=\"phonetic_class\",\n",
    "                descend=\"letter\",\n",
    "                map={\n",
    "                    \"vowel\": \"V\",\n",
    "                    \"consonant\": \"C\",\n",
    "                },\n",
    "                default=PH_ABSENT,\n",
    "                show=True,\n",
    "                pos=None,\n",
    "            ),\n",
    "            voice=dict(\n",
    "                feature=\"phonation\",\n",
    "                descend=\"letter\",\n",
    "                map={\n",
    "                    \"plain\": \"P\",\n",
    "                    \"unvoiced_aspirated\": \"H\",\n",
    "                    \"voiced\": \"V\",\n",
    "                    \"unvoiced\": \"F\",\n",
    "                    \"unvoiced_unaspirated\": \"G\",\n",
    "                    \"emphatic\": \"X\",\n",
    "                },\n",
    "                default=PH_ABSENT,\n",
    "                pos=\"cls\",\n",
    "            ),\n",
    "            place=dict(\n",
    "                feature=\"phonetic_place\",\n",
    "                descend=\"letter\",\n",
    "                map={\n",
    "                    \"dental-alveolar\": \"D\",\n",
    "                    \"labial\": \"B\",\n",
    "                    \"palatal-alveolar\": \"C\",\n",
    "                    \"palatal\": \"J\",\n",
    "                    \"velar\": \"G\",\n",
    "                    \"uvular\": \"X\",\n",
    "                    \"pharyngeal\": \"Q\",\n",
    "                    \"laryngeal\": \"H\",\n",
    "                },\n",
    "                default=PH_ABSENT,\n",
    "                pos=\"cls\",\n",
    "            ),\n",
    "            manner=dict(\n",
    "                feature=\"phonetic_manner\",\n",
    "                descend=\"letter\",\n",
    "                map={\n",
    "                    \"affricative\": \"A\",\n",
    "                    \"nasal\": \"N\",\n",
    "                    \"other\": \"X\",\n",
    "                    \"fricative\": \"F\",\n",
    "                    \"lateral\": \"L\",\n",
    "                    \"sibilant\": \"S\",\n",
    "                },\n",
    "                default=PH_ABSENT,\n",
    "                pos=\"cls\",\n",
    "            ),\n",
    "        ),\n",
    "        afterFeature=\"full_end\",\n",
    "        afterDefault=\"/\",\n",
    "    ),\n",
    "    sentence=dict(\n",
    "        afterDefault=\"\\n\",\n",
    "        by=True,\n",
    "    ),\n",
    "    line=dict(\n",
    "        layers=dict(\n",
    "            number=dict(\n",
    "                feature=\"line_number\",\n",
    "                map=None,\n",
    "                default=-1,\n",
    "                pos=None,\n",
    "                show=True,\n",
    "            ),\n",
    "        ),\n",
    "        afterDefault=\"\\n\",\n",
    "    ),\n",
    "    text=dict(\n",
    "        layers=dict(\n",
    "            title=dict(\n",
    "                feature=\"title\",\n",
    "                map=None,\n",
    "                default=\"¿\",\n",
    "                pos=None,\n",
    "                show=True,\n",
    "                example=\"A\",\n",
    "            ),\n",
    "            dialect=dict(\n",
    "                feature=\"dialect\",\n",
    "                ascend=\"dialect\",\n",
    "                map=None,\n",
    "                default=\"¿\",\n",
    "                pos=None,\n",
    "                show=True,\n",
    "            ),\n",
    "            tid=dict(\n",
    "                feature=\"text_id\",\n",
    "                map=None,\n",
    "                default=\"¿\",\n",
    "                pos=None,\n",
    "            ),\n",
    "            place=dict(\n",
    "                feature=\"place\",\n",
    "                map=None,\n",
    "                default=\"¿\",\n",
    "                pos=None,\n",
    "                example=\"Dure\",\n",
    "            ),\n",
    "        ),\n",
    "        afterDefault=\"\\n\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "marked-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG[\"letter\"] = dict(\n",
    "    letter=dict(\n",
    "        layers=dict(\n",
    "            full=dict(\n",
    "                feature=\"full\",\n",
    "                map=None,\n",
    "                default=CH_ABSENT,\n",
    "                pos=None,\n",
    "                show=True,\n",
    "                example=\"mu83\",\n",
    "            ),\n",
    "            cls=dict(\n",
    "                feature=\"phonetic_class\",\n",
    "                map={\n",
    "                    \"vowel\": \"V\",\n",
    "                    \"consonant\": \"C\",\n",
    "                },\n",
    "                default=PH_ABSENT,\n",
    "                show=True,\n",
    "                pos=None,\n",
    "            ),\n",
    "            voice=dict(\n",
    "                feature=\"phonation\",\n",
    "                map={\n",
    "                    \"plain\": \"P\",\n",
    "                    \"unvoiced_aspirated\": \"H\",\n",
    "                    \"voiced\": \"V\",\n",
    "                    \"unvoiced\": \"F\",\n",
    "                    \"unvoiced_unaspirated\": \"G\",\n",
    "                    \"emphatic\": \"X\",\n",
    "                },\n",
    "                default=PH_ABSENT,\n",
    "                pos=\"cls\",\n",
    "            ),\n",
    "            place=dict(\n",
    "                feature=\"phonetic_place\",\n",
    "                map={\n",
    "                    \"dental-alveolar\": \"D\",\n",
    "                    \"labial\": \"B\",\n",
    "                    \"palatal-alveolar\": \"C\",\n",
    "                    \"palatal\": \"J\",\n",
    "                    \"velar\": \"G\",\n",
    "                    \"uvular\": \"X\",\n",
    "                    \"pharyngeal\": \"Q\",\n",
    "                    \"laryngeal\": \"H\",\n",
    "                },\n",
    "                default=PH_ABSENT,\n",
    "                pos=\"cls\",\n",
    "            ),\n",
    "            manner=dict(\n",
    "                feature=\"phonetic_manner\",\n",
    "                map={\n",
    "                    \"affricative\": \"A\",\n",
    "                    \"nasal\": \"N\",\n",
    "                    \"other\": \"X\",\n",
    "                    \"fricative\": \"F\",\n",
    "                    \"lateral\": \"L\",\n",
    "                    \"sibilant\": \"S\",\n",
    "                },\n",
    "                default=PH_ABSENT,\n",
    "                pos=\"cls\",\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    word=dict(\n",
    "        layers=dict(\n",
    "            lang=dict(\n",
    "                feature=\"lang\",\n",
    "                map={x[0]: i + 1 for (i, x) in enumerate(F.lang.freqList())},\n",
    "                default=0,\n",
    "                pos=None,\n",
    "            ),\n",
    "            speaker=dict(\n",
    "                feature=\"speaker\",\n",
    "                map={x[0]: i + 1 for (i, x) in enumerate(F.speaker.freqList())},\n",
    "                default=0,\n",
    "                pos=None,\n",
    "                show=True,\n",
    "            ),\n",
    "        ),\n",
    "        afterFeature=\"full_end\",\n",
    "        afterDefault=\"/\",\n",
    "    ),\n",
    "    sentence=dict(\n",
    "        afterDefault=\"\\n\",\n",
    "        by=True,\n",
    "    ),\n",
    "    line=dict(\n",
    "        layers=dict(\n",
    "            number=dict(\n",
    "                feature=\"line_number\",\n",
    "                map=None,\n",
    "                default=-1,\n",
    "                pos=None,\n",
    "                show=True,\n",
    "            ),\n",
    "        ),\n",
    "        afterDefault=\"\\n\",\n",
    "    ),\n",
    "    text=dict(\n",
    "        layers=dict(\n",
    "            title=dict(\n",
    "                feature=\"title\",\n",
    "                map=None,\n",
    "                default=\"¿\",\n",
    "                pos=None,\n",
    "                show=True,\n",
    "                example=\"A\",\n",
    "            ),\n",
    "            dialect=dict(\n",
    "                feature=\"dialect\",\n",
    "                ascend=\"dialect\",\n",
    "                map=None,\n",
    "                default=\"¿\",\n",
    "                pos=None,\n",
    "                show=True,\n",
    "            ),\n",
    "            tid=dict(\n",
    "                feature=\"text_id\",\n",
    "                map=None,\n",
    "                default=\"¿\",\n",
    "                pos=None,\n",
    "            ),\n",
    "            place=dict(\n",
    "                feature=\"place\",\n",
    "                map=None,\n",
    "                default=\"¿\",\n",
    "                pos=None,\n",
    "                example=\"Dure\",\n",
    "            ),\n",
    "        ),\n",
    "        afterDefault=\"\\n\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "balanced-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkConfig(kind):\n",
    "    sys.stdout.write(f\"Making data based on {kind}-config\")\n",
    "    \n",
    "    layerConfig = CONFIG[kind]\n",
    "    typeSeq = list(layerConfig)\n",
    "    typesLower = {}\n",
    "\n",
    "    for (i, tp) in enumerate(typeSeq):\n",
    "        typesLower[tp] = typeSeq[0: i + 1]\n",
    "        \n",
    "    config = dict(layerConfig=layerConfig, typeSeq=typeSeq, typesLower=typesLower)\n",
    "\n",
    "    # check show and by attributes\n",
    "\n",
    "    theBys = []\n",
    "    theShows = []\n",
    "\n",
    "    for (nType, typeInfo) in layerConfig.items():\n",
    "        if typeInfo.get(\"by\", False):\n",
    "            theBys.append(nType)\n",
    "\n",
    "        for (name, layerInfo) in layerConfig[nType].get(\"layers\", {}).items():\n",
    "            if layerInfo.get(\"show\", False):\n",
    "                theShows.append((nType, name))\n",
    "\n",
    "    if len(theBys) == 0:\n",
    "        sys.stderr.write(\"No node type is declared as result container ('by')\\n\")\n",
    "    elif len(theBys) > 1:\n",
    "        sys.stderr.write(\"Multiple node types declared as result container ('by'):\\n\")\n",
    "        sys.stderr.write(\"\\t\" + (\", \".join(theBys)) + \"\\n\")\n",
    "    else:\n",
    "        sys.stdout.write(\"Node type declared as result container ('by'):\\n\")\n",
    "        sys.stdout.write(f\"\\t{theBys[0]}\\n\")\n",
    "\n",
    "    sys.stderr.flush()\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if len(theShows) == 0:\n",
    "        sys.stderr.write(\"No layer type is declared as result shower ('show')\\n\")\n",
    "    else:\n",
    "        sys.stdout.write(\"Layers declared as result showers ('show'):\\n\")\n",
    "        sys.stdout.write(\"\\t\" + (\", \".join(\"/\".join(s) for s in theShows)) + \"\\n\")\n",
    "\n",
    "    sys.stderr.flush()\n",
    "    sys.stdout.flush()\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-circus",
   "metadata": {},
   "source": [
    "We take care that for every phonetic property, the value is always exactly one character, no more no less.\n",
    "That means that all recorded phonetic texts have the same mapping between character positions and slot numbers.\n",
    "\n",
    "For the full text it is different: there are 18 letters with an empty full text, and some letters use multiple characters for their full text.\n",
    "\n",
    "In the end, we only have to produce two mappings for the character node type: for the full text and for the phonetics.\n",
    "We choose the phonetic `cls` text to carry the phonetic mapping.\n",
    "\n",
    "As to the mapping from letter nodes to words, sentences, lines and texts: we only need to do that once, and we create\n",
    "it as a single *up* relation, stored outside the recorders.\n",
    "\n",
    "The *up* relation goes from nodes from one type to containing nodes of another type.\n",
    "\n",
    "We make use of the fact that texts are built from lines, which are built from sentences, which are built from words,\n",
    "which are built from characters. \n",
    "\n",
    "This simplifies the *up* relation considerably: we may assume that every node *n* has a single *up* parent:\n",
    "\n",
    "* look in the node type that is one level higher than the type of *n*\n",
    "* pick a node *u* in that type that embeds *n*\n",
    "* *u* must be the only node with that proeprty w.r.t. *n*, since the nodes of these types act as building blocks.\n",
    "\n",
    "Another simplifying hypothesis that holds for this data, is that each character position corresponds with at most\n",
    "one node per node type.\n",
    "\n",
    "So if we have a set of nodes that all correspond with the same character position, they must all belong to different types.\n",
    "Hence, when we organize mappings from character positions to nodes, and we do that for each node type separately,\n",
    "then such mappings map each character position to at most one nodes.\n",
    "\n",
    "Characters on positions that are not mapped by a layer to nodes cannnot be compared with character positions in other layers.\n",
    "So they will fall out of the results if more than one layer is being compared.\n",
    "\n",
    "**N.B.**\n",
    "\n",
    "These simplifying hypothesis make it easier to code the layered search interface in Javascript.\n",
    "But they are not needed for the concept to work.\n",
    "\n",
    "Since this is my first implementation of layered search, written under time constraints, I thankfully make use of these\n",
    "simplifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "tender-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(data):\n",
    "    sets = {}\n",
    "    \n",
    "    compressed = []\n",
    "\n",
    "    for n in sorted(data):\n",
    "        sets.setdefault(data[n], []).append(n)\n",
    "        \n",
    "    for (value, nset) in sorted(\n",
    "        sets.items(), key=lambda x: (x[1][0], x[1][-1])\n",
    "    ):\n",
    "        nSpec = n if len(nset) == 1 else specFromRanges(rangesFromSet(nset))\n",
    "        compressed.append(f\"{nSpec}\\t{value}\")\n",
    "        \n",
    "    return compressed\n",
    "\n",
    "def invert(data):\n",
    "    return {v: k for (k,v) in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "other-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(kind):\n",
    "    A.indent(reset=True)\n",
    "    A.info(\"preparing ... \")\n",
    "    config = checkConfig(kind)\n",
    "    layerConfig = config[\"layerConfig\"]\n",
    "    typeSeq = config[\"typeSeq\"]\n",
    "    typesLower = config[\"typesLower\"]\n",
    "    letterLevel = kind == \"letter\"\n",
    "\n",
    "    A.info(\"start recording\")\n",
    "\n",
    "    up = {}\n",
    "    by = {}\n",
    "    show = {}\n",
    "    layers = {}\n",
    "    texts = {}\n",
    "    positions = {}\n",
    "    recorders = {}\n",
    "    accumulators = {}\n",
    "    testTexts = []\n",
    "\n",
    "    preSep = dict(\n",
    "        text=\"text\",\n",
    "        line=\"\\tline\",\n",
    "        sentence=\"\\t\\tsent\",\n",
    "        word=\"\\t\\t\\tword\",\n",
    "        letter=\"\\t\\t\\t\\tletter\",\n",
    "    )\n",
    "    postSep = dict(\n",
    "        text=\"\\n\",\n",
    "        line=\"\\n\",\n",
    "        sentence=\"\\n\",\n",
    "        word=\"\\n\",\n",
    "        letter=\"\\n\",\n",
    "    )\n",
    "\n",
    "    for (nType, typeInfo) in layerConfig.items():\n",
    "        ti = typeInfo.get(\"layers\", None)\n",
    "        by[nType] = typeInfo.get(\"by\", False)\n",
    "        if ti is None:\n",
    "            continue\n",
    "\n",
    "        show[nType] = {name: ti[name].get(\"show\", False) for name in ti}\n",
    "        layers[nType] = {\n",
    "            name: dict(\n",
    "                map=ti[name][\"map\"],\n",
    "                pos=ti[name][\"pos\"] or name,\n",
    "                value=ti[name].get(\"example\", \"\"),\n",
    "            )\n",
    "            for name in ti\n",
    "        }\n",
    "        texts[nType] = {name: None for name in ti}\n",
    "        positions[nType] = {name: None for name in ti if ti[name][\"pos\"] is None}\n",
    "        recorders[nType] = {\n",
    "            name: Recorder(A.api) for name in ti if ti[name][\"pos\"] is None\n",
    "        }\n",
    "        accumulators[nType] = {name: [] for name in ti if ti[name][\"pos\"] is not None}\n",
    "\n",
    "    nChAbsent = 0\n",
    "\n",
    "    def addValue(node):\n",
    "        returnValue = None\n",
    "\n",
    "        nType = F.otype.v(node)\n",
    "        typeInfo = layerConfig[nType]\n",
    "        theseLayers = typeInfo.get(\"layers\", {})\n",
    "\n",
    "        first = True\n",
    "\n",
    "        pre = preSep[nType]\n",
    "        post = postSep[nType]\n",
    "\n",
    "        if nType == \"text\":\n",
    "            testText = []\n",
    "            testTexts.append((node, testText))\n",
    "        else:\n",
    "            testText = testTexts[-1][-1]\n",
    "\n",
    "        testText.append(f\"{pre} {node} [\")\n",
    "\n",
    "        for name in theseLayers:\n",
    "            info = theseLayers[name]\n",
    "            descend = info.get(\"descend\", False)\n",
    "            ascend = info.get(\"ascend\", False)\n",
    "            vMap = info[\"map\"]\n",
    "            default = info[\"default\"]\n",
    "            pos = info[\"pos\"]\n",
    "            if descend:\n",
    "                value = \"\"\n",
    "                for n in L.d(node, otype=descend):\n",
    "                    val = Fs(info[\"feature\"]).v(n)\n",
    "                    if vMap:\n",
    "                        val = vMap.get(val, default)\n",
    "                    else:\n",
    "                        val = val or default\n",
    "                    value += str(val)\n",
    "            else:\n",
    "                refNode = L.u(node, otype=ascend)[0] if ascend else node\n",
    "                value = Fs(info[\"feature\"]).v(refNode)\n",
    "                if vMap:\n",
    "                    value = vMap.get(value, default)\n",
    "                else:\n",
    "                    value = value or default\n",
    "                value = str(value)\n",
    "\n",
    "            if pos is None:\n",
    "                recorders[nType][name].add(value)\n",
    "            else:\n",
    "                accumulators[nType][name].append(value)\n",
    "\n",
    "            testText.append((\"\" if first else \"|\") + value)\n",
    "\n",
    "            if first:\n",
    "                returnValue = value\n",
    "                first = False\n",
    "\n",
    "        testText.append(f\"]{post}\")\n",
    "\n",
    "        return returnValue\n",
    "\n",
    "    def addAfterValue(node):\n",
    "        nType = F.otype.v(node)\n",
    "        typeInfo = layerConfig[nType]\n",
    "        afterFeature = typeInfo.get(\"afterFeature\", None)\n",
    "        afterDefault = typeInfo.get(\"afterDefault\", None)\n",
    "        value = \"\"\n",
    "        if afterFeature is not None:\n",
    "            value = Fs(afterFeature).v(node)\n",
    "        if afterDefault is not None:\n",
    "            if not value:\n",
    "                value = afterDefault\n",
    "        if value:\n",
    "            addAll(nType, value)\n",
    "\n",
    "    def addAll(nType, value):\n",
    "        lowerTypes = typesLower[nType]\n",
    "        for nType in lowerTypes:\n",
    "            if nType in recorders:\n",
    "                for x in recorders[nType].values():\n",
    "                    x.add(value)\n",
    "            if nType in accumulators:\n",
    "                for x in accumulators[nType].values():\n",
    "                    x.append(value)\n",
    "\n",
    "    def deliverAll():\n",
    "        for (nType, typeInfo) in recorders.items():\n",
    "            for (name, x) in typeInfo.items():\n",
    "                texts[nType][name] = x.text()\n",
    "                # here we are going to use that there is at most one node per node type\n",
    "                # that corresponds to a character position\n",
    "                positions[nType][name] = [\n",
    "                    tuple(nodes)[0] if nodes else None for nodes in x.positions()\n",
    "                ]\n",
    "\n",
    "        for (nType, typeInfo) in accumulators.items():\n",
    "            for (name, x) in typeInfo.items():\n",
    "                texts[nType][name] = \"\".join(x)\n",
    "\n",
    "    def startNode(node):\n",
    "        # we have organized recorders by node type\n",
    "        # we only record nodes of matching type in recorders\n",
    "\n",
    "        nType = F.otype.v(node)\n",
    "\n",
    "        if nType in recorders:\n",
    "            for rec in recorders[nType].values():\n",
    "                rec.start(node)\n",
    "\n",
    "    def endNode(node):\n",
    "        # we have organized recorders by node type\n",
    "        # we only record nodes of matching type in recorders\n",
    "        nType = F.otype.v(node)\n",
    "\n",
    "        if nType in recorders:\n",
    "            for rec in recorders[nType].values():\n",
    "                rec.end(node)\n",
    "\n",
    "    # note the `up[n] = m` statements below:\n",
    "    # we only let `up` connect nodes from one level to one level higher\n",
    "\n",
    "    for (i, text) in enumerate(F.otype.s(\"text\")):\n",
    "        startNode(text)\n",
    "        title = addValue(text)\n",
    "        sys.stdout.write(\"\\r\" + f\"{i + 1:>3} {title:<80}\")\n",
    "\n",
    "        for line in L.d(text, otype=\"line\"):\n",
    "            up[line] = text\n",
    "            startNode(line)\n",
    "            addValue(line)\n",
    "\n",
    "            for sent in L.d(line, otype=\"sentence\"):\n",
    "                up[sent] = line\n",
    "                startNode(sent)\n",
    "                addValue(sent)\n",
    "\n",
    "                for word in L.d(sent, otype=\"word\"):\n",
    "                    up[word] = sent\n",
    "                    startNode(word)\n",
    "                    addValue(word)\n",
    "\n",
    "                    if letterLevel:\n",
    "                        for letter in L.d(word, otype=\"letter\"):\n",
    "                            up[letter] = word\n",
    "                            startNode(letter)\n",
    "\n",
    "                            ch = addValue(letter)\n",
    "                            if ch == CH_ABSENT:\n",
    "                                nChAbsent += 1\n",
    "\n",
    "                            endNode(letter)\n",
    "                            addAfterValue(letter)\n",
    "\n",
    "                    endNode(word)\n",
    "                    addAfterValue(word)\n",
    "\n",
    "                endNode(sent)\n",
    "                addAfterValue(sent)\n",
    "\n",
    "            endNode(line)\n",
    "            addAfterValue(line)\n",
    "\n",
    "        endNode(text)\n",
    "        addAfterValue(text)\n",
    "\n",
    "    deliverAll()\n",
    "\n",
    "    sys.stdout.write(\"\\n\")\n",
    "\n",
    "    if letterLevel:\n",
    "        A.info(f\"{nChAbsent} letter nodes with empty full text\")\n",
    "\n",
    "    data = dict(\n",
    "        captions=dict(\n",
    "            title=\"NENA phono search\",\n",
    "        ),\n",
    "        ntypes=typeSeq,\n",
    "        dtypeOf={typeSeq[i + 1]: tp for (i, tp) in enumerate(typeSeq[0:-1])},\n",
    "        utypeOf={tp: typeSeq[i + 1] for (i, tp) in enumerate(typeSeq[0:-1])},\n",
    "        by=by,\n",
    "        show=show,\n",
    "        layers=layers,\n",
    "        texts=texts,\n",
    "        positions=positions,\n",
    "        up=compress(up),\n",
    "    )\n",
    "\n",
    "    return (data, testTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cosmetic-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumpData(data, testTexts, debug=False):\n",
    "    A.indent(reset=True)\n",
    "    A.info(\"Dumping data to a single compact json file\")\n",
    "\n",
    "    for d in (OUTPUT,) + ((TEST_TEXTS_DIR,) if debug else ()):\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d, exist_ok=True)\n",
    "    \n",
    "    fileName = f\"{OUTPUT}/corpus.js\"\n",
    "    \n",
    "    with open(fileName, \"w\") as fh:\n",
    "        fh.write(\"const corpus = \")\n",
    "        json.dump(data, fh, ensure_ascii=False, indent=None, separators=(',', ':'))\n",
    "        \n",
    "    A.info(f\"Data written to file {fileName}\")\n",
    "    \n",
    "    if debug:\n",
    "        A.info(f\"Writing same data as non-compact json file\")\n",
    "        fileName = f\"{DEBUG_OUTPUT}/corpus.js\"\n",
    "        with open(fileName, \"w\") as fh:\n",
    "            fh.write(\"const corpus = \")\n",
    "            json.dump(data, fh, ensure_ascii=False, indent=1)\n",
    "        A.info(f\"Data written to file {fileName}\")\n",
    "            \n",
    "        A.info(f\"Writing same data as separate, human readable files\")\n",
    "        for (kind, subData) in data.items():\n",
    "            if kind in {\"ntypes\", \"up\"}:\n",
    "                fileName = f\"{DEBUG_OUTPUT}/{kind}.tsv\"\n",
    "                A.info(fileName)\n",
    "                with open(fileName, \"w\") as fh:\n",
    "                    fh.write(\"\\n\".join(subData) + \"\\n\")\n",
    "                continue\n",
    "                \n",
    "            if kind in {\"captions\", \"by\", \"show\", \"utypeOf\", \"dtypeOf\"}:\n",
    "                fileName = f\"{DEBUG_OUTPUT}/{kind}.json\"\n",
    "                A.info(fileName)\n",
    "                with open(fileName, \"w\") as fh:\n",
    "                    json.dump(subData, fh, ensure_ascii=False, indent=1)\n",
    "                continue\n",
    "                \n",
    "            for (nType, typeData) in subData.items():\n",
    "                for (name, layerData) in typeData.items():\n",
    "                    ext = \"txt\" if kind == \"texts\" else \"tsv\" if kind == \"positions\" else \"json\"\n",
    "                    fileName = f\"{DEBUG_OUTPUT}/{kind}-{nType}-{name}.{ext}\"\n",
    "                    A.info(fileName)\n",
    "                    with open(fileName, \"w\") as fh:\n",
    "                        if ext == \"json\":\n",
    "                            json.dump(layerData, fh, ensure_ascii=False, indent=1)\n",
    "                        elif ext == \"tsv\":\n",
    "                            for entry in layerData:\n",
    "                                fh.write(f\"{entry}\\n\")\n",
    "                        else:\n",
    "                            fh.write(layerData)\n",
    "                            \n",
    "        for (node, testText) in testTexts:\n",
    "            fileName = f\"{TEST_TEXTS_DIR}/{node:>06}.txt\"\n",
    "\n",
    "            with open(fileName, \"w\") as fh:\n",
    "                fh.write(\"\".join(testText))\n",
    "        A.info(f\"Test texts written to directory {TEST_TEXTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ahead-rover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s preparing ... \n",
      "Making data based on letter-configNode type declared as result container ('by'):\n",
      "\tsentence\n",
      "Layers declared as result showers ('show'):\n",
      "\tletter/full, letter/cls, word/speaker, line/number, text/title, text/dialect\n",
      "  0.00s start recording\n",
      "126 Women Do Things Best                                                            \n",
      "    12s 18 letter nodes with empty full text\n"
     ]
    }
   ],
   "source": [
    "# kind = \"word\"\n",
    "kind = \"letter\"\n",
    "\n",
    "(data, testText) = record(kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "obvious-george",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Dumping data to a single compact json file\n",
      "  1.37s Data written to file ~/github/CambridgeSemiticsLab/nena_tf/nena2search/app/corpus.js\n",
      "  1.37s Writing same data as non-compact json file\n",
      "  2.77s Data written to file ~/github/CambridgeSemiticsLab/nena_tf/_local/corpus.js\n",
      "  2.77s Writing same data as separate, human readable files\n",
      "  2.77s ~/github/CambridgeSemiticsLab/nena_tf/_local/captions.json\n",
      "  2.77s ~/github/CambridgeSemiticsLab/nena_tf/_local/ntypes.tsv\n",
      "  2.77s ~/github/CambridgeSemiticsLab/nena_tf/_local/dtypeOf.json\n",
      "  2.77s ~/github/CambridgeSemiticsLab/nena_tf/_local/utypeOf.json\n",
      "  2.77s ~/github/CambridgeSemiticsLab/nena_tf/_local/by.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/show.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-letter-full.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-letter-cls.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-letter-voice.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-letter-place.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-letter-manner.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-word-lang.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-word-speaker.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-line-number.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-text-title.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-text-dialect.json\n",
      "  2.78s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-text-tid.json\n",
      "  2.79s ~/github/CambridgeSemiticsLab/nena_tf/_local/layers-text-place.json\n",
      "  2.79s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-letter-full.txt\n",
      "  2.79s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-letter-cls.txt\n",
      "  2.79s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-letter-voice.txt\n",
      "  2.80s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-letter-place.txt\n",
      "  2.80s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-letter-manner.txt\n",
      "  2.80s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-word-lang.txt\n",
      "  2.80s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-word-speaker.txt\n",
      "  2.81s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-line-number.txt\n",
      "  2.81s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-text-title.txt\n",
      "  2.81s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-text-dialect.txt\n",
      "  2.81s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-text-tid.txt\n",
      "  2.81s ~/github/CambridgeSemiticsLab/nena_tf/_local/texts-text-place.txt\n",
      "  2.81s ~/github/CambridgeSemiticsLab/nena_tf/_local/positions-letter-full.tsv\n",
      "  3.18s ~/github/CambridgeSemiticsLab/nena_tf/_local/positions-letter-cls.tsv\n",
      "  3.45s ~/github/CambridgeSemiticsLab/nena_tf/_local/positions-word-lang.tsv\n",
      "  3.56s ~/github/CambridgeSemiticsLab/nena_tf/_local/positions-word-speaker.tsv\n",
      "  3.68s ~/github/CambridgeSemiticsLab/nena_tf/_local/positions-line-number.tsv\n",
      "  3.68s ~/github/CambridgeSemiticsLab/nena_tf/_local/positions-text-title.tsv\n",
      "  3.68s ~/github/CambridgeSemiticsLab/nena_tf/_local/positions-text-dialect.tsv\n",
      "  3.68s ~/github/CambridgeSemiticsLab/nena_tf/_local/positions-text-tid.tsv\n",
      "  3.68s ~/github/CambridgeSemiticsLab/nena_tf/_local/positions-text-place.tsv\n",
      "  3.68s ~/github/CambridgeSemiticsLab/nena_tf/_local/up.tsv\n",
      "  3.86s Test texts written to directory ~/github/CambridgeSemiticsLab/nena_tf/_local/texts\n"
     ]
    }
   ],
   "source": [
    "dumpData(data, testText, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-submission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
