{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Character Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_lite = {\n",
    "    'ʾ': ')',\n",
    "    'ʿ': '(',\n",
    "    'c̭': 'c',\n",
    "    'č': '5',\n",
    "    'č̭': '5',\n",
    "    'č̣': '%',\n",
    "    'ḍ': 'D',\n",
    "    'ð': '6',\n",
    "    'ð̣': '^',\n",
    "    'ġ': 'G',\n",
    "    'ḥ': 'H',\n",
    "    'ɟ': '4',\n",
    "    'Ɉ': '4',\n",
    "    'k̭': '&',\n",
    "    'ḷ': 'L',\n",
    "    'ṃ': 'M',\n",
    "    'p̭': 'p',\n",
    "    'p̌': 'p',\n",
    "    'p̣': 'P',\n",
    "    'ṛ': 'R',\n",
    "    'ṣ': 'S',\n",
    "    'š': '$',\n",
    "    'ṱ': '<+>',\n",
    "    'ṭ': 'T',\n",
    "    'θ': '8',\n",
    "    'ž': '7',\n",
    "    'ẓ': 'Z',\n",
    "    'á': 'a',\n",
    "    'à': 'a',\n",
    "    'ā': 'a',\n",
    "    'ā̀': 'A',\n",
    "    'ā́': 'A',\n",
    "    'ă': '@',\n",
    "    'ắ': '@',\n",
    "    'ằ': '@',\n",
    "    'e': 'e',\n",
    "    'ē': 'E',\n",
    "    'ɛ': '3',\n",
    "    'i': 'i',\n",
    "    'ī': 'I',\n",
    "    'ĭ': '9',\n",
    "    'ə': '9',\n",
    "    'o': 'o',\n",
    "    'ō': 'O',\n",
    "    'u': 'u',\n",
    "    'ū': 'U',\n",
    "    'ŭ': '2',\n",
    "    'ı': 'i',\n",
    "    'ɑ': 'a',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "\n",
    "for char, trans in trans_lite.items():\n",
    "    char = unicodedata.normalize('NFC', char)\n",
    "    c_hex = '+'.join(hex(ord(c)) for c in char)\n",
    "    names = '+'.join(unicodedata.name(c) for c in char)\n",
    "    \n",
    "    table.append({\n",
    "        'chars': char,\n",
    "        'trans': trans,\n",
    "        'hexs': c_hex,\n",
    "        'names': names,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unicodedata.normalize('NFC', 'c̭'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trans_lite.tsv', 'w') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=table[0].keys(), delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialect-dependent Transcription\n",
    "\n",
    "We will prepare an ASCII transcription for the NENA dialects. Character transcriptions, however, can be different per dialect. This is because the semantic value of a consonant is dependent on its dialect. For instance, the character `q` in Barwar should be transcribed as a `k̭` in Christian Urmi. \n",
    "\n",
    "In the next section, we build up these consonant mappings by describing character sets, which consist of unicode codes and regex patterns. We can then map those sets in various ways depending on the dialects.\n",
    "\n",
    "The foundation of our transcription is the [*Comprehensive Aramaic Lexicon*](http://cal.huc.edu/) which is likewise used in the [Dukhrana database](https://www.dukhrana.com/lexicon/PayneSmith/). \n",
    "\n",
    "We will use [unicode literals](https://docs.python.org/3/howto/unicode.html#unicode-literals-in-python-source-code) for the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from pathlib import Path\n",
    "# char_table_dir = Path('/Users/cody/github/CambridgeSemiticsLab/nena_tf/char_tables/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # map ASCII universal transcription symbol\n",
    "# # to a colloquial name of the character\n",
    "# universal_transcription = {\n",
    "#     'consonants': {\n",
    "#         ')': '', \n",
    "#         'b': '', \n",
    "#         'g': '', \n",
    "#         'd': '', \n",
    "#         'D': '', \n",
    "#         'h': '', \n",
    "#         'w': '', \n",
    "#         'z': '', \n",
    "#         'x': '', \n",
    "#         'T': '', \n",
    "#         'y': '', \n",
    "#         'k': '',\n",
    "#         'l': '', \n",
    "#         'm': '', \n",
    "#         'n': '', \n",
    "#         's': '', \n",
    "#         '(': '', \n",
    "#         'p': '', \n",
    "#         'f': '', \n",
    "#         'S': '', \n",
    "#         'q': '', \n",
    "#         'r': '', \n",
    "#         '$': '',\n",
    "#         't': '',\n",
    "#         '&': '',\n",
    "#     },\n",
    "#     'vowels': {\n",
    "#         'a': 'a', \n",
    "#         'e': 'e', \n",
    "#         'i': 'i',\n",
    "#         'o': 'o', \n",
    "#         'u': 'u', \n",
    "#         'E': 'shewa', # ə\n",
    "        \n",
    "#         # get rid of?\n",
    "#         '1': 'dotless i', # ı\n",
    "#         '@': 'alpha',     # ɑ \n",
    "#         '3': 'open E',    # ɛ\n",
    "#     },\n",
    "#     'vowel_diacritics': {# e.g.\n",
    "#         '`': 'grave',     # à\n",
    "#         \"'\": 'acute',     # á\n",
    "#         '_': 'macron',    # ā\n",
    "#         '%': 'breve',     # ă\n",
    "#         '\"': 'diaeresis', # ä\n",
    "#         '~': 'tilde'      # ã\n",
    "#     },\n",
    "#     'consonant_diacritics': {   # e.g.\n",
    "#         '<': 'caron',             # x̌\n",
    "#         '^': 'circumflex',        # x̂\n",
    "#         ';': 'dot above',         # ẋ\n",
    "#         '.': 'dot below',         # x̣\n",
    "#         '>': 'circumflex below',  # x̭\n",
    "        \n",
    "#         # !! WHAT TO NAME +?\n",
    "#         '+': '',                  # ⁺x \n",
    "#     },\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_spreadsheets = collections.defaultdict(list)\n",
    "\n",
    "# for t_name, table in universal_transcription.items():\n",
    "#     for char, name in table.items():\n",
    "#         table_spreadsheets[t_name].append([char, name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t_name, data in table_spreadsheets.items():\n",
    "#     universal = char_table_dir.joinpath('universal')\n",
    "#     filename = universal.joinpath(t_name+'.tsv')\n",
    "#     with open(filename, 'w') as outfile:\n",
    "#         writer = csv.writer(outfile, delimiter='\\t')\n",
    "#         writer.writerow(['char', 'name'])\n",
    "#         writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # map universal characters to \n",
    "# # UTF8 instances\n",
    "\n",
    "# typical_vowels = {\n",
    "#     'a': 'a', \n",
    "#     'e': 'e',\n",
    "#     'i': 'i',\n",
    "#     'o': 'o',\n",
    "#     'u': 'u',\n",
    "#     '\\u0259': 'E', # shewa\n",
    "    \n",
    "#     # get rid of?\n",
    "#     '\\u0131': '1',  # dotless i\n",
    "#     '\\u0251': '@',  # alpha\n",
    "#     '\\u025B': '3',  # ɛ open e\n",
    "    \n",
    "# }\n",
    "# typical_accents = {\n",
    "#     '\\u0300': '`', # grave\n",
    "#     '\\u0301': \"'\", # acute\n",
    "#     '\\u0304': '_', # macron\n",
    "#     '\\u0306': '%', # breve\n",
    "#     '\\u0308': '\"', # diaeresis\n",
    "#     '\\u0303': '~', # tilde\n",
    "# }\n",
    "# typical_diacritics = {\n",
    "#     '\\u030C': '<', # caron\n",
    "#     '\\u0302': '^', # circumflex\n",
    "#     '\\u0307': ';', # dot above\n",
    "#     '\\u0323': '.', # dot below\n",
    "#     '\\u032D': '>', # circumflex below\n",
    "#     '\\u207A': '+', # plus for Urmi\n",
    "# }\n",
    "\n",
    "# # build mappings from UTF8 representation\n",
    "# # to universal transcription symbol\n",
    "# dialect_transcriptions = {\n",
    "#     'Barwar': {\n",
    "#         'consonants': {\n",
    "#             '\\u02be': ')', # aleph\n",
    "#             'b': 'b',\n",
    "#             'g': 'g', \n",
    "#             'd': 'd',\n",
    "#             '\\u00f0': 'D', # eth\n",
    "#             'h': 'h', \n",
    "#             'w': 'w', \n",
    "#             'z': 'z', \n",
    "#             'x': 'x', \n",
    "#             '\\u1e6d': 'T', # t with dot below\n",
    "#             'y': 'y', \n",
    "#             'k': 'k', \n",
    "#             'l': 'l', \n",
    "#             'm': 'm', \n",
    "#             'n': 'n', \n",
    "#             's': 's', \n",
    "#             '\\u02bf': '(', # ayin\n",
    "#             'p': 'p',\n",
    "#             'f': 'f',\n",
    "#             '\\u1e63': 'S', # s with dot below\n",
    "#             'q': 'q',\n",
    "#             'r': 'r',\n",
    "#             '\\u0161': '$', # s with caron\n",
    "#             't': 't',\n",
    "#             '\\u03b8': '&', # theta\n",
    "#             '\\u02b8': 'y', # small letter y (!CHECK THIS ONE!)\n",
    "#         },\n",
    "#         'vowels': \n",
    "#             typical_vowels,\n",
    "#         'consonant_diacritics': \n",
    "#             typical_diacritics,\n",
    "#         'vowel_diacritics': \n",
    "#             typical_accents,\n",
    "#     },\n",
    "#     'Urmi_C': {\n",
    "#         'consonants': {\n",
    "#             '\\u02be': ')', # aleph\n",
    "#             'b': 'b',\n",
    "#             '\\u025f': 'g', # ɟ\n",
    "#             '\\u0248': 'g', # Ɉ i.e. capital ɟ\n",
    "#             'd': 'd',\n",
    "#             # no ð\n",
    "#             'h': 'h', \n",
    "#             'w': 'w', \n",
    "#             'z': 'z', \n",
    "#             'x': 'x', \n",
    "#             '\\u1e71': 'T', # t with circumflex below\n",
    "#             'y': 'y', \n",
    "#             'k': 'k', \n",
    "#             'l': 'l', \n",
    "#             'm': 'm', \n",
    "#             'n': 'n', \n",
    "#             's': 's', \n",
    "#             # no ayin\n",
    "#             'p': 'p',\n",
    "#             'f': 'f',\n",
    "#             's': 'S', # !! NB THIS IS A PROBLEM IN URMI! See other s!\n",
    "#             'q': 'q',\n",
    "#             'r': 'r',\n",
    "#             '\\u0161': '$', # s with caron\n",
    "#             't': 't',\n",
    "#             # no theta\n",
    "#         },\n",
    "#         'vowels': \n",
    "#             typical_vowels,\n",
    "#         'consonant_diacritics': \n",
    "#             typical_diacritics,\n",
    "#         'vowel_diacritics': \n",
    "#             typical_accents,\n",
    "#     },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_spreadsheets = collections.defaultdict(list)\n",
    "# for dialect, table in dialect_transcriptions.items():\n",
    "#     for char, trans in table.items():\n",
    "#         table_spreadsheets[dialect].append([char, trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dialect, data in table_spreadsheets.items():\n",
    "#     dialect = char_table_dir.joinpath(dialect)\n",
    "#     filename = dialect.joinpath(t_name+'.tsv')\n",
    "#     with open(filename, 'w') as outfile:\n",
    "#         writer = csv.writer(outfile, delimiter='\\t')\n",
    "#         writer.writerow(['char', 'trans'])\n",
    "#         writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
