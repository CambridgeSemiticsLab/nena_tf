{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Christian Urmi and Barwar texts\n",
    "\n",
    "In order to work with the texts, it is useful to try and separate the NENA text from the metadata, such as titles, authors/informants, and verse numbers, and to structure it in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to text format\n",
    "\n",
    "The texts are available in MS-Word format. That can be converted to a computer readable text format with a tool like AbiWord:\n",
    "\n",
    "    # Convert Christian Urmi texts in \"cu vol 4 texts.doc\" to \"urmi_c.txt\"\n",
    "    $ abiword --to=txt \"cu vol 4 texts.doc\" --to-name=urmi_c.txt\n",
    "\n",
    "    # Convert Barwar texts in \"bar text *.doc\" to \"bar text *.txt\"\n",
    "    $ for i in bar\\ text*; do abiword --to=txt \"${i}\"; done\n",
    "    # combine Barwar texts in correct order in \"barwar.txt\"\n",
    "    $ ls -1d -- *.txt | sort -Vf | xargs -d \"\\n\" cat -- > barwar.txt\n",
    "\n",
    "The conversion does remove most of the formatting. Although the formatting is sometimes meaningful, such as superscript characters and symbols, the meaning can be mostly inferred from the characters themselves and their position in the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import in Python\n",
    "\n",
    "First, we need to import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining patterns and functions\n",
    "\n",
    "Then define a NamedTuple to conveniently store the structured text and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'id dialect title informant place text'\n",
    "\n",
    "Text = collections.namedtuple('Text', fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to structure the text files into meaningful elements, such as metadata (titles, authors/informants, places, verse numbers) and texts, verses, words, and other symbols, we have to recognize some patterns that are either present in the formatting of the Word files, or generated by the conversion to text by AbiWord.\n",
    "\n",
    "The patterns are different for the Barwar and Urmi texts. We use regular expressions to recognize the patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verse numbers are one or more digits in parentheses\n",
    "re_verse_no = re.compile('\\s*(\\([0-9]+\\))\\s*')\n",
    "\n",
    "# Footnotes start with a space after a newline,\n",
    "# and in our cases end with the first full stop.\n",
    "# If a footnote would contain more full stops,\n",
    "# I do not know how we could recognize the end.\n",
    "re_footnote = re.compile('^ [^.]*\\.')\n",
    "\n",
    "# Regexes for Barwar texts\n",
    "# Title contains identifier (e.g. 'A1') followed by\n",
    "# at least one TAB character, and the title.\n",
    "re_title = re.compile('^([ABCD][0-9]+) *[\\t]+(.*\\S)\\s*$')\n",
    "# The informant line starts with 'Informant: ', followed\n",
    "# by the informant name, and in parentheses the place.\n",
    "re_info = re.compile('^Informant: (.*) \\((.*)\\)\\s*$')\n",
    "\n",
    "# Regexes for Urmi texts\n",
    "# Heading only contains identifier (e.g. 'A 1' or 'B2').\n",
    "re_heading = re.compile('^([AB]\\s*[0-9]+)\\s*$')\n",
    "# title_info line contains Title, and in parentheses\n",
    "# the informant name followed by a comma, and the place\n",
    "re_title_info = re.compile('^(.*\\S)\\s*\\(([^,]*), (.*)\\)\\s*$')\n",
    "# Ignore other lines with only capitalized text and/or numbers\n",
    "re_ignore = re.compile('^[A-Z][A-Z0-9 ]+\\s*$')\n",
    "# Version regex is for a special case in Urmi text A35\n",
    "re_version = re.compile('^(Version [0-9]+): (.*) \\((.*)\\)\\s*$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_text()` reads the text files line by line, and tries to match the lines with the regular expressions. It returns a list of NamedTuple objects, and a list of lines that were ignored (such as front matter, empty lines or lines with one character, and footnotes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(filename, dialect, replace=None, ignore=None):\n",
    "    \"\"\"Read and structure NENA texts.\n",
    "    \n",
    "    Reads from filename, and structures the texts to fit in the fields\n",
    "    of the namedtuple Text.\n",
    "    Optimized for text files extracted from MS-Word files with Barwar\n",
    "    and Christian Urmi texts.\n",
    "    \"\"\"\n",
    "    \n",
    "    t_id = None\n",
    "    version = None\n",
    "    texts = []\n",
    "    ignored = []\n",
    "\n",
    "    with open(filename, 'r') as text_file:\n",
    "        for line in text_file:\n",
    "            \n",
    "            # ignore 'empty' lines of 1 character\n",
    "            empty = len(line.strip()) < 2\n",
    "            \n",
    "            # Normalize the characters: split combined characters such as 'á'\n",
    "            # into separate characters 'a' and combining acute accent\n",
    "            line = unicodedata.normalize('NFD', line)\n",
    "            \n",
    "            # these replace methods may not be the fastest solution\n",
    "            if replace is not None:\n",
    "                for c in replace:\n",
    "                    line = line.replace(c, replace[c])\n",
    "            \n",
    "            if ignore is not None:\n",
    "                for c in ignore:\n",
    "                    line = line.replace(c, '')\n",
    "            \n",
    "            title_line = re_title.match(line)\n",
    "            heading_line = re_heading.match(line)\n",
    "            if title_line or heading_line:\n",
    "                if t_id:\n",
    "                    text, ignored_v = split_verses(text)\n",
    "                    ignored.extend(ignored_v)\n",
    "                    texts.append(Text(t_id, dialect, title, informant, place, text))\n",
    "                if title_line:\n",
    "                    t_id, title = title_line.groups()\n",
    "                elif heading_line:\n",
    "                    t_id = ''.join(heading_line.group(1).split()) # remove space in 'A 1'\n",
    "                    title = None\n",
    "                informant = None\n",
    "                place = None\n",
    "                text = []\n",
    "                continue\n",
    "\n",
    "            # Version is special case for Urmi A35\n",
    "            # Version line also matches re_title_info, so must be checked before\n",
    "            # Title has been added to text list\n",
    "            version_line = re_version.match(line)\n",
    "            if version_line:\n",
    "                version, v_informant, v_place = version_line.groups()\n",
    "                if len([e for e in text if e.strip()]) == 1:\n",
    "                    title = text[0].strip()\n",
    "                    text = []\n",
    "                text.append(version)\n",
    "                \n",
    "                if informant is not None:\n",
    "                    informant += '; {}: {}'.format(version, v_informant)\n",
    "                else:\n",
    "                    informant = '{}: {}'.format(version, v_informant)\n",
    "                if place is not None:\n",
    "                    place += '; {}: {}'.format(version, v_place)\n",
    "                else:\n",
    "                    place = '{}: {}'.format(version, v_place)\n",
    "                continue\n",
    "            \n",
    "            informant_line = re_info.match(line)\n",
    "            title_info_line = re_title_info.match(line)\n",
    "            if t_id and informant is None and (informant_line or title_info_line):\n",
    "                if informant_line:\n",
    "                    informant, place = informant_line.groups()\n",
    "                elif title_info_line:\n",
    "                    title, informant, place = title_info_line.groups()\n",
    "                continue\n",
    "            \n",
    "            # if no heading/title has yet been encountered,\n",
    "            # line is part of front matter, so ignore\n",
    "            if t_id is None:\n",
    "                ignored.append(line)\n",
    "                continue\n",
    "            \n",
    "            # if line does not match heading/title\n",
    "            if re_ignore.match(line):\n",
    "                ignored.append(line)\n",
    "                continue\n",
    "            \n",
    "            # footnotes are replaced by newline(s), followed by\n",
    "            # the footnote text preceded by a space.\n",
    "            # Ignore footnote and preceding newlines\n",
    "            # TODO: store footnote and its location somewhere?\n",
    "            footnote = re_footnote.match(line)\n",
    "            if footnote:\n",
    "                ignored.append(footnote.group())\n",
    "                line = re_footnote.sub('', line)\n",
    "                while text and text[-1].strip() == '':\n",
    "                    ignored.append(text.pop())\n",
    "                \n",
    "            if text or not empty:\n",
    "                text.append(line)\n",
    "            elif empty: # empty line after title or informant lines\n",
    "                ignored.append(line)\n",
    "                pass\n",
    "\n",
    "        # add last text\n",
    "        text, ignored_v = split_verses(text)\n",
    "        ignored.extend(ignored_v)\n",
    "        \n",
    "        texts.append(Text(t_id, dialect, title, informant, place, text))\n",
    "    \n",
    "    return (texts, ignored)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `split_verses()` splits the text into verses, starting with the verse number in parentheses. It keeps all characters such as whitespace and newlines (except the trailing whitespace/newlines at the end of the text), so that special formatting, such as for poetry, is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_verses(text):\n",
    "    \"\"\"Split text into verses.\n",
    "    \n",
    "    Verses are marked by a verse number in parentheses.\n",
    "    Returns a list of tuples: (verse_no, verse_text)\n",
    "    \"\"\"\n",
    "    \n",
    "    ignored = []\n",
    "    \n",
    "    # strip empty lines and lines with only one character from end of text\n",
    "    # (single characters are sometimes appended by abiword to end of file)\n",
    "    while len(text[-1].strip()) < 2:\n",
    "        ignored.append(text.pop())\n",
    "\n",
    "    verses = []\n",
    "    cur_verse = []\n",
    "    verse_no = ''\n",
    "    \n",
    "    for string in text:\n",
    "        for e in re_verse_no.split(string):\n",
    "            if cur_verse and cur_verse[-1].startswith('Version'):\n",
    "                if not e.strip():\n",
    "                    ignored.append(e)\n",
    "                    continue # ignore newlines after 'Version', it will be added\n",
    "            if re_verse_no.match(e):\n",
    "                if cur_verse and cur_verse[-1].startswith('Version'):\n",
    "                    e = '{}:\\n\\n{}'.format(cur_verse.pop(), e)\n",
    "                if verse_no and cur_verse:\n",
    "                    verses.append((verse_no, ''.join(cur_verse)))\n",
    "                    cur_verse = []\n",
    "                verse_no = e\n",
    "            elif e:\n",
    "                cur_verse.append(e)\n",
    "    \n",
    "    # from last verse in text, strip trailing whitespace\n",
    "    verses.append((verse_no, ''.join(cur_verse).rstrip()))\n",
    "    \n",
    "    return verses, ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the text of the verses into words, we need to be able to find word boundaries. Splitting on spaces is not enough, since some words are prefixed or suffixed to other words by means of hyphens. In some cases the space is omitted apparently accidentally, but the word boundary is indicated by stress markers that occur only at the beginning or end of words. In all cases, we want to keep the boundary markers (spaces, hyphens, or other) because they may be useful in later analysis.\n",
    "\n",
    "This cannot be done with `str.split()`, and also not (easily) with `re.split()`, so we use a special function `split_words()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(s, split_after=None, split_before=None):\n",
    "    \"\"\"Split string s into words while keeping delimiters.\n",
    "    \n",
    "    Splits the string on the delimiters given in split_after\n",
    "    and split_before, while not removing the delimiters.\n",
    "    The delimiters in split_after are appended to the preceding\n",
    "    string, those in split_before to the following string (if\n",
    "    any).\n",
    "    If both delimiters are None or empty strings, a normal\n",
    "    str.split() is returned.\n",
    "    \n",
    "    >>> string = 'this-here is- just\\na=test=\\n'\n",
    "    >>> split_after = ' -\\n'  # space, hyphen, newline\n",
    "    >>> split_before = '='  # equals sign\n",
    "    >>> split_words(string, split_after, split_before)\n",
    "    ['this-', 'here ', 'is- ', 'just\\n', 'a', '=test=\\n']\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Another way could be using re.split, but without after_chars.\n",
    "    # Example splitting on space and hyphen:\n",
    "    # (adapted from https://stackoverflow.com/a/7866863/9230612)\n",
    "    #\n",
    "    # >>> re.split(\"([^ -]+[ -]?)\", \"my first- test-string\")[1::2]\n",
    "    # ['my ', 'first-', 'test-', 'string']\n",
    "    #\n",
    "    # but that does not keep all characters (space after hyphen is lost).\n",
    "    \n",
    "    split_after = '' if split_after is None else split_after\n",
    "    split_before = '' if split_before is None else split_before\n",
    "\n",
    "    delimiters = split_after + split_before\n",
    "    \n",
    "    if not delimiters:\n",
    "        return s.split()\n",
    "    \n",
    "    result = []\n",
    "    start = 0\n",
    "    pos = 0\n",
    "    \n",
    "    while pos < len(s):\n",
    "        if pos > start and s[pos-1] in delimiters and s[pos] not in delimiters:\n",
    "            if s[pos-1] in split_after:\n",
    "                result.append(s[start:pos])\n",
    "                start = pos\n",
    "            else: # s[pos-1] in split_before:\n",
    "                i = 1\n",
    "                while pos-i > start and s[pos-i-1] in split_before:\n",
    "                    i += 1\n",
    "                if pos-i > start:\n",
    "                    result.append(s[start:pos-i])\n",
    "                start = pos-i\n",
    "        # UGLY HACK to split words not playing by the rules:\n",
    "        # words following vertical line or ellipsis marks without spaces\n",
    "        elif (pos > start and s[pos].isalpha()\n",
    "              and (s[pos-1] in '|…' or (pos > start-1 and s[pos-2:pos]) == '..')):\n",
    "            result.append(s[start:pos])\n",
    "            start = pos\n",
    "        pos += 1\n",
    "    result.append(s[start:])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the texts\n",
    "\n",
    "Assuming that the text files that were generated earlier, `barwar.txt` and `urmi_c.txt`, are present in the current directory, we can now import them. For convenience we also combine them in a list containing all texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "barwar_texts, ignored_b = get_texts('barwar.txt', 'Barwar')\n",
    "\n",
    "urmi_texts, ignored_u = get_texts('urmi_c.txt', 'Urmi_C')\n",
    "\n",
    "ignored = ignored_b + ignored_u # to allow for inspection of ignored text\n",
    "\n",
    "alltexts = barwar_texts + urmi_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "Now that we have all texts separated from the metadata and structured into verses, we can start counting all kinds of things.\n",
    "\n",
    "For example, we can count all characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = collections.Counter()\n",
    "\n",
    "for t in alltexts:\n",
    "    for v, verse in t.text:\n",
    "        for c in verse:\n",
    "            cnt[c] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pandas DataFrame to display the resulting counts, sorted first by Unicode category, and then by character value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>character</th>\n",
       "      <th>count</th>\n",
       "      <th>hex codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc</td>\n",
       "      <td>\\n</td>\n",
       "      <td>397</td>\n",
       "      <td>0xa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc</td>\n",
       "      <td></td>\n",
       "      <td>7256</td>\n",
       "      <td>0x1e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Cf</td>\n",
       "      <td>‎</td>\n",
       "      <td>1</td>\n",
       "      <td>0x200e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Cf</td>\n",
       "      <td>‮</td>\n",
       "      <td>1</td>\n",
       "      <td>0x202e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Co</td>\n",
       "      <td></td>\n",
       "      <td>1100</td>\n",
       "      <td>0xf1ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ll</td>\n",
       "      <td>a</td>\n",
       "      <td>108660</td>\n",
       "      <td>0x61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ll</td>\n",
       "      <td>b</td>\n",
       "      <td>14437</td>\n",
       "      <td>0x62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ll</td>\n",
       "      <td>c</td>\n",
       "      <td>5986</td>\n",
       "      <td>0x63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ll</td>\n",
       "      <td>d</td>\n",
       "      <td>13208</td>\n",
       "      <td>0x64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ll</td>\n",
       "      <td>e</td>\n",
       "      <td>18801</td>\n",
       "      <td>0x65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ll</td>\n",
       "      <td>f</td>\n",
       "      <td>326</td>\n",
       "      <td>0x66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ll</td>\n",
       "      <td>g</td>\n",
       "      <td>2573</td>\n",
       "      <td>0x67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ll</td>\n",
       "      <td>h</td>\n",
       "      <td>4510</td>\n",
       "      <td>0x68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Ll</td>\n",
       "      <td>i</td>\n",
       "      <td>25237</td>\n",
       "      <td>0x69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Ll</td>\n",
       "      <td>j</td>\n",
       "      <td>1409</td>\n",
       "      <td>0x6a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ll</td>\n",
       "      <td>k</td>\n",
       "      <td>8759</td>\n",
       "      <td>0x6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Ll</td>\n",
       "      <td>l</td>\n",
       "      <td>39211</td>\n",
       "      <td>0x6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Ll</td>\n",
       "      <td>m</td>\n",
       "      <td>25753</td>\n",
       "      <td>0x6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Ll</td>\n",
       "      <td>n</td>\n",
       "      <td>26517</td>\n",
       "      <td>0x6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Ll</td>\n",
       "      <td>o</td>\n",
       "      <td>7617</td>\n",
       "      <td>0x6f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Ll</td>\n",
       "      <td>p</td>\n",
       "      <td>5841</td>\n",
       "      <td>0x70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ll</td>\n",
       "      <td>q</td>\n",
       "      <td>4102</td>\n",
       "      <td>0x71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Ll</td>\n",
       "      <td>r</td>\n",
       "      <td>23976</td>\n",
       "      <td>0x72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Ll</td>\n",
       "      <td>s</td>\n",
       "      <td>16055</td>\n",
       "      <td>0x73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Ll</td>\n",
       "      <td>t</td>\n",
       "      <td>29345</td>\n",
       "      <td>0x74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Ll</td>\n",
       "      <td>u</td>\n",
       "      <td>21268</td>\n",
       "      <td>0x75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Ll</td>\n",
       "      <td>v</td>\n",
       "      <td>9058</td>\n",
       "      <td>0x76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Ll</td>\n",
       "      <td>w</td>\n",
       "      <td>6186</td>\n",
       "      <td>0x77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Ll</td>\n",
       "      <td>x</td>\n",
       "      <td>20574</td>\n",
       "      <td>0x78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Ll</td>\n",
       "      <td>y</td>\n",
       "      <td>18677</td>\n",
       "      <td>0x79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Ll</td>\n",
       "      <td>z</td>\n",
       "      <td>5393</td>\n",
       "      <td>0x7a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ð</td>\n",
       "      <td>1381</td>\n",
       "      <td>0xf0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ı</td>\n",
       "      <td>9</td>\n",
       "      <td>0x131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ǝ</td>\n",
       "      <td>3354</td>\n",
       "      <td>0x1dd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ɑ</td>\n",
       "      <td>96</td>\n",
       "      <td>0x251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ə</td>\n",
       "      <td>38573</td>\n",
       "      <td>0x259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ɛ</td>\n",
       "      <td>4434</td>\n",
       "      <td>0x25b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ɟ</td>\n",
       "      <td>3028</td>\n",
       "      <td>0x25f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Ll</td>\n",
       "      <td>θ</td>\n",
       "      <td>3615</td>\n",
       "      <td>0x3b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Lm</td>\n",
       "      <td>ʾ</td>\n",
       "      <td>19345</td>\n",
       "      <td>0x2be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Lm</td>\n",
       "      <td>ʿ</td>\n",
       "      <td>192</td>\n",
       "      <td>0x2bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lu</td>\n",
       "      <td>A</td>\n",
       "      <td>273</td>\n",
       "      <td>0x41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lu</td>\n",
       "      <td>B</td>\n",
       "      <td>196</td>\n",
       "      <td>0x42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lu</td>\n",
       "      <td>C</td>\n",
       "      <td>78</td>\n",
       "      <td>0x43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lu</td>\n",
       "      <td>D</td>\n",
       "      <td>45</td>\n",
       "      <td>0x44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lu</td>\n",
       "      <td>E</td>\n",
       "      <td>154</td>\n",
       "      <td>0x45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lu</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>0x46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lu</td>\n",
       "      <td>G</td>\n",
       "      <td>81</td>\n",
       "      <td>0x47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lu</td>\n",
       "      <td>H</td>\n",
       "      <td>118</td>\n",
       "      <td>0x48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lu</td>\n",
       "      <td>I</td>\n",
       "      <td>60</td>\n",
       "      <td>0x49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lu</td>\n",
       "      <td>J</td>\n",
       "      <td>23</td>\n",
       "      <td>0x4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lu</td>\n",
       "      <td>K</td>\n",
       "      <td>70</td>\n",
       "      <td>0x4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lu</td>\n",
       "      <td>L</td>\n",
       "      <td>37</td>\n",
       "      <td>0x4c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lu</td>\n",
       "      <td>M</td>\n",
       "      <td>173</td>\n",
       "      <td>0x4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lu</td>\n",
       "      <td>N</td>\n",
       "      <td>154</td>\n",
       "      <td>0x4e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lu</td>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "      <td>0x4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lu</td>\n",
       "      <td>P</td>\n",
       "      <td>236</td>\n",
       "      <td>0x50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lu</td>\n",
       "      <td>Q</td>\n",
       "      <td>79</td>\n",
       "      <td>0x51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Lu</td>\n",
       "      <td>R</td>\n",
       "      <td>394</td>\n",
       "      <td>0x52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lu</td>\n",
       "      <td>S</td>\n",
       "      <td>158</td>\n",
       "      <td>0x53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Lu</td>\n",
       "      <td>T</td>\n",
       "      <td>86</td>\n",
       "      <td>0x54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Lu</td>\n",
       "      <td>U</td>\n",
       "      <td>98</td>\n",
       "      <td>0x55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lu</td>\n",
       "      <td>V</td>\n",
       "      <td>10</td>\n",
       "      <td>0x56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lu</td>\n",
       "      <td>W</td>\n",
       "      <td>15</td>\n",
       "      <td>0x57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Lu</td>\n",
       "      <td>X</td>\n",
       "      <td>48</td>\n",
       "      <td>0x58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lu</td>\n",
       "      <td>Y</td>\n",
       "      <td>34</td>\n",
       "      <td>0x59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lu</td>\n",
       "      <td>Z</td>\n",
       "      <td>135</td>\n",
       "      <td>0x5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̀</td>\n",
       "      <td>36346</td>\n",
       "      <td>0x300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Mn</td>\n",
       "      <td>́</td>\n",
       "      <td>56797</td>\n",
       "      <td>0x301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̂</td>\n",
       "      <td>562</td>\n",
       "      <td>0x302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̃</td>\n",
       "      <td>1</td>\n",
       "      <td>0x303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̄</td>\n",
       "      <td>1682</td>\n",
       "      <td>0x304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̆</td>\n",
       "      <td>1605</td>\n",
       "      <td>0x306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̇</td>\n",
       "      <td>270</td>\n",
       "      <td>0x307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̈</td>\n",
       "      <td>14</td>\n",
       "      <td>0x308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̌</td>\n",
       "      <td>11127</td>\n",
       "      <td>0x30c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̣</td>\n",
       "      <td>4461</td>\n",
       "      <td>0x323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̭</td>\n",
       "      <td>10110</td>\n",
       "      <td>0x32d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̵</td>\n",
       "      <td>2</td>\n",
       "      <td>0x335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̶</td>\n",
       "      <td>1</td>\n",
       "      <td>0x336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pd</td>\n",
       "      <td>-</td>\n",
       "      <td>18025</td>\n",
       "      <td>0x2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Pd</td>\n",
       "      <td>—</td>\n",
       "      <td>27</td>\n",
       "      <td>0x2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pe</td>\n",
       "      <td>)</td>\n",
       "      <td>5</td>\n",
       "      <td>0x29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pe</td>\n",
       "      <td>]</td>\n",
       "      <td>28</td>\n",
       "      <td>0x5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Po</td>\n",
       "      <td>!</td>\n",
       "      <td>560</td>\n",
       "      <td>0x21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Po</td>\n",
       "      <td>,</td>\n",
       "      <td>7761</td>\n",
       "      <td>0x2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Po</td>\n",
       "      <td>.</td>\n",
       "      <td>14648</td>\n",
       "      <td>0x2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Po</td>\n",
       "      <td>:</td>\n",
       "      <td>73</td>\n",
       "      <td>0x3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Po</td>\n",
       "      <td>;</td>\n",
       "      <td>1</td>\n",
       "      <td>0x3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Po</td>\n",
       "      <td>?</td>\n",
       "      <td>1686</td>\n",
       "      <td>0x3f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Po</td>\n",
       "      <td>…</td>\n",
       "      <td>181</td>\n",
       "      <td>0x2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ps</td>\n",
       "      <td>(</td>\n",
       "      <td>5</td>\n",
       "      <td>0x28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ps</td>\n",
       "      <td>[</td>\n",
       "      <td>28</td>\n",
       "      <td>0x5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sm</td>\n",
       "      <td>+</td>\n",
       "      <td>11633</td>\n",
       "      <td>0x2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Sm</td>\n",
       "      <td>|</td>\n",
       "      <td>35931</td>\n",
       "      <td>0x7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zs</td>\n",
       "      <td></td>\n",
       "      <td>91764</td>\n",
       "      <td>0x20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category character   count hex codes\n",
       "0        Cc        \\n     397       0xa\n",
       "1        Cc         \n",
       "    7256      0x1e\n",
       "91       Cf         ‎       1    0x200e\n",
       "94       Cf         ‮       1    0x202e\n",
       "95       Co             1100    0xf1ea\n",
       "41       Ll         a  108660      0x61\n",
       "42       Ll         b   14437      0x62\n",
       "43       Ll         c    5986      0x63\n",
       "44       Ll         d   13208      0x64\n",
       "45       Ll         e   18801      0x65\n",
       "46       Ll         f     326      0x66\n",
       "47       Ll         g    2573      0x67\n",
       "48       Ll         h    4510      0x68\n",
       "49       Ll         i   25237      0x69\n",
       "50       Ll         j    1409      0x6a\n",
       "51       Ll         k    8759      0x6b\n",
       "52       Ll         l   39211      0x6c\n",
       "53       Ll         m   25753      0x6d\n",
       "54       Ll         n   26517      0x6e\n",
       "55       Ll         o    7617      0x6f\n",
       "56       Ll         p    5841      0x70\n",
       "57       Ll         q    4102      0x71\n",
       "58       Ll         r   23976      0x72\n",
       "59       Ll         s   16055      0x73\n",
       "60       Ll         t   29345      0x74\n",
       "61       Ll         u   21268      0x75\n",
       "62       Ll         v    9058      0x76\n",
       "63       Ll         w    6186      0x77\n",
       "64       Ll         x   20574      0x78\n",
       "65       Ll         y   18677      0x79\n",
       "66       Ll         z    5393      0x7a\n",
       "68       Ll         ð    1381      0xf0\n",
       "69       Ll         ı       9     0x131\n",
       "70       Ll         ǝ    3354     0x1dd\n",
       "71       Ll         ɑ      96     0x251\n",
       "72       Ll         ə   38573     0x259\n",
       "73       Ll         ɛ    4434     0x25b\n",
       "74       Ll         ɟ    3028     0x25f\n",
       "90       Ll         θ    3615     0x3b8\n",
       "75       Lm         ʾ   19345     0x2be\n",
       "76       Lm         ʿ     192     0x2bf\n",
       "13       Lu         A     273      0x41\n",
       "14       Lu         B     196      0x42\n",
       "15       Lu         C      78      0x43\n",
       "16       Lu         D      45      0x44\n",
       "17       Lu         E     154      0x45\n",
       "18       Lu         F      39      0x46\n",
       "19       Lu         G      81      0x47\n",
       "20       Lu         H     118      0x48\n",
       "21       Lu         I      60      0x49\n",
       "22       Lu         J      23      0x4a\n",
       "23       Lu         K      70      0x4b\n",
       "24       Lu         L      37      0x4c\n",
       "25       Lu         M     173      0x4d\n",
       "26       Lu         N     154      0x4e\n",
       "27       Lu         O      12      0x4f\n",
       "28       Lu         P     236      0x50\n",
       "29       Lu         Q      79      0x51\n",
       "30       Lu         R     394      0x52\n",
       "31       Lu         S     158      0x53\n",
       "32       Lu         T      86      0x54\n",
       "33       Lu         U      98      0x55\n",
       "34       Lu         V      10      0x56\n",
       "35       Lu         W      15      0x57\n",
       "36       Lu         X      48      0x58\n",
       "37       Lu         Y      34      0x59\n",
       "38       Lu         Z     135      0x5a\n",
       "77       Mn         ̀   36346     0x300\n",
       "78       Mn         ́   56797     0x301\n",
       "79       Mn         ̂     562     0x302\n",
       "80       Mn         ̃       1     0x303\n",
       "81       Mn         ̄    1682     0x304\n",
       "82       Mn         ̆    1605     0x306\n",
       "83       Mn         ̇     270     0x307\n",
       "84       Mn         ̈      14     0x308\n",
       "85       Mn         ̌   11127     0x30c\n",
       "86       Mn         ̣    4461     0x323\n",
       "87       Mn         ̭   10110     0x32d\n",
       "88       Mn         ̵       2     0x335\n",
       "89       Mn         ̶       1     0x336\n",
       "8        Pd         -   18025      0x2d\n",
       "92       Pd         —      27    0x2014\n",
       "5        Pe         )       5      0x29\n",
       "40       Pe         ]      28      0x5d\n",
       "3        Po         !     560      0x21\n",
       "7        Po         ,    7761      0x2c\n",
       "9        Po         .   14648      0x2e\n",
       "10       Po         :      73      0x3a\n",
       "11       Po         ;       1      0x3b\n",
       "12       Po         ?    1686      0x3f\n",
       "93       Po         …     181    0x2026\n",
       "4        Ps         (       5      0x28\n",
       "39       Ps         [      28      0x5b\n",
       "6        Sm         +   11633      0x2b\n",
       "67       Sm         |   35931      0x7c\n",
       "2        Zs             91764      0x20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# make pandas not truncate the table rows\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "data = []\n",
    "for c in sorted(cnt):\n",
    "    data.append({'character': c,\n",
    "                 'count': cnt[c],\n",
    "                 'category': unicodedata.category(c[0]),\n",
    "                 'hex codes': ' '.join([hex(ord(e)) for e in c])})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.sort_values(['category', 'character'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us all the Unicode codepoints occurring in the text. Most are letters (Unicode categories 'Ll', 'Lu', and 'Lm') or combining diacritic symbols (category 'Mn'). Others are punctuation ('Pd', 'Po') or brackets/parentheses ('Ps', 'Pe'), or symbols ('Sm'). There is also white space: space (category 'Zs') and newline ('\\n', category 'Cc').\n",
    "\n",
    "### Problematic characters\n",
    "\n",
    "Since the texts were composed in Word to be read by humans, some inconsistencies in the character encoding that are invisable for humans can confuse automatic analysis. We will look at some problematic characters that are found using the table above.\n",
    "\n",
    "In category 'Cc', the character with the hexadecimal number 0x1e is a control character named U+001E 'INFORMATION SEPARATOR TWO'. It is (for some reason?) converted by AbiWord from the character shown in Word as U+2011 'NON-BREAKING HYPHEN', and seems to have the same function as the regular U+002D 'HYPHEN-MINUS'.\n",
    "\n",
    "In category 'Cf' are two characters 0x200e and 0x202e, which are invisible control characters to change the text direction, but have no meaning in our text and should be ignored.\n",
    "\n",
    "The category 'Co' is the 'Private use area' of Unicode. The character 0xf1ea is a [deprecated SIL character](https://scripts.sil.org/cms/scripts/page.php?site_id=nrsi&id=PUA_Deprecated), which looks like a short equals sign or a double hyphen and is apparently used to connect suffixed forms to the end of a word. It can be replaced by the valid Unicode character U+2E40 'DOUBLE HYPHEN'.\n",
    "\n",
    "Under letters are two symbols that look the same: U+01DD 'LATIN SMALL LETTER TURNED E' and U+0259 'LATIN SMALL LETTER SCHWA'. Assuming that they represent the same character, the 'turned e' can be replaced by the 'schwa'.\n",
    "\n",
    "In category 'Mn' are two combining strokes, a short and a long one. Inspection of the text shows that they are both combined with the capital J, apparently to form an uppercase counterpart for 'ɟ': U+025F 'LATIN SMALL LETTER DOTLESS J WITH STROKE'. The three occurrences could be replaced by the Unicode character 'Ɉ': U+0248 'LATIN CAPITAL LETTER J WITH STROKE' (which also does have an official lowercase variant, 'ɉ' U+0249 'LATIN SMALL LETTER J WITH STROKE', but that one has a dot).\n",
    "\n",
    "The three dots of '…' U+2026 'HORIZONTAL ELLIPSIS' represent three dots and are likely automatically replaced by Word, so they can be replaced back by three dots '...'.\n",
    "\n",
    "The 't' and the combining diacritic U+032d '̭' 'COMBINING CIRCUMFLEX ACCENT BELOW' are in some cases separated by a hyphen (t-̭). Word processors apparently still render this as intended, with the circumflex below the ṱ, but when separating words on hyphens, the circumflex ends up at the beginning of the following word, so the hyphen and the circumflex must switch positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to replace or remove the problematic characters, we define a tuple for the characters to ignore, and a dictionary for the characters to replace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define characters to be ignored (RtL markers)\n",
    "ignore = ('\\u200e', '\\u202e')\n",
    "\n",
    "# define characters to be replaced\n",
    "replace = {\n",
    "    # In MS Word, this is U+2011 'NON-BREAKING HYPHEN'.\n",
    "    # Somehow in conversion to text, AbiWord converts it to\n",
    "    # U+001E 'INFORMATION SEPARATOR TWO' (record separator).\n",
    "    # Replaced by regular U+002D 'HYPHEN-MINUS'\n",
    "    '\\u001e': '\\u002d',\n",
    "    # U+01DD 'LATIN SMALL LETTER TURNED E'\n",
    "    # replaced by U+0259 'LATIN SMALL LETTER SCHWA' (looks the same).\n",
    "    '\\u01dd': '\\u0259',\n",
    "    # Deprecated SIL character U+F1EA 'MODIFIER LETTER SHORT EQUALS SIGN'\n",
    "    # (https://scripts.sil.org/cms/scripts/page.php?site_id=nrsi&id=PUA_Deprecated)\n",
    "    # replaced by U+2E40 'DOUBLE HYPHEN'\n",
    "    '\\uf1ea': '\\u2e40',\n",
    "    # U+2026 '…' HORIZONTAL ELLIPSIS\n",
    "    # replaced by three dots\n",
    "    '\\u2026': '...',\n",
    "        \n",
    "    # digraph 'J' LATIN CAPITAL LETTER J and \n",
    "    # U+0335 '̵' COMBINING SHORT STROKE OVERLAY or\n",
    "    # U+0336 '̶' COMBINING LONG STROKE OVERLAY:\n",
    "    # represents U+0248 'Ɉ' LATIN CAPITAL LETTER J WITH STROKE?\n",
    "    # (capital equivalent of:\n",
    "    # U+025f 'ɟ' LATIN SMALL LETTER DOTLESS J WITH STROKE?)\n",
    "    # occurs 3x:\n",
    "    # Urmi_C B1 The Assyrians of Urmi 20 (p.238): ... J̶avìlan ... # (long stroke overlay)\n",
    "    # Urmi_C B7 Village Life 15 (p.288): ... mən-J̵avìlan ... # (short stroke overlay)\n",
    "    # Urmi_C B17 Village Life 40 (p.344): ... ɟu-J̵úrjəs-+tan| ... # (short stroke overlay)\n",
    "    'J\\u0335': '\\u0248',\n",
    "    'J\\u0336': '\\u0248',\n",
    "    \n",
    "    # Hyphen and circumflex accent below must switch positions\n",
    "    '\\u002d\\u032d': '\\u032d\\u002d',\n",
    "    # also '\\u001e', since in an unordered dictionary,\n",
    "    # it is unknown which substitution will take place first\n",
    "    '\\u001e\\u032d': '\\u032d\\u002d',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the characters to be ignored or replaced known, we can now re-read the texts, and generate a cleaner table of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "barwar_texts, ignored_b = get_texts('barwar.txt', 'Barwar', replace=replace, ignore=ignore)\n",
    "\n",
    "urmi_texts, ignored_u = get_texts('urmi_c.txt', 'Urmi_C', replace=replace, ignore=ignore)\n",
    "\n",
    "ignored = ignored_b + ignored_u # to allow for inspection of ignored text\n",
    "\n",
    "alltexts = barwar_texts + urmi_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>character</th>\n",
       "      <th>count</th>\n",
       "      <th>hex codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc</td>\n",
       "      <td>\\n</td>\n",
       "      <td>397</td>\n",
       "      <td>0xa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ll</td>\n",
       "      <td>a</td>\n",
       "      <td>108660</td>\n",
       "      <td>0x61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ll</td>\n",
       "      <td>b</td>\n",
       "      <td>14437</td>\n",
       "      <td>0x62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ll</td>\n",
       "      <td>c</td>\n",
       "      <td>5986</td>\n",
       "      <td>0x63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ll</td>\n",
       "      <td>d</td>\n",
       "      <td>13208</td>\n",
       "      <td>0x64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ll</td>\n",
       "      <td>e</td>\n",
       "      <td>18801</td>\n",
       "      <td>0x65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ll</td>\n",
       "      <td>f</td>\n",
       "      <td>326</td>\n",
       "      <td>0x66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ll</td>\n",
       "      <td>g</td>\n",
       "      <td>2573</td>\n",
       "      <td>0x67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ll</td>\n",
       "      <td>h</td>\n",
       "      <td>4510</td>\n",
       "      <td>0x68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ll</td>\n",
       "      <td>i</td>\n",
       "      <td>25237</td>\n",
       "      <td>0x69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Ll</td>\n",
       "      <td>j</td>\n",
       "      <td>1409</td>\n",
       "      <td>0x6a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Ll</td>\n",
       "      <td>k</td>\n",
       "      <td>8759</td>\n",
       "      <td>0x6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ll</td>\n",
       "      <td>l</td>\n",
       "      <td>39211</td>\n",
       "      <td>0x6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Ll</td>\n",
       "      <td>m</td>\n",
       "      <td>25753</td>\n",
       "      <td>0x6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Ll</td>\n",
       "      <td>n</td>\n",
       "      <td>26517</td>\n",
       "      <td>0x6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Ll</td>\n",
       "      <td>o</td>\n",
       "      <td>7617</td>\n",
       "      <td>0x6f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Ll</td>\n",
       "      <td>p</td>\n",
       "      <td>5841</td>\n",
       "      <td>0x70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Ll</td>\n",
       "      <td>q</td>\n",
       "      <td>4102</td>\n",
       "      <td>0x71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ll</td>\n",
       "      <td>r</td>\n",
       "      <td>23976</td>\n",
       "      <td>0x72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Ll</td>\n",
       "      <td>s</td>\n",
       "      <td>16055</td>\n",
       "      <td>0x73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Ll</td>\n",
       "      <td>t</td>\n",
       "      <td>29345</td>\n",
       "      <td>0x74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Ll</td>\n",
       "      <td>u</td>\n",
       "      <td>21268</td>\n",
       "      <td>0x75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Ll</td>\n",
       "      <td>v</td>\n",
       "      <td>9058</td>\n",
       "      <td>0x76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Ll</td>\n",
       "      <td>w</td>\n",
       "      <td>6186</td>\n",
       "      <td>0x77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Ll</td>\n",
       "      <td>x</td>\n",
       "      <td>20574</td>\n",
       "      <td>0x78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Ll</td>\n",
       "      <td>y</td>\n",
       "      <td>18677</td>\n",
       "      <td>0x79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Ll</td>\n",
       "      <td>z</td>\n",
       "      <td>5393</td>\n",
       "      <td>0x7a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ð</td>\n",
       "      <td>1381</td>\n",
       "      <td>0xf0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ı</td>\n",
       "      <td>9</td>\n",
       "      <td>0x131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ɑ</td>\n",
       "      <td>96</td>\n",
       "      <td>0x251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ə</td>\n",
       "      <td>41927</td>\n",
       "      <td>0x259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ɛ</td>\n",
       "      <td>4434</td>\n",
       "      <td>0x25b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Ll</td>\n",
       "      <td>ɟ</td>\n",
       "      <td>3028</td>\n",
       "      <td>0x25f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Ll</td>\n",
       "      <td>θ</td>\n",
       "      <td>3615</td>\n",
       "      <td>0x3b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Lm</td>\n",
       "      <td>ʾ</td>\n",
       "      <td>19345</td>\n",
       "      <td>0x2be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Lm</td>\n",
       "      <td>ʿ</td>\n",
       "      <td>192</td>\n",
       "      <td>0x2bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lu</td>\n",
       "      <td>A</td>\n",
       "      <td>273</td>\n",
       "      <td>0x41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lu</td>\n",
       "      <td>B</td>\n",
       "      <td>196</td>\n",
       "      <td>0x42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lu</td>\n",
       "      <td>C</td>\n",
       "      <td>78</td>\n",
       "      <td>0x43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lu</td>\n",
       "      <td>D</td>\n",
       "      <td>45</td>\n",
       "      <td>0x44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lu</td>\n",
       "      <td>E</td>\n",
       "      <td>154</td>\n",
       "      <td>0x45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lu</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>0x46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lu</td>\n",
       "      <td>G</td>\n",
       "      <td>81</td>\n",
       "      <td>0x47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lu</td>\n",
       "      <td>H</td>\n",
       "      <td>118</td>\n",
       "      <td>0x48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lu</td>\n",
       "      <td>I</td>\n",
       "      <td>60</td>\n",
       "      <td>0x49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lu</td>\n",
       "      <td>J</td>\n",
       "      <td>20</td>\n",
       "      <td>0x4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lu</td>\n",
       "      <td>K</td>\n",
       "      <td>70</td>\n",
       "      <td>0x4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lu</td>\n",
       "      <td>L</td>\n",
       "      <td>37</td>\n",
       "      <td>0x4c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lu</td>\n",
       "      <td>M</td>\n",
       "      <td>173</td>\n",
       "      <td>0x4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lu</td>\n",
       "      <td>N</td>\n",
       "      <td>154</td>\n",
       "      <td>0x4e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lu</td>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "      <td>0x4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lu</td>\n",
       "      <td>P</td>\n",
       "      <td>236</td>\n",
       "      <td>0x50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lu</td>\n",
       "      <td>Q</td>\n",
       "      <td>79</td>\n",
       "      <td>0x51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lu</td>\n",
       "      <td>R</td>\n",
       "      <td>394</td>\n",
       "      <td>0x52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Lu</td>\n",
       "      <td>S</td>\n",
       "      <td>158</td>\n",
       "      <td>0x53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lu</td>\n",
       "      <td>T</td>\n",
       "      <td>86</td>\n",
       "      <td>0x54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Lu</td>\n",
       "      <td>U</td>\n",
       "      <td>98</td>\n",
       "      <td>0x55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Lu</td>\n",
       "      <td>V</td>\n",
       "      <td>10</td>\n",
       "      <td>0x56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lu</td>\n",
       "      <td>W</td>\n",
       "      <td>15</td>\n",
       "      <td>0x57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lu</td>\n",
       "      <td>X</td>\n",
       "      <td>48</td>\n",
       "      <td>0x58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Lu</td>\n",
       "      <td>Y</td>\n",
       "      <td>34</td>\n",
       "      <td>0x59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lu</td>\n",
       "      <td>Z</td>\n",
       "      <td>135</td>\n",
       "      <td>0x5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Lu</td>\n",
       "      <td>Ɉ</td>\n",
       "      <td>3</td>\n",
       "      <td>0x248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̀</td>\n",
       "      <td>36346</td>\n",
       "      <td>0x300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Mn</td>\n",
       "      <td>́</td>\n",
       "      <td>56797</td>\n",
       "      <td>0x301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̂</td>\n",
       "      <td>562</td>\n",
       "      <td>0x302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̃</td>\n",
       "      <td>1</td>\n",
       "      <td>0x303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̄</td>\n",
       "      <td>1682</td>\n",
       "      <td>0x304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̆</td>\n",
       "      <td>1605</td>\n",
       "      <td>0x306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̇</td>\n",
       "      <td>270</td>\n",
       "      <td>0x307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̈</td>\n",
       "      <td>14</td>\n",
       "      <td>0x308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̌</td>\n",
       "      <td>11127</td>\n",
       "      <td>0x30c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̣</td>\n",
       "      <td>4461</td>\n",
       "      <td>0x323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Mn</td>\n",
       "      <td>̭</td>\n",
       "      <td>10110</td>\n",
       "      <td>0x32d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pd</td>\n",
       "      <td>-</td>\n",
       "      <td>25281</td>\n",
       "      <td>0x2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Pd</td>\n",
       "      <td>—</td>\n",
       "      <td>27</td>\n",
       "      <td>0x2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Pd</td>\n",
       "      <td>⹀</td>\n",
       "      <td>1100</td>\n",
       "      <td>0x2e40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pe</td>\n",
       "      <td>)</td>\n",
       "      <td>5</td>\n",
       "      <td>0x29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pe</td>\n",
       "      <td>]</td>\n",
       "      <td>28</td>\n",
       "      <td>0x5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Po</td>\n",
       "      <td>!</td>\n",
       "      <td>560</td>\n",
       "      <td>0x21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Po</td>\n",
       "      <td>,</td>\n",
       "      <td>7761</td>\n",
       "      <td>0x2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Po</td>\n",
       "      <td>.</td>\n",
       "      <td>15191</td>\n",
       "      <td>0x2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Po</td>\n",
       "      <td>:</td>\n",
       "      <td>73</td>\n",
       "      <td>0x3a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Po</td>\n",
       "      <td>;</td>\n",
       "      <td>1</td>\n",
       "      <td>0x3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Po</td>\n",
       "      <td>?</td>\n",
       "      <td>1686</td>\n",
       "      <td>0x3f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ps</td>\n",
       "      <td>(</td>\n",
       "      <td>5</td>\n",
       "      <td>0x28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ps</td>\n",
       "      <td>[</td>\n",
       "      <td>28</td>\n",
       "      <td>0x5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sm</td>\n",
       "      <td>+</td>\n",
       "      <td>11633</td>\n",
       "      <td>0x2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Sm</td>\n",
       "      <td>|</td>\n",
       "      <td>35931</td>\n",
       "      <td>0x7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zs</td>\n",
       "      <td></td>\n",
       "      <td>91764</td>\n",
       "      <td>0x20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category character   count hex codes\n",
       "0        Cc        \\n     397       0xa\n",
       "40       Ll         a  108660      0x61\n",
       "41       Ll         b   14437      0x62\n",
       "42       Ll         c    5986      0x63\n",
       "43       Ll         d   13208      0x64\n",
       "44       Ll         e   18801      0x65\n",
       "45       Ll         f     326      0x66\n",
       "46       Ll         g    2573      0x67\n",
       "47       Ll         h    4510      0x68\n",
       "48       Ll         i   25237      0x69\n",
       "49       Ll         j    1409      0x6a\n",
       "50       Ll         k    8759      0x6b\n",
       "51       Ll         l   39211      0x6c\n",
       "52       Ll         m   25753      0x6d\n",
       "53       Ll         n   26517      0x6e\n",
       "54       Ll         o    7617      0x6f\n",
       "55       Ll         p    5841      0x70\n",
       "56       Ll         q    4102      0x71\n",
       "57       Ll         r   23976      0x72\n",
       "58       Ll         s   16055      0x73\n",
       "59       Ll         t   29345      0x74\n",
       "60       Ll         u   21268      0x75\n",
       "61       Ll         v    9058      0x76\n",
       "62       Ll         w    6186      0x77\n",
       "63       Ll         x   20574      0x78\n",
       "64       Ll         y   18677      0x79\n",
       "65       Ll         z    5393      0x7a\n",
       "67       Ll         ð    1381      0xf0\n",
       "68       Ll         ı       9     0x131\n",
       "70       Ll         ɑ      96     0x251\n",
       "71       Ll         ə   41927     0x259\n",
       "72       Ll         ɛ    4434     0x25b\n",
       "73       Ll         ɟ    3028     0x25f\n",
       "87       Ll         θ    3615     0x3b8\n",
       "74       Lm         ʾ   19345     0x2be\n",
       "75       Lm         ʿ     192     0x2bf\n",
       "12       Lu         A     273      0x41\n",
       "13       Lu         B     196      0x42\n",
       "14       Lu         C      78      0x43\n",
       "15       Lu         D      45      0x44\n",
       "16       Lu         E     154      0x45\n",
       "17       Lu         F      39      0x46\n",
       "18       Lu         G      81      0x47\n",
       "19       Lu         H     118      0x48\n",
       "20       Lu         I      60      0x49\n",
       "21       Lu         J      20      0x4a\n",
       "22       Lu         K      70      0x4b\n",
       "23       Lu         L      37      0x4c\n",
       "24       Lu         M     173      0x4d\n",
       "25       Lu         N     154      0x4e\n",
       "26       Lu         O      12      0x4f\n",
       "27       Lu         P     236      0x50\n",
       "28       Lu         Q      79      0x51\n",
       "29       Lu         R     394      0x52\n",
       "30       Lu         S     158      0x53\n",
       "31       Lu         T      86      0x54\n",
       "32       Lu         U      98      0x55\n",
       "33       Lu         V      10      0x56\n",
       "34       Lu         W      15      0x57\n",
       "35       Lu         X      48      0x58\n",
       "36       Lu         Y      34      0x59\n",
       "37       Lu         Z     135      0x5a\n",
       "69       Lu         Ɉ       3     0x248\n",
       "76       Mn         ̀   36346     0x300\n",
       "77       Mn         ́   56797     0x301\n",
       "78       Mn         ̂     562     0x302\n",
       "79       Mn         ̃       1     0x303\n",
       "80       Mn         ̄    1682     0x304\n",
       "81       Mn         ̆    1605     0x306\n",
       "82       Mn         ̇     270     0x307\n",
       "83       Mn         ̈      14     0x308\n",
       "84       Mn         ̌   11127     0x30c\n",
       "85       Mn         ̣    4461     0x323\n",
       "86       Mn         ̭   10110     0x32d\n",
       "7        Pd         -   25281      0x2d\n",
       "88       Pd         —      27    0x2014\n",
       "89       Pd         ⹀    1100    0x2e40\n",
       "4        Pe         )       5      0x29\n",
       "39       Pe         ]      28      0x5d\n",
       "2        Po         !     560      0x21\n",
       "6        Po         ,    7761      0x2c\n",
       "8        Po         .   15191      0x2e\n",
       "9        Po         :      73      0x3a\n",
       "10       Po         ;       1      0x3b\n",
       "11       Po         ?    1686      0x3f\n",
       "3        Ps         (       5      0x28\n",
       "38       Ps         [      28      0x5b\n",
       "5        Sm         +   11633      0x2b\n",
       "66       Sm         |   35931      0x7c\n",
       "1        Zs             91764      0x20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = collections.Counter()\n",
    "\n",
    "for t in alltexts:\n",
    "    for v, verse in t.text:\n",
    "        for c in verse:\n",
    "            cnt[c] += 1\n",
    "\n",
    "data = []\n",
    "for c in sorted(cnt):\n",
    "    data.append({'character': c,\n",
    "                 'count': cnt[c],\n",
    "                 'category': unicodedata.category(c[0]),\n",
    "                 'hex codes': ' '.join([hex(ord(e)) for e in c])})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.sort_values(['category', 'character'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other special characters\n",
    "\n",
    "#### Hyphens\n",
    "\n",
    "Hyphens connect prefixed forms to words, and double hyphens connect suffixed forms to words. When splitting words, we would split a form like `pre-+word⹀suff.|` into three parts: `pre-`, `+word`, and `⹀suff.|`.\n",
    "\n",
    "#### Pauses and ellipsis\n",
    "\n",
    "There are two kinds of pause or ellipsis markers: consecutive dots and em dashes. The dots vary in number from two to five. In some cases the ellipsis is not followed by a space but directly by the following word. In other cases the ellipsis is followed by either a vertical bar or by a comma.\n",
    "\n",
    "#### Parentheses and brackets\n",
    "\n",
    "Sometimes, parentheses or brackets are used to indicate that a text was spoken by the interviewer, and once, to insert a remark (Urmi_C A3 Axiqar 18: \"(interruption)\").\n",
    "\n",
    " - **Question:** how to handle these?\n",
    "   Just filter out the remarks and brackets, and leave the text?\n",
    "   Or remove altogether? It can be easily removed with a regular expression, like:\n",
    "\n",
    "        >>> s = '(18) (GK: bla bla.|) more bla.| [GK bla?] +bla bla.|'\n",
    "        >>> pattern = '[[(][A-Z]+:? ([^])]+)[\\]\\)]'\n",
    "        >>> ''.join(re.split(pattern, s))\n",
    "        '(18) bla bla.| more bla.| bla? +bla bla.|'   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the right word boundary characters, white space and hyphens, we can now more reliably split the verses into words (but see remark in `split_words()` about 'UGLY HACK': there are not always spaces so sometimes you need to use a hack). That means we can also count the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alltexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_marks = {\n",
    "    'Arm': 'Arm(enian?)',\n",
    "    'Az': 'Az(eri?)',\n",
    "    'E': 'English',\n",
    "    'F': 'French',\n",
    "    'Ge': 'Ge(rman?)',\n",
    "    'P': 'P(ersian?)',\n",
    "    'R': 'R(ussian?)',\n",
    "}\n",
    "\n",
    "fields = [\n",
    "    'surface',\n",
    "    'word',\n",
    "    'before',\n",
    "    'after',\n",
    "    'punct',\n",
    "    'mark_s',\n",
    "    'mark_e',\n",
    "]\n",
    "\n",
    "# TODO This doesn't work yet (because tuples are immutable)\n",
    "# Word = collections.namedtuple('Word', fields)\n",
    "# # set all values except 'surface' to empty string by default\n",
    "# # https://stackoverflow.com/a/18348004/9230612\n",
    "# Word.__new__.__defaults__ = ('',) * (len(Word._fields) - 1)\n",
    "\n",
    "# for t in alltexts:\n",
    "#     for v, verse in t.text:\n",
    "#         words = []\n",
    "#         new_verse = []\n",
    "#         for word in split_words(verse, ' -\\n', '+⹀'):\n",
    "#             w = Word(surface=word)\n",
    "#             # remove characters before word\n",
    "#             while word and word[0] in '+⹀':\n",
    "#                 print(repr(w.before))\n",
    "#                 w.before = w.before + word[0]\n",
    "#                 word = word[1:]\n",
    "#             # starting markers are looked up only to match ending markers\n",
    "#             # check if there are ending markers by looking for capital letters\n",
    "#             # occurring after lowercase letters\n",
    "#             pos = 0\n",
    "#             while pos < len(word) and not word[pos].islower():\n",
    "#                 pos += 1\n",
    "#             while pos < len(word) and not word[pos].isupper():\n",
    "#                 pos += 1\n",
    "#             # check if remaining string starts with any of known_marks\n",
    "#             mark_e = ([m for m in known_marks if word[pos:].startswith(m)]+[''])[0]\n",
    "#             if mark_e:\n",
    "#                 # remove marker from word string\n",
    "#                 word = word[:pos] + word[pos+len(mark_e):]\n",
    "#                 w.mark_e = mark_e\n",
    "# #                 # look for starting marker\n",
    "# #                 if word.startswith(mark_e) and word                       \n",
    "#             new_verse.append(w)\n",
    "#         verse = new_verse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urmi_C A3 (70) EhotèlEux,| \n",
      "Urmi_C A3 (72) EhotèlEux.| \n",
      "Urmi_C A3 (75) EhotèlEu,| \n",
      "Urmi_C A3 (77) EhotèlEu| \n",
      "Urmi_C A41 (6) EpencílEə \n",
      "Urmi_C A41 (12) ElístEət \n",
      "Urmi_C A43 (22) RpovàrRə \n",
      "Urmi_C A43 (23) RpovàrRə \n",
      "Urmi_C A51 (6) RiRʾ \n",
      "Urmi_C A56 (4) RnèrvRu| \n",
      "Urmi_C B2 (12) PšusèPva| \n",
      "120565\n",
      "'Arm'\n",
      "'Az'\n",
      "'E'\n",
      "'Eu'\n",
      "'Eux'\n",
      "'Eə'\n",
      "'Eət'\n",
      "'F'\n",
      "'Ge'\n",
      "'P'\n",
      "'Pva'\n",
      "'R'\n",
      "'Ru'\n",
      "'Rə'\n",
      "'Rʾ'\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "result = []\n",
    "\n",
    "for i, t in enumerate(alltexts):\n",
    "    for v, verse in t.text:\n",
    "        words = split_words(verse, ' -\\n', '+⹀')\n",
    "        total += len(words)\n",
    "        for j, word in enumerate(words):\n",
    "            if not any(c.isalpha() for c in word):  # or 'GK' in word or 'OK' in word:\n",
    "                continue\n",
    "            stripped = word.lstrip('+⹀([ʾʿ').rstrip('-)]|.,?!:; \\n')\n",
    "            # strip off initial capitals\n",
    "            while stripped and (stripped[0].isupper() or stripped[0] in 'ʾʿ'):\n",
    "                stripped = stripped[1:]\n",
    "            has_case = stripped != stripped.lower()\n",
    "            \n",
    "            if has_case or any(c in '+⹀([)]|.,?!:;' for c in stripped):\n",
    "                while not stripped[0].isupper():  # == stripped[0].lower():\n",
    "                    stripped = stripped[1:]\n",
    "                result.append(stripped)\n",
    "                if stripped not in known_marks:\n",
    "                    print(t.dialect, t.id, v, word)\n",
    "#             stripped = word.lstrip('+⹀([')\n",
    "#             if stripped and  and not stripped[0].isalpha():\n",
    "#                 print(t.dialect, t.id, v, repr((words[j-1] if j>0 else '') + word))\n",
    "\n",
    "# problems: Urmi suffixes attached to loan words, with no separation?\n",
    "# Urmi_C A3 (70) EhotèlEux,| \n",
    "# Urmi_C A3 (72) EhotèlEux.| \n",
    "# Urmi_C A3 (75) EhotèlEu,| \n",
    "# Urmi_C A3 (77) EhotèlEu| \n",
    "# Urmi_C A41 (6) EpencílEə \n",
    "# Urmi_C A41 (12) ElístEət \n",
    "# Urmi_C A43 (22) RpovàrRə \n",
    "# Urmi_C A43 (23) RpovàrRə \n",
    "# Urmi_C A51 (6) RiRʾ \n",
    "# Urmi_C A56 (4) RnèrvRu| \n",
    "# Urmi_C B2 (12) PšusèPva| \n",
    "\n",
    "print(total)\n",
    "for w in sorted(set(result)):\n",
    "    print(repr(w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: word or section markers, such as capital P around a word (meaning Persian loanword?) or 'Az' around several words. In the Word and PDF versions, the markers are set in superscript and the marked words in roman letters (instead of cursive), but in our text we will need to recover them in other ways (such as by looking at capital letters not at the beginning of a word, and matching that with an earlier capital letter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also TODO: make a nice table of letters, separated into vowels and consonants, with all possible combinations of diacritic symbols, and consult with Geoffrey what combinations are significant (e.g., 'a' and 'á' are the same sound, but 'c' and 'č' are different sounds/consonants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unicode range for combining characters\n",
    "combining_characters = range(0x300, 0x370)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure we did not lose anything of value, here is a list of all non-empty strings in the `ignored` list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' The name Čuxo means ‘one who wears the woolen čuxa garment’.',\n",
       " '4\\n',\n",
       " '3\\n',\n",
       " '?\\n',\n",
       " '1\\n',\n",
       " 'THE NEO-ARAMAIC DIALECT OF\\n',\n",
       " 'THE ASSYRIAN CHRISTIANS OF URMI\\n',\n",
       " 'GEOFFREY KHAN\\n',\n",
       " '\\x0c\\x0c\\n',\n",
       " 'VOLUME 4\\n',\n",
       " 'TEXTS\\n',\n",
       " '\\x0c\\x0c\\n',\n",
       " 'Contents\\n',\n",
       " 'FOLKTALES\\n',\n",
       " 'A1 The Bald Man and the King (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t9\\n',\n",
       " 'A2 Women are Stronger than Men (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t13\\n',\n",
       " 'A3 Axiqar (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t15\\n',\n",
       " 'A4 Is there a Man with No Worries? (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t21\\n',\n",
       " 'A5 Women do Things Best (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t22\\n',\n",
       " 'A6 The Dead Rise and Return (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t24\\n',\n",
       " 'A7 A Pound of Flesh (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t25\\n',\n",
       " 'A8 The Loan of a Cooking Pot (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t27\\n',\n",
       " 'A9 Much Ado About Nothing (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t27\\n',\n",
       " 'A10 A Visit from Harun ar-Rashid (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t28\\n',\n",
       " 'A11 The Cat’s Dinner (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t29\\n',\n",
       " 'A12 Ice for Dinner (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t29\\n',\n",
       " 'A13 Am I dead? (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t29\\n',\n",
       " 'A14 A Thousand Dinars (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t30\\n',\n",
       " 'A15 Kindness to a Donkey (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t31\\n',\n",
       " 'A16 The Stupid Carpenter (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t31\\n',\n",
       " 'A17 A Close Shave (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t31\\n',\n",
       " 'A18 A Sweater to Pay Off a Debt (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t31\\n',\n",
       " 'A19 No Bread Today (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t32\\n',\n",
       " 'A20 An Orphan Duckling (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t32\\n',\n",
       " 'A21 Mistaken Identity (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t32\\n',\n",
       " 'A22 Trickster (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t33\\n',\n",
       " 'A23 Problems Lighting a Fire (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t33\\n',\n",
       " 'A24 The Angel of Death (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t33\\n',\n",
       " 'A25 Stomach Trouble (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t34\\n',\n",
       " 'A26 A Lost Donkey (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t34\\n',\n",
       " 'A27 A Lost Ring (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t34\\n',\n",
       " 'A28 The Purchase of a Donkey (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t34\\n',\n",
       " 'A29 Lost Money (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t35\\n',\n",
       " 'A30 The Wife’s Condition (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t35\\n',\n",
       " 'A31 A Donkey Knows Best (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t36\\n',\n",
       " 'A32 When Shall I Die? (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t36\\n',\n",
       " 'A33 I Have Died (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t36\\n',\n",
       " 'A34 The Fisherman and the Princess (Nancy George, Babari, S)\\t37\\n',\n",
       " 'A35 The Wife who Learns How to Work\\t38\\n',\n",
       " 'A36 A Cure for a Husband s Madness (Nancy George, Babari, S)\\t40\\n',\n",
       " 'A37 The Bald Child and the Monsters (Yosəp bet Yosəp, Zumallan, N)\\t42\\n',\n",
       " 'A38 The Wise Young Daughter (Yosəp bet Yosəp, Zumallan, N)\\t44\\n',\n",
       " 'A39 The Adventures of Ashur (Yonan Petrus, Mushawa, N)\\t46\\n',\n",
       " 'A40 A Dragon in the Well (Frederic Ayyubkhan, Spurġān, N)\\t51\\n',\n",
       " 'A41 A Painting of the King Of Iran (Frederic Ayyubkhan, +Spurġān, N)\\t52\\n',\n",
       " 'A42 The Adventures of Two Brothers (Manya Givoyev, Guylasar, Armenia)\\t53\\n',\n",
       " 'A43 The Adventures of a Princess (Manya Givoyev, Guylasar, Armenia)\\t57\\n',\n",
       " 'A44 Two Wicked Daughters-in-law (Manya Givoyev, Guylasar, Armenia)\\t61\\n',\n",
       " 'A45 A Dutiful Son (Manya Givoyev, Guylasar, Armenia)\\t62\\n',\n",
       " 'A46 The Little Prince and the Snake (Nadia Aloverdova, Guylasar, Armenia)\\t64\\n',\n",
       " 'A47 The Snake s Dilemma (Arsen Mikhaylov, Arzni, Armenia)\\t64\\n',\n",
       " 'A48 The Wise Brother (Arsen Mikhaylov, Arzni, Armenia)\\t66\\n',\n",
       " 'A49 The Man who Wanted to Complain to God (Sophia Danielova, Arzni, Armenia)\\t69\\n',\n",
       " 'A50 The Giant One-Eyed Demon (Sophia Danielova, Arzni, Armenia)\\t70\\n',\n",
       " 'A51 The Cow and The Poor Girl (Maryam Gwirgis, Canda, Georgia)\\t71\\n',\n",
       " 'A52 A Frog Wants a Husband (Maryam Gwirgis, Canda, Georgia)\\t72\\n',\n",
       " 'A53 The Bird and the Fox (Maryam Gwirgis, Canda, Georgia)\\t73\\n',\n",
       " 'A54 The Old Man and the Fish (Maryam Gwirgis, Canda, Georgia)\\t74\\n',\n",
       " 'A55 Two Birds Fall in Love (Maryam Gwirgis, Canda, Georgia)\\t75\\n',\n",
       " 'A56 Star-Crossed Lovers (Maryam Gwirgis, Canda, Georgia)\\t75\\n',\n",
       " 'HISTORY AND CULTURE\\n',\n",
       " 'B1 The Assyrians of Urmi (Yosəp bet Yosəp, Zumallan, N)\\t78\\n',\n",
       " 'B2 Village Life (Yonan Petrus, Mushava, N)\\t82\\n',\n",
       " 'B3 Agriculture and Village Life (Natan Khoshaba, Zumallan, N)\\t84\\n',\n",
       " 'B4 Hunting (Natan Khoshaba, Zumallan, N)\\t88\\n',\n",
       " 'B5 Weddings and Festivals (Natan Khoshaba, Zumallan, N)\\t90\\n',\n",
       " 'B6 Events in 1946 on the Urmi Plain (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t91\\n',\n",
       " 'B7 Village Life (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t93\\n',\n",
       " 'B8 Weddings (Yulia Davudi, +Hassar +Baba-čanɟa, N)\\t95\\n',\n",
       " 'B9 Games (Alice Bet-Yosəp, Zumallan, N)\\t96\\n',\n",
       " 'B10 Village Life (Alice Bet-Yosəp, Zumallan, N)\\t98\\n',\n",
       " 'B11 St. Zayya s Cake Dough (Victor Orshan, Zumallan, N)\\t101\\n',\n",
       " 'B12 Nipuxta (Victor Orshan, Zumallan, N)\\t102\\n',\n",
       " 'B13 Vineyards (Victor Orshan, Zumallan, N)\\t103\\n',\n",
       " 'B14 Village Life (Jacob Petrus, Gulpashan, S)\\t104\\n',\n",
       " 'B15 Village Life (Nadia Aloverdova, Guylasar, Armenia)\\t105\\n',\n",
       " 'B16 The Assyrians of Armenia (Nadia Aloverdova, Guylasar, Armenia)\\t106\\n',\n",
       " 'B17 Village Life (Merab Badalov, Canda, Georgia)\\t107\\n',\n",
       " '\\x0c\\x0c\\n',\n",
       " 'FOLKTALES\\n',\n",
       " '\\x0c\\n',\n",
       " ' In the original recording of the story the speaker used the word camra ‘animal droppings’ here, but subsequently corrected this to calla.',\n",
       " 'HISTORY AND CULTURE\\n',\n",
       " '\\x0c\\n',\n",
       " '\\x0c\\n',\n",
       " ' Mistake for šənnə +xarayə.',\n",
       " 'PAGE  190\\n',\n",
       " 'PAGE  189\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e for e in ignored if e and e != '\\n']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
