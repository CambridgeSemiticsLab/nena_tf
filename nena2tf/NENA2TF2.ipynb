{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NENA 2 TF 2.0\n",
    "\n",
    "This version of the NENA conversion is the first to use the new \n",
    "text markup and parsing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "import tabulate\n",
    "import unicodedata as ud\n",
    "import tf\n",
    "from pathlib import Path\n",
    "\n",
    "# configure paths to data input and output\n",
    "VERSION = 'alpha'\n",
    "CSL_DIR = Path.home().joinpath('github/CambridgeSemiticsLab/')\n",
    "PROJECT_DIR = CSL_DIR.joinpath('nena_tf')\n",
    "CORPUS_DIR = CSL_DIR.joinpath('nena_corpus')\n",
    "INPUT_DIR = CORPUS_DIR.joinpath(f'parsed_texts/{VERSION}')\n",
    "CORPUS_METADATA = CORPUS_DIR.joinpath('standards/metadata.json')\n",
    "OUTPUT_DIR = PROJECT_DIR.joinpath(f'tf/{VERSION}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Feature and Object Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_meta = json.loads(CORPUS_METADATA.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'North Eastern Neo-Aramaic Text Corpus',\n",
       " 'origin': 'The NENA text corpus is derived from decades of fieldwork by Professor Geoffrey Khan and his colleagues at the University of Cambridge, Faculty of Asian and Middle Eastern Studies',\n",
       " 'license': 'Creative Commons Attribution 4.0 International Public License',\n",
       " 'contributors': 'Geoffrey Khan, Eleanor Coghill, Roberta Borghero, Lidia Napiorkowska, Hezy Mutzafi, Alinda Damsma, Paul Noorlander, Dorota Molin, Johan Lundberg',\n",
       " 'scientific_programmers': 'Cody Kingham, James Strachan, Dirk Roorda, Hannes Vlaardingerbroek',\n",
       " 'DOI': '10.5281/zenodo.3541999',\n",
       " 'corpus_repo': 'https://github.com/CambridgeSemiticsLab/nena_corpus'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_meta['NENA_corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "intFeatures = {'number'}\n",
    "otext = {\n",
    "    'sectionTypes': 'dialect,text,line',\n",
    "    'sectionFeatures': 'dialect,title,number',\n",
    "    'fmt:text-orig-full': 'word#{text}{end}',\n",
    "    'fmt:text-orig-lite': 'word#{text_lite}{end}',\n",
    "    'fmt:text-trans-full': 'word#{full}{full_end}',\n",
    "    'fmt:text-trans-lite': 'word#{lite}{lite_end}',\n",
    "    'fmt:text-trans-fuzzy': 'word#{fuzzy}{fuzzy_end}',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NenaTfBuilder:\n",
    "    \"\"\"Construct Text-Fabric graph resource from parsed JSON files\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dir, output_dir, metadata, TF, **TF_kwargs):\n",
    "        \"\"\"Load json data from input dir to prepare for TF conversion.\n",
    "        \n",
    "        Args:\n",
    "            input_dir: pathlib Path which is a directory that contains\n",
    "                subdirectories named after the respective dialects in the\n",
    "                text corpus. Each subdirectory should contain parsed JSON\n",
    "                texts ready for analysis.\n",
    "            output_dir: directory to save the .tf files\n",
    "            metadata: dictionary containing metadata on the corpus needed\n",
    "                to construct the TF graph\n",
    "            TF: Text-Fabric module loaded\n",
    "            **TF_kwargs: optional kwargs to pass to Text-Fabric loader\n",
    "        \"\"\"\n",
    "        \n",
    "        # load JSON data and initialize TF objects with paths\n",
    "        self.metadata = metadata\n",
    "        self.dialect2parsings = self.load_parsed_jsons(input_dir)\n",
    "        self.Fabric = TF.fabric.Fabric(locations=str(output_dir), **TF_kwargs)\n",
    "        self.cv = TF.convert.walker.CV(self.Fabric)\n",
    "        self.message = self.Fabric.tmObj # timestamped messages\n",
    "        \n",
    "    def load_parsed_jsons(self, dialect_dir):\n",
    "        \"\"\"Map directory of dialect subdirectories to parsed json data.\n",
    "        \n",
    "        Args:\n",
    "            dialect_dir: a pathlib Path that contains subdirectories\n",
    "                named after respective dialects; each subdirectory \n",
    "                contains parsed JSON files which are each a text\n",
    "        \n",
    "        Returns:\n",
    "            dict with structure of dict[dialect] = list(text_parsings)\n",
    "        \"\"\"\n",
    "        dialect2parsings = collections.defaultdict(list)\n",
    "        for dialect_dir in sorted(INPUT_DIR.glob('*')):\n",
    "            for text_file in sorted(dialect_dir.glob('*.json')):\n",
    "                dialect = dialect_dir.name\n",
    "                text_data = json.loads(text_file.read_text())\n",
    "                dialect2parsings[dialect].append(text_data)\n",
    "        return dialect2parsings\n",
    "    \n",
    "    def build(**walk_kwargs):\n",
    "        \"\"\"Executes the TF conversion on the loaded source\n",
    "        \n",
    "        Args:\n",
    "            walk_kwargs: optional. Keyword arguments to feed \n",
    "                to TF's cv.walk function.\n",
    "        \"\"\"\n",
    "        slot_type = 'letter'\n",
    "        self.good = self.cv.walk(\n",
    "            self.director,\n",
    "            slot_type,\n",
    "            **walk_kwargs,\n",
    "        )\n",
    "    \n",
    "    def director(self, cv):\n",
    "        \"\"\"Call cv methods to index the graph.\n",
    "        \n",
    "        This function does the bulk of the work of building the TF resource.\n",
    "        It operates in one large loop that walks over all parsed data. \n",
    "        The supplied cv Text-Fabric class possesses methods that create node \n",
    "        IDs and associate features with those IDs. These methods are called \n",
    "        throughout the loop. \n",
    "        \n",
    "        cv methods used here:\n",
    "            cv.slot: make a new slot, the atomic element of the graph. All \n",
    "                nodes active during an active slot will contain that slot.\n",
    "            cv.node: make a new node in the graph with supplied object name\n",
    "            cv.feature: add a string/integer feature to a supplied cv.node\n",
    "            cv.terminate: deactivate a given node; this ends any further\n",
    "                slot embeddings, which are calculated automatically from \n",
    "                whichever slots are activated while the node is also active.\n",
    "                \n",
    "        Further info about cv functionality can be referenced in the \n",
    "        Text-Fabric documentation.\n",
    "        \n",
    "        Args:\n",
    "            cv: Text-Fabric CV class loaded with Fabric\n",
    "        \"\"\"\n",
    "        \n",
    "        features = self.metadata['object_features']\n",
    "        text_features = {f for f in features if f['value'] == 'text'}\n",
    "        general_features = {f for f in features if f not in text_features}\n",
    "        nodes = {} # gets updated throughout\n",
    "    \n",
    "        def swap_node(node):\n",
    "            \"\"\"Replace any active nodes with new node.\"\"\"\n",
    "            try:\n",
    "                cv.terminate(nodes[node])\n",
    "                nodes[node] = cv.node(node)\n",
    "            except KeyError:\n",
    "                nodes[node] = cv.node(node)\n",
    "        \n",
    "        # parse all data for every dialect\n",
    "        for dialect, texts in self.dialect2parsings.items():\n",
    "            \n",
    "            # make dialect node / features\n",
    "            nodes['dialect'] = cv.node('dialect')\n",
    "            cv.feature(nodes['dialect'], dialect=dialect)\n",
    "            \n",
    "            # make text node / features\n",
    "            for text in texts:\n",
    "        \n",
    "                nodes['text'] = cv.node('text')\n",
    "                text_feats, paragraphs = text\n",
    "                cv.feature(nodes['text'], **self.dict_intersect(text_feats, features))\n",
    "                \n",
    "                for paragraph in paragraphs:\n",
    "                    \n",
    "                    nodes['stress'] = cv.node('stress')\n",
    "                    nodes['inton'] = cv.node('inton')\n",
    "                    nodes['subsentence'] = cv.node('subsentence')\n",
    "                    nodes['sentence'] = cv.node('sentence')\n",
    "                    nodes['paragraph'] = cv.node('paragraph')\n",
    "                \n",
    "                    # -- Process Paragraph elements --\n",
    "                    \n",
    "                    # track span features for addition to words\n",
    "                    # features get updated by span triggers in iteration\n",
    "                    span_feats = {\n",
    "                        'speaker': list(text_feats['speakers'].values())[0],\n",
    "                        'lang': 'NENA',\n",
    "                        'timestamp': None,\n",
    "                    }\n",
    "                    \n",
    "                    for element in paragraph:\n",
    "                        \n",
    "                        # -- process span elements --\n",
    "                        if element['class'] == 'span':\n",
    "                            \n",
    "                            # build line nodes\n",
    "                            if 'line_number' in element:\n",
    "                                swap_node('line')\n",
    "                                cv.feature(\n",
    "                                    nodes['line'], \n",
    "                                    line_number=element['line_number']\n",
    "                                )\n",
    "                            \n",
    "                            # update other span fields\n",
    "                            span_feats.update(\n",
    "                                self.dict_intersect(element, span_feats)\n",
    "                            )\n",
    "                            \n",
    "                        # -- process words and letters --\n",
    "                        elif element['class'] == 'word':\n",
    "                            \n",
    "                            nodes['word'] = cv.node('word')\n",
    "                            word_features = {}\n",
    "                            word_features.update(span_feats)\n",
    "                            word_features.update(\n",
    "                                self.dict_intersect(element, general_features)\n",
    "                            )\n",
    "                        \n",
    "                            # 1. process word's letters and their features\n",
    "                            for letter in element['letters']:\n",
    "                                letter_node = cv.slot()\n",
    "                                letter_features = self.dict_intersect(letter, features)\n",
    "                                \n",
    "                                # process features for letter\n",
    "                                # pass on text features to word and compile it\n",
    "                                for feature, value in letter_features.items():\n",
    "                                    cv.feature(letter_node, feature=value)\n",
    "                                    if feature in text_features:\n",
    "                                        word_features[feature] = word_features.get(feature,'') + value\n",
    "                                        \n",
    "                                cv.terminate(letter_node)\n",
    "    \n",
    "                            # 2. process word's parsing features\n",
    "                        \n",
    "            \n",
    "                            # 3. mark sentence/subsentence/inton/stress bounds on endings of word\n",
    "                    \n",
    "                    \n",
    "    def dict_intersect(self, dict1, dict2):\n",
    "        \"\"\"Set intersection from one dict to another\"\"\"\n",
    "        return {k:v for k,v in dict1.items() if k in dict2}\n",
    "    \n",
    "    def exclude_keys(self, dicti, *exclusions):\n",
    "        \"\"\"Filter dictionary to exclude keys\"\"\"\n",
    "        return {k:v for k,v in dicti.items() if k not in exclusions}\n",
    "    \n",
    "    def build_text(self, letters, text_features):\n",
    "        \"\"\"Construct text representations of word based on available features.\n",
    "        \n",
    "        Letters need to be re-joined to form a word's text representation.\n",
    "        This method constructs all available text representations from a \n",
    "        list of letter dicts.\n",
    "        \"\"\"\n",
    "        text_forms = {}\n",
    "        for feat in text_features:\n",
    "            try:\n",
    "                text_forms[feat] = self.join_letters(letters, feat)\n",
    "            except KeyError:\n",
    "                continue\n",
    "        return text_forms\n",
    "    \n",
    "    def join_letters(self, letters, feature, on=''):\n",
    "        \"\"\"Joins letters based on given text feature\"\"\"\n",
    "        letter_text = [l[feature] for l in letters]\n",
    "        return f'{on}'.join(letter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nena_builder = NenaTfBuilder(INPUT_DIR, OUTPUT_DIR, corpus_meta, tf, silent='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'word',\n",
       " 'string': 'xá',\n",
       " 'letters': [{'decomposed_regex': 'x(?![̀-ͯ])|X(?![̀-ͯ])',\n",
       "   'decomposed_string': 'x',\n",
       "   'phonetic_class': 'consonant',\n",
       "   'phonetic_place': 'velar',\n",
       "   'phonetic_manner': 'fricative',\n",
       "   'phonation': 'unvoiced',\n",
       "   'lite': 'x',\n",
       "   'text_nostress': 'x',\n",
       "   'full': 'x',\n",
       "   'text': 'x',\n",
       "   'fuzzy': 'x'},\n",
       "  {'decomposed_regex': 'á(?![̀-ͯ])|Á(?![̀-ͯ])',\n",
       "   'decomposed_string': 'á',\n",
       "   'phonetic_class': 'vowel',\n",
       "   'lite': '',\n",
       "   'text_nostress': '',\n",
       "   'full': '',\n",
       "   'text': '',\n",
       "   'fuzzy': ''}],\n",
       " 'beginnings': [],\n",
       " 'endings': [{'decomposed_regex': '-',\n",
       "   'decomposed_string': '-',\n",
       "   'class': 'connector',\n",
       "   'modifies': 'stress group',\n",
       "   'position': 'end',\n",
       "   'lite': '-',\n",
       "   'text_nostress': '-',\n",
       "   'full': '-',\n",
       "   'text': '-',\n",
       "   'fuzzy': '-'}],\n",
       " 'parsings': [{'pos': 'NUMR',\n",
       "   'gloss': 'one; a (§14.1.)',\n",
       "   'lex': 'xa',\n",
       "   'gn': 'F'}]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nena_builder.dialect2parsings['Barwar'][0][1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NENA_corpus': {'name': 'North Eastern Neo-Aramaic Text Corpus',\n",
       "  'origin': 'The NENA text corpus is derived from decades of fieldwork by Professor Geoffrey Khan and his colleagues at the University of Cambridge, Faculty of Asian and Middle Eastern Studies',\n",
       "  'license': 'Creative Commons Attribution 4.0 International Public License',\n",
       "  'contributors': 'Geoffrey Khan, Eleanor Coghill, Roberta Borghero, Lidia Napiorkowska, Hezy Mutzafi, Alinda Damsma, Paul Noorlander, Dorota Molin, Johan Lundberg',\n",
       "  'scientific_programmers': 'Cody Kingham, James Strachan, Dirk Roorda, Hannes Vlaardingerbroek',\n",
       "  'DOI': '10.5281/zenodo.3541999',\n",
       "  'corpus_repo': 'https://github.com/CambridgeSemiticsLab/nena_corpus'},\n",
       " 'corpus_objects': {'dialect': 'dialect of North Eastern Neo-Aramaic',\n",
       "  'text': 'transcribed story from a native NENA informant',\n",
       "  'paragraph': 'paragraph segment based on newlines',\n",
       "  'line': 'verse-like section used for reference; corresponds with publications where applicable',\n",
       "  'sentence': 'sentence based on one or more of the following punctuators [.!?]',\n",
       "  'subsentence': 'part of sentence based on one of the following punctuators: [;,—:]',\n",
       "  'inton': 'intonation group of words/letters based on ˈ symbol (superscript |), which marks such boundaries',\n",
       "  'stress': \"stress group of words, marked either by hyphenated segments or standalone words; e.g. 'xa-ga' is 2 words, 1 stress group\",\n",
       "  'word': 'word in NENA or other language segmented by either whitespace or one of [-=]',\n",
       "  'letter': 'an individual letter including diacritics recognized by pattern matches against canonical NENA alphabet'},\n",
       " 'object_features': {'dialect': {'about': 'name of a dialect in North Eastern Neo-Aramaic',\n",
       "   'value': 'categorical'},\n",
       "  'title': {'about': 'title of a text (story)', 'value': 'string'},\n",
       "  'place': {'about': 'place a text was recorded', 'value': 'categorical'},\n",
       "  'text_id': {'about': 'id of a text within its original publication; can overlap between publications',\n",
       "   'value': 'string'},\n",
       "  'speakers': {'about': 'names of speakers found in a text',\n",
       "   'value': 'string'},\n",
       "  'line_number': {'about': 'sequential number of a line for reference purposes; corresponds with publications where applicable',\n",
       "   'value': 'integer'},\n",
       "  'text': {'about': 'utf8 text representation of a letter or word',\n",
       "   'value': 'text'},\n",
       "  'text_nostress': {'about': 'utf8 text without stress markers',\n",
       "   'value': 'text'},\n",
       "  'full': {'about': 'full transcription, one-to-one transcription of a letter or word',\n",
       "   'value': 'text'},\n",
       "  'lite': {'about': 'lite transcription of a letter or word, without vowel accents',\n",
       "   'value': 'text'},\n",
       "  'fuzzy': {'about': 'fuzzy transcription that leaves out most diacritics and maps certain characters in certain dialects to common characters',\n",
       "   'value': 'text'},\n",
       "  'text_end': {'about': 'space, punctuation, or other stylistic text at the end a letter or word',\n",
       "   'value': 'text'},\n",
       "  'full_end': {'about': 'full transcription of punctuation or other stylistic text at the end of a letter or word; see also trans_f',\n",
       "   'value': 'text'},\n",
       "  'lite_end': {'about': 'lite transcription of punctuation or other stylistic text at the end of a letter or word, excluding intonation boundary markers; see also trans_l',\n",
       "   'value': 'text'},\n",
       "  'fuzzy_end': {'about': 'fuzzy transcription of punctuation or other stylistic text at the end of a letter or word, excluding intonation boundary markers; see also trans_l',\n",
       "   'value': 'text'},\n",
       "  'speaker': {'about': 'name of person speaking a given word',\n",
       "   'value': 'string'},\n",
       "  'lang': {'about': 'language of a foreign word', 'value': 'categorical'},\n",
       "  'phonetic_class': {'about': 'class of a letter (consonant or vowel)',\n",
       "   'value': 'categorical'},\n",
       "  'phonetic_place': {'about': 'place of articulation of a given letter',\n",
       "   'value': 'categorical'},\n",
       "  'phonetic_manner': {'about': 'manner of the sound of a letter',\n",
       "   'value': 'categorical'},\n",
       "  'phonation': {'about': 'phonation of a letter', 'value': 'categorical'},\n",
       "  'lemma': {'about': 'parsed lemma form, if available', 'value': 'string'},\n",
       "  'pos': {'about': 'part of speech of lemma', 'value': 'categorical'},\n",
       "  'variable': {'about': 'variability of lemma form', 'value': 'categorical'},\n",
       "  'st': {'about': 'grammatical state of a word', 'value': 'categorical'},\n",
       "  'gn': {'about': 'grammatical gender of a word', 'value': 'categoricial'},\n",
       "  'nu': {'about': 'grammatical number of a word', 'value': 'categorical'},\n",
       "  'nu_class': {'about': \"semantic class of a word's grammatical number\",\n",
       "   'value': 'categorical'},\n",
       "  'trns': {'about': 'transitivity of a word', 'value': 'categorical'},\n",
       "  'syn': {'about': 'synonyms/antonyms of a word', 'value': 'string'},\n",
       "  'stem': {'about': 'stem of a verb', 'value': 'categorical'},\n",
       "  'tense': {'about': 'tense of a verb', 'value': 'categorical'},\n",
       "  'gloss': {'about': 'English gloss of a word lemma, if available',\n",
       "   'value': 'string'}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nena_builder.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Insert key with a value of default if key is not in the dictionary.\n",
       "\n",
       "Return the value for key if key is in the dictionary, else default.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.setdefault?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'span', 'line_number': '1'},\n",
       " {'class': 'word',\n",
       "  'string': 'xá',\n",
       "  'letters': [{'decomposed_regex': 'x(?![̀-ͯ])|X(?![̀-ͯ])',\n",
       "    'decomposed_string': 'x',\n",
       "    'phonetic_class': 'consonant',\n",
       "    'phonetic_place': 'velar',\n",
       "    'phonetic_manner': 'fricative',\n",
       "    'phonation': 'unvoiced',\n",
       "    'lite': 'x',\n",
       "    'text_nostress': 'x',\n",
       "    'full': 'x',\n",
       "    'text': 'x',\n",
       "    'fuzzy': 'x'},\n",
       "   {'decomposed_regex': 'á(?![̀-ͯ])|Á(?![̀-ͯ])',\n",
       "    'decomposed_string': 'á',\n",
       "    'phonetic_class': 'vowel',\n",
       "    'lite': '',\n",
       "    'text_nostress': '',\n",
       "    'full': '',\n",
       "    'text': '',\n",
       "    'fuzzy': ''}],\n",
       "  'beginnings': [],\n",
       "  'endings': [{'decomposed_regex': '-',\n",
       "    'decomposed_string': '-',\n",
       "    'class': 'connector',\n",
       "    'modifies': 'stress group',\n",
       "    'position': 'end',\n",
       "    'lite': '-',\n",
       "    'text_nostress': '-',\n",
       "    'full': '-',\n",
       "    'text': '-',\n",
       "    'fuzzy': '-'}],\n",
       "  'parsings': [{'pos': 'NUMR',\n",
       "    'gloss': 'one; a (§14.1.)',\n",
       "    'lex': 'xa',\n",
       "    'gn': 'F'}]},\n",
       " {'class': 'word',\n",
       "  'string': 'ga',\n",
       "  'letters': [{'decomposed_regex': 'g(?![̀-ͯ])|G(?![̀-ͯ])',\n",
       "    'decomposed_string': 'g',\n",
       "    'phonetic_class': 'consonant',\n",
       "    'phonetic_place': 'velar',\n",
       "    'phonetic_manner': 'affricative',\n",
       "    'phonation': 'voiced',\n",
       "    'lite': 'g',\n",
       "    'text_nostress': 'g',\n",
       "    'full': 'g',\n",
       "    'text': 'g',\n",
       "    'fuzzy': 'g'},\n",
       "   {'decomposed_regex': 'a(?![̀-ͯ])|A(?![̀-ͯ])',\n",
       "    'decomposed_string': 'a',\n",
       "    'phonetic_class': 'vowel',\n",
       "    'lite': 'a',\n",
       "    'text_nostress': 'a',\n",
       "    'full': 'a',\n",
       "    'text': 'a',\n",
       "    'fuzzy': 'a'}],\n",
       "  'beginnings': [],\n",
       "  'endings': [{'decomposed_regex': ' ',\n",
       "    'decomposed_string': ' ',\n",
       "    'class': 'separator',\n",
       "    'modifies': 'word',\n",
       "    'position': 'end',\n",
       "    'lite': ' ',\n",
       "    'text_nostress': ' ',\n",
       "    'full': ' ',\n",
       "    'text': ' ',\n",
       "    'fuzzy': ' '}],\n",
       "  'parsings': [{'pos': 'PART',\n",
       "    'gloss': 'almost, about to; connective particle (§15.1.1.11., §18.1.6.).',\n",
       "    'lex': 'ga'},\n",
       "   {'pos': 'NOUN',\n",
       "    'gn': 'F',\n",
       "    'gloss': 'time, instance',\n",
       "    'lang': 'K.',\n",
       "    'lex': 'ga.2',\n",
       "    'nu': 'PL'}]},\n",
       " {'class': 'word',\n",
       "  'string': 'xèta',\n",
       "  'letters': [{'decomposed_regex': 'x(?![̀-ͯ])|X(?![̀-ͯ])',\n",
       "    'decomposed_string': 'x',\n",
       "    'phonetic_class': 'consonant',\n",
       "    'phonetic_place': 'velar',\n",
       "    'phonetic_manner': 'fricative',\n",
       "    'phonation': 'unvoiced',\n",
       "    'lite': 'x',\n",
       "    'text_nostress': 'x',\n",
       "    'full': 'x',\n",
       "    'text': 'x',\n",
       "    'fuzzy': 'x'},\n",
       "   {'decomposed_regex': 'è(?![̀-ͯ])|È(?![̀-ͯ])',\n",
       "    'decomposed_string': 'è',\n",
       "    'phonetic_class': 'vowel',\n",
       "    'lite': '',\n",
       "    'text_nostress': '',\n",
       "    'full': '',\n",
       "    'text': '',\n",
       "    'fuzzy': ''},\n",
       "   {'decomposed_regex': 't(?![̀-ͯ])|T(?![̀-ͯ])',\n",
       "    'decomposed_string': 't',\n",
       "    'phonetic_class': 'consonant',\n",
       "    'phonetic_place': 'dental-alveolar',\n",
       "    'phonetic_manner': 'affricative',\n",
       "    'phonation': 'unvoiced_aspirated',\n",
       "    'lite': 't',\n",
       "    'text_nostress': 't',\n",
       "    'full': 't',\n",
       "    'text': 't',\n",
       "    'fuzzy': 't'},\n",
       "   {'decomposed_regex': 'a(?![̀-ͯ])|A(?![̀-ͯ])',\n",
       "    'decomposed_string': 'a',\n",
       "    'phonetic_class': 'vowel',\n",
       "    'lite': 'a',\n",
       "    'text_nostress': 'a',\n",
       "    'full': 'a',\n",
       "    'text': 'a',\n",
       "    'fuzzy': 'a'}],\n",
       "  'beginnings': [],\n",
       "  'endings': [{'decomposed_regex': ',',\n",
       "    'decomposed_string': ',',\n",
       "    'class': 'separator',\n",
       "    'modifies': 'subsentence',\n",
       "    'position': 'end',\n",
       "    'lite': ',',\n",
       "    'text_nostress': ',',\n",
       "    'full': ',',\n",
       "    'text': '',\n",
       "    'fuzzy': ','},\n",
       "   {'decomposed_regex': 'ˈ',\n",
       "    'decomposed_string': 'ˈ',\n",
       "    'class': 'separator',\n",
       "    'modifies': 'intonation group',\n",
       "    'position': 'end',\n",
       "    'lite': '|',\n",
       "    'text_nostress': 'ˈ',\n",
       "    'full': '|',\n",
       "    'text': '',\n",
       "    'fuzzy': ''},\n",
       "   {'decomposed_regex': ' ',\n",
       "    'decomposed_string': ' ',\n",
       "    'class': 'separator',\n",
       "    'modifies': 'word',\n",
       "    'position': 'end',\n",
       "    'lite': ' ',\n",
       "    'text_nostress': ' ',\n",
       "    'full': ' ',\n",
       "    'text': ' ',\n",
       "    'fuzzy': ' '}],\n",
       "  'parsings': []},\n",
       " {'class': 'word',\n",
       "  'string': 'mállah',\n",
       "  'letters': [{'decomposed_regex': 'm(?![̀-ͯ])|M(?![̀-ͯ])',\n",
       "    'decomposed_string': 'm',\n",
       "    'phonetic_class': 'consonant',\n",
       "    'phonetic_place': 'labial',\n",
       "    'phonetic_manner': 'nasal',\n",
       "    'phonation': 'plain',\n",
       "    'lite': 'm',\n",
       "    'text_nostress': 'm',\n",
       "    'full': 'm',\n",
       "    'text': 'm',\n",
       "    'fuzzy': 'm'},\n",
       "   {'decomposed_regex': 'á(?![̀-ͯ])|Á(?![̀-ͯ])',\n",
       "    'decomposed_string': 'á',\n",
       "    'phonetic_class': 'vowel',\n",
       "    'lite': '',\n",
       "    'text_nostress': '',\n",
       "    'full': '',\n",
       "    'text': '',\n",
       "    'fuzzy': ''},\n",
       "   {'decomposed_regex': 'l(?![̀-ͯ])|L(?![̀-ͯ])',\n",
       "    'decomposed_string': 'l',\n",
       "    'phonetic_class': 'consonant',\n",
       "    'phonetic_place': 'dental-alveolar',\n",
       "    'phonetic_manner': 'lateral',\n",
       "    'phonation': 'plain',\n",
       "    'lite': 'l',\n",
       "    'text_nostress': 'l',\n",
       "    'full': 'l',\n",
       "    'text': 'l',\n",
       "    'fuzzy': 'l'},\n",
       "   {'decomposed_regex': 'l(?![̀-ͯ])|L(?![̀-ͯ])',\n",
       "    'decomposed_string': 'l',\n",
       "    'phonetic_class': 'consonant',\n",
       "    'phonetic_place': 'dental-alveolar',\n",
       "    'phonetic_manner': 'lateral',\n",
       "    'phonation': 'plain',\n",
       "    'lite': 'l',\n",
       "    'text_nostress': 'l',\n",
       "    'full': 'l',\n",
       "    'text': 'l',\n",
       "    'fuzzy': 'l'},\n",
       "   {'decomposed_regex': 'a(?![̀-ͯ])|A(?![̀-ͯ])',\n",
       "    'decomposed_string': 'a',\n",
       "    'phonetic_class': 'vowel',\n",
       "    'lite': 'a',\n",
       "    'text_nostress': 'a',\n",
       "    'full': 'a',\n",
       "    'text': 'a',\n",
       "    'fuzzy': 'a'},\n",
       "   {'decomposed_regex': 'h(?![̀-ͯ])|H(?![̀-ͯ])',\n",
       "    'decomposed_string': 'h',\n",
       "    'phonetic_class': 'consonant',\n",
       "    'phonetic_place': 'laryngeal',\n",
       "    'phonetic_manner': 'fricative',\n",
       "    'phonation': 'unvoiced',\n",
       "    'lite': 'h',\n",
       "    'text_nostress': 'h',\n",
       "    'full': 'h',\n",
       "    'text': 'h',\n",
       "    'fuzzy': 'h'}],\n",
       "  'beginnings': [],\n",
       "  'endings': [{'decomposed_regex': ' ',\n",
       "    'decomposed_string': ' ',\n",
       "    'class': 'separator',\n",
       "    'modifies': 'word',\n",
       "    'position': 'end',\n",
       "    'lite': ' ',\n",
       "    'text_nostress': ' ',\n",
       "    'full': ' ',\n",
       "    'text': ' ',\n",
       "    'fuzzy': ' '}],\n",
       "  'parsings': []}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_nena.dialect2parsings['Barwar'][0][1][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
