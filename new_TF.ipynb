{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import pathlib\n",
    "import logging\n",
    "import unicodedata\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from tf.fabric import Fabric\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nena_corpus import html_to_text, parse_metadata\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "files_barwar = pathlib.Path.cwd().glob('texts/bar text *.html')\n",
    "files_urmi_c = pathlib.Path.cwd().glob('texts/cu *.html')\n",
    "\n",
    "# Characters to be replaced\n",
    "replace = {\n",
    "    '\\u2011': '\\u002d',  # U+2011 NON-BREAKING HYPHEN -> U+002D HYPHEN-MINUS\n",
    "    '\\u01dd': '\\u0259',  # U+01DD LATIN SMALL LETTER TURNED E -> U+0259 LATIN SMALL LETTER SCHWA\n",
    "    '\\uf1ea': '\\u003d',  # U+F1EA Deprecated SIL character -> U+003D '=' EQUALS SIGN\n",
    "    '\\u2026': '...',  # U+2026 '…' HORIZONTAL ELLIPSIS -> three dots\n",
    "    'J\\u0335': '\\u0248',  # 'J' + U+0335 COMBINING SHORT STROKE OVERLAY -> U+0248 'Ɉ' LATIN CAPITAL LETTER J WITH STROKE\n",
    "    'J\\u0336': '\\u0248',  # 'J' + U+0336 COMBINING LONG STROKE OVERLAY -> U+0248 'Ɉ' LATIN CAPITAL LETTER J WITH STROKE\n",
    "    '\\u002d\\u032d': '\\u032d\\u002d',  # Switch positions of Hyphen and Circumflex accent below\n",
    "    '\\u2011\\u032d': '\\u032d\\u002d',  # Switch positions of Non-breaking hyphen and Circumflex accent below\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing file bar text A14.html ...\n",
      "INFO:root:Processing file bar text a29.html ...\n",
      "INFO:root:Processing file bar text A49.html ...\n",
      "INFO:root:Processing file bar text a28.html ...\n",
      "INFO:root:Processing file bar text a50-A52.html ...\n",
      "INFO:root:Processing file bar text A45.html ...\n",
      "INFO:root:Processing file bar text a31-A33.html ...\n",
      "INFO:root:Processing file bar text A42-A44.html ...\n",
      "INFO:root:Processing file bar text a25.html ...\n",
      "INFO:root:Processing file bar text a30.html ...\n",
      "INFO:root:Processing file bar text a34.html ...\n",
      "INFO:root:Processing file bar text a19-A23.html ...\n",
      "INFO:root:Processing file bar text a24.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'footer'.\n",
      "DEBUG:root:Text:  7 .\n",
      "INFO:root:Processing file bar text a18.html ...\n",
      "INFO:root:Processing file bar text A37-A40.html ...\n",
      "INFO:root:Processing file bar text a1-A7.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'sdfootnote1'.\n",
      "DEBUG:root:Text:  1 The name Čuxo means ‘one who wears the woolen čuxa garment’. .\n",
      "INFO:root:Processing file bar text a36.html ...\n",
      "INFO:root:Processing file bar text a41.html ...\n",
      "INFO:root:Processing file bar text a8.html ...\n",
      "INFO:root:Processing file bar text a26.html ...\n",
      "INFO:root:Processing file bar text a48.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'footer'.\n",
      "DEBUG:root:Text:  1 .\n",
      "INFO:root:Processing file bar text a46-A47.html ...\n",
      "INFO:root:Processing file bar text a35.html ...\n",
      "INFO:root:Processing file bar text a27.html ...\n",
      "INFO:root:Processing file bar text A9-A13.html ...\n",
      "INFO:root:Processing file bar text a15-A17.html ...\n",
      "INFO:root:Processing file cu vol 4 texts.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "WARNING:root:Unfinished marker: 'R'.\n",
      "DEBUG:root:Urmi_C, A43:17\n",
      "DEBUG:root:Text: ' várdə=da mattúvvəla k̭am-bràto.| ʾáxči cálu labùlola.| +p̂urmìlux k̭a-díyyi?| lublàlun,| lublàlun,| lublàlun,| lublàlun.|'\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'sdfootnote1'.\n",
      "DEBUG:root:Text:  1 In the original recording of the story the speaker used the word camra ‘animal droppings’ here, but subsequently corrected this to calla. .\n",
      "DEBUG:root:Unhandled paragraph type: 'sdfootnote2'.\n",
      "DEBUG:root:Text:  2 Mistake for šənnə +xarayə. .\n",
      "DEBUG:root:Unhandled paragraph type: 'footer'.\n",
      "DEBUG:root:Text:  189 .\n"
     ]
    }
   ],
   "source": [
    "def iterateKey(dictionary):\n",
    "    '''\n",
    "    Auto increments a key from a dictionary.\n",
    "    '''\n",
    "    return max(dictionary.keys(), default=0)+1\n",
    "\n",
    "def combine_chars(text):\n",
    "    \"\"\"Yield letters combined with combining diacritics\"\"\"\n",
    "    \n",
    "    char = []\n",
    "    \n",
    "    for c in text:\n",
    "        if unicodedata.category(c) == 'Mn':  # 'Mn': non-spacing combining mark\n",
    "            char.append(c)\n",
    "            continue\n",
    "        \n",
    "        if char:\n",
    "            yield ''.join(char)\n",
    "        char = [c]\n",
    "        \n",
    "    yield ''.join(char)\n",
    "\n",
    "raw_node_features = collections.defaultdict(lambda:collections.defaultdict(set))\n",
    "raw_oslots = collections.defaultdict(lambda:collections.defaultdict(set))\n",
    "\n",
    "slot = 0\n",
    "\n",
    "this_sentence = 1 # for first iteration since only sentence ends are marked\n",
    "\n",
    "# units:\n",
    "#     book/publication/dialect?\n",
    "#     text\n",
    "#     paragraph\n",
    "#     line/verse\n",
    "#     sentence\n",
    "#     subsentence\n",
    "#     word\n",
    "#     morpheme\n",
    "#     char\n",
    "\n",
    "# oslots\n",
    "# node_features\n",
    "\n",
    "for dialect, files in (('Barwar', files_barwar), ('Urmi_C', files_urmi_c)):\n",
    "    \n",
    "    # TODO At this point record book/publication/dialect?\n",
    "    # E.g. SSLL_2016_Urmi_C, HOS_2008_Barwar?\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        logging.info(f'Processing file {file.name} ...')\n",
    "        \n",
    "        for p in html_to_text(file, replace=replace):\n",
    "            # metadata:\n",
    "            # - dialect\n",
    "            # - file.name\n",
    "            \n",
    "            if p.type.startswith('gp-') and str(p).strip():\n",
    "                # store metadata from headings:\n",
    "                # - text_id\n",
    "                # - title\n",
    "                # - informant\n",
    "                # - place\n",
    "                # - version (if applicable -- only Urmi_C A35)\n",
    "                if p.type.startswith('gp-sectionheading'):\n",
    "                    metadata = {}\n",
    "                for k, v in parse_metadata(p):\n",
    "                    metadata[k] = v\n",
    "            #\n",
    "            elif p.type == 'p':\n",
    "                # regular paragraphs\n",
    "                \n",
    "                # first check if we need to update metadata\n",
    "                # TODO for now we do not store informant, place, and version,\n",
    "                # since those are not always features of a text, but of a section\n",
    "                # of the text, and I do not know how to do that.\n",
    "                # QUESTION -- do we need to add a layer 'subsection'?\n",
    "                if (metadata\n",
    "                    and (not raw_node_features['text_id']\n",
    "                         or raw_node_features['text_id'][this_text] != metadata['text_id'])):\n",
    "                    this_text = iterateKey(raw_oslots['text'])\n",
    "                    raw_node_features['text_id'][this_text] = metadata['text_id']\n",
    "                    raw_node_features['title'][this_text] = metadata['title']\n",
    "                \n",
    "                # increment paragraph\n",
    "                this_paragraph = iterateKey(raw_oslots['paragraph'])\n",
    "                \n",
    "                marker_stack = []\n",
    "                word_end = True\n",
    "                \n",
    "                for text, text_style in p:\n",
    "                    # check if need to increment verse/line\n",
    "                    if text_style == 'verse_no':\n",
    "                        this_line = iterateKey(raw_oslots['line'])\n",
    "                        raw_node_features['line'][this_line] = text.strip(' ()') # TODO int()?\n",
    "                        metadata['verse_no'] = text.strip(' ()')  # TODO Remove from metadata dict?\n",
    "                        continue\n",
    "                        \n",
    "                    elif text_style == 'fn_anchor':\n",
    "                        # TODO handle footnotes in some way, discard for now\n",
    "                        continue\n",
    "                    \n",
    "                    elif text_style == 'comment':\n",
    "                        continue  # TODO handle comments\n",
    "                    \n",
    "                    elif text_style == 'marker':\n",
    "                        if marker_stack and marker_stack[-1] == text:\n",
    "                            marker_stack.pop()\n",
    "                        else:\n",
    "                            marker_stack.append(text)\n",
    "                        continue\n",
    "                    \n",
    "                    elif text_style not in ('', 'foreign'):\n",
    "                        logging.debug(f'Unhandled text_style: {repr(text_style)}, {repr(text)}')\n",
    "                        continue\n",
    "                    \n",
    "                    elif text_style == 'foreign':\n",
    "                        pass  # TODO store feature\n",
    "                    \n",
    "                    else: # text_style == '':\n",
    "                        pass\n",
    "                    \n",
    "                    if (text_style == '' and marker_stack\n",
    "                        and any(c.isalpha() for c in text)\n",
    "                        and not text.isalpha()):\n",
    "                        # In one case, there is no closing marker tag, so force closing the marker\n",
    "                        # Urmi_C A42 9: 'RzdànyəlaR' (p.154, r.28) 'zdàny' roman, 'əla' cursive\n",
    "                        # Urmi_C A43 17: 'ʾe-Rbuk̭ḗṱ' (p. 174, r.14), no closing 'R'\n",
    "                        # Urmi_C B2 16: 'Pʾafšɑ̄rī̀P' (p.250 r.17), inital 'ʾ' cursive\n",
    "                        marker = marker_stack.pop()\n",
    "                        logging.warning(f'Unfinished marker: {repr(marker)}.')\n",
    "                        logging.debug(f'{dialect}, {metadata[\"text_id\"]}:{metadata[\"verse_no\"]}')\n",
    "                        logging.debug(f'Text: {repr(text)}')\n",
    "                    \n",
    "                    # If we got this far, we have a text string,\n",
    "                    # with either text_style '' or 'foreign'.\n",
    "                    # We will iterate over them character by character.\n",
    "                    char = []\n",
    "                    for c in combine_chars(text):\n",
    "                        \n",
    "                        if word_end and c[0].isalpha():\n",
    "                            word_end = False\n",
    "                            this_word = iterateKey(raw_oslots['word'])\n",
    "                            \n",
    "                        elif not word_end and not c[0].isalpha(): # TODO and not in ('-', '=')?\n",
    "                            word_end = True\n",
    "                        \n",
    "                        # TODO check for sentence, subsentence, morpheme boundaries\n",
    "                        \n",
    "                        slot += 1\n",
    "                        raw_node_features['char'][slot] = c\n",
    "\n",
    "                        raw_oslots['text'][this_text].add(slot)\n",
    "                        raw_oslots['paragraph'][this_paragraph].add(slot)\n",
    "                        raw_oslots['line'][this_line].add(slot)\n",
    "                        if not word_end:\n",
    "                            raw_oslots['word'][this_word].add(slot)\n",
    "                \n",
    "            else:\n",
    "                logging.debug(f'Unhandled paragraph type: {repr(p.type)}.')\n",
    "                logging.debug(f'Text: {str(p)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindex Objects Above Slot Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "otype2feature = {\n",
    "    'text': {'text_id', 'title'},\n",
    "    'paragraph': {},\n",
    "    'line': {'line'},\n",
    "    'word': {}\n",
    "}\n",
    "\n",
    "node_features = collections.defaultdict(lambda:collections.defaultdict())\n",
    "\n",
    "node_features['char'] = raw_node_features['char'] # add slot features\n",
    "# node_features['trailer'] = raw_node_features['trailer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slot in node_features['char']:\n",
    "    node_features['otype'][slot] = 'char'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features = collections.defaultdict(lambda:collections.defaultdict(set)) # oslots will go here\n",
    "\n",
    "onode = max(raw_node_features['char']) # max slot, incremented +1 in loop\n",
    "\n",
    "for otype in raw_oslots.keys():\n",
    "    for oID, slots in raw_oslots[otype].items():\n",
    "        \n",
    "        # make new object node number\n",
    "        onode += 1\n",
    "        node_features['otype'][onode] = otype\n",
    "        \n",
    "        # remap node features to node number\n",
    "        for feat in otype2feature[otype]:\n",
    "            node_features[feat][onode] = raw_node_features[feat][oID]\n",
    "        edge_features['oslots'][onode] = raw_oslots[otype][oID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['char', 'otype', 'text_id', 'title', 'line'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['oslots'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.0\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "10 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "otext = {\n",
    "    'sectionTypes': 'text,paragraph,line,',\n",
    "    'sectionFeatures': 'text_id,line',\n",
    "    'fmt:text-orig-full': '{char}'\n",
    "}\n",
    "\n",
    "meta = {'':{'author': 'Geoffrey Khan, Cody Kingham, and Hannes Vlaardingerbroek'},\n",
    "        'oslots':{'edgeValues':False, 'valueType':'int'},\n",
    "        'otype':{'valueType':'str'},\n",
    "        'text':{'valueType':'str'},\n",
    "        'paragraph':{'valueType':'str'},\n",
    "        'line':{'valueType':'str'},\n",
    "        'word':{'valueType':'str'},\n",
    "        'char':{'valueType':'str'},\n",
    "        'text_id':{'valueType':'str'},\n",
    "        'title':{'valueType':'str'},\n",
    "        'otext':otext}\n",
    "\n",
    "TFs = Fabric(locations=['new_tf/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Exporting 5 node and 1 edge and 4 config features to new_tf/:\n",
      "  0.00s VALIDATING oslots feature\n",
      "  0.12s VALIDATING oslots feature\n",
      "  0.12s maxSlot=     730892\n",
      "  0.12s maxNode=     854244\n",
      "  0.15s OK: oslots is valid\n",
      "   |     1.13s T char                 to new_tf\n",
      "   |     0.00s T line                 to new_tf\n",
      "   |     0.28s T otype                to new_tf\n",
      "   |     0.00s T text_id              to new_tf\n",
      "   |     0.00s T title                to new_tf\n",
      "   |     0.59s T oslots               to new_tf\n",
      "   |     0.00s M otext                to new_tf\n",
      "   |     0.00s M paragraph            to new_tf\n",
      "   |     0.00s M text                 to new_tf\n",
      "   |     0.00s M word                 to new_tf\n",
      "  2.16s Exported 5 node features and 1 edge features and 4 config features to new_tf/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFs.save(nodeFeatures=node_features, edgeFeatures=edge_features, metaData=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.0\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "10 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.37s T otype                from new_tf\n",
      "   |     0.00s Not enough info for sections in otext, section functionality will not work\n",
      "   |     0.00s Not enough info for structure in otext, structure functionality will not work\n",
      "   |     1.95s T char                 from new_tf\n",
      "   |      |     0.12s C __levels__           from otype, oslots, otext\n",
      "   |      |     5.48s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.40s C __rank__             from otype, __order__\n",
      "   |      |     5.61s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     0.53s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     4.47s C __boundary__         from otype, oslots, __rank__\n",
      "   |     0.00s T text_id              from new_tf\n",
      "   |     0.02s T line                 from new_tf\n",
      "   |     0.00s T title                from new_tf\n",
      "    22s All features loaded/computed - for details use loadLog()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='new_tf/')\n",
    "\n",
    "N = TF.load('''\n",
    "\n",
    "text_id paragraph line word char otype title\n",
    "\n",
    "''')\n",
    "\n",
    "N.makeAvailableIn(globals())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120141 words in the corpus\n"
     ]
    }
   ],
   "source": [
    "print(len(list(F.otype.s('word'))), 'words in the corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books and their word counts: \n",
      "\n",
      "730893 TALES FROM THE 1001 NIGHTS\n",
      "\t4195 words\n",
      "730894 THE TALE OF RUSTAM (2)\n",
      "\t2254 words\n",
      "730895 THE CROW AND THE CHEESE\n",
      "\t71 words\n",
      "730896 THE TALE OF RUSTAM (1)\n",
      "\t1316 words\n",
      "730897 THE SISISAMBƏR PLANT\n",
      "\t385 words\n",
      "730898 QAṬINA RESCUES HIS NEPHEW FROM LELIΘA\n",
      "\t492 words\n",
      "730899 THE BATTLE WITH YUWANƏS THE ARMENIAN\n",
      "\t780 words\n",
      "730900 THE FOX AND THE STORK\n",
      "\t102 words\n",
      "730901 THE GIANT’S CAVE\n",
      "\t336 words\n",
      "730902 THE FOX AND THE MILLER\n",
      "\t1101 words\n",
      "730903 THE LION WITH A SWOLLEN LEG\n",
      "\t494 words\n",
      "730904 THE FOX AND THE LION\n",
      "\t124 words\n",
      "730905 SOUR GRAPES\n",
      "\t82 words\n",
      "730906 THE CAT AND THE MICE\n",
      "\t138 words\n",
      "730907 THE TALE OF FARXO AND SƏTTIYA\n",
      "\t3303 words\n",
      "730908 THE CRAFTY HIRELING\n",
      "\t1818 words\n",
      "730909 THE GIRL AND THE SEVEN BROTHERS\n",
      "\t1030 words\n",
      "730910 THE LELIΘA FROM Č̭ĀL\n",
      "\t321 words\n",
      "730911 THE BEAR AND THE FOX\n",
      "\t506 words\n",
      "730912 THE DAUGHTER OF THE KING\n",
      "\t1716 words\n",
      "730913 THE SALE OF AN OX\n",
      "\t1711 words\n",
      "730914 THE MAN WHO WANTED TO WORK\n",
      "\t1461 words\n",
      "730915 THE TALE OF PARIZADA, WARDA AND NARGIS\n",
      "\t2698 words\n",
      "730916 BABY LELIΘA\n",
      "\t1148 words\n",
      "730917 THE TALE OF NASIMO\n",
      "\t500 words\n",
      "730918 ŠOŠƏT XERE\n",
      "\t439 words\n",
      "730919 THE BROTHER OF GIANTS\n",
      "\t659 words\n",
      "730920 THE WISE DAUGHTER OF THE KING\n",
      "\t535 words\n",
      "730921 The Wise Snake\n",
      "\t1020 words\n",
      "730922 The Priest and the Mullah\n",
      "\t435 words\n",
      "730923 The Selfish Neighbour\n",
      "\t210 words\n",
      "730924 A tale of a prince and a princess\n",
      "\t2437 words\n",
      "730925 The Cooking Pot\n",
      "\t327 words\n",
      "730926 A Hundred Gold Coins\n",
      "\t483 words\n",
      "730927 A Man Called Čuxo\n",
      "\t1041 words\n",
      "730928 THE STORY WITH NO END\n",
      "\t195 words\n",
      "730929 MEASURE FOR MEASURE\n",
      "\t174 words\n",
      "730930 Gozali and Nozali\n",
      "\t5424 words\n",
      "730931 THE TALE OF MĂMO AND ZINE\n",
      "\t3510 words\n",
      "730932 THE MAN WHO CRIED WOLF\n",
      "\t250 words\n",
      "730933 THE LION KING\n",
      "\t150 words\n",
      "730934 MAN IS TREACHEROUS\n",
      "\t313 words\n",
      "730935 NANNO AND JƏNDO\n",
      "\t865 words\n",
      "730936 THE TALE OF MƏRZA PĂMƏT\n",
      "\t1473 words\n",
      "730937 THE SCORPION AND THE SNAKE\n",
      "\t298 words\n",
      "730938 I AM WORTH THE SAME AS A BLIND WOLF\n",
      "\t713 words\n",
      "730939 DƏMDƏMA\n",
      "\t849 words\n",
      "730940 THE KING WITH FORTY SONS\n",
      "\t3366 words\n",
      "730941 A TALE OF TWO KINGS\n",
      "\t703 words\n",
      "730942 The Monk And The Angel\n",
      "\t950 words\n",
      "730943 THE MONK WHO WANTED TO KNOW WHEN HE WOULD DIE\n",
      "\t487 words\n",
      "730944 THE WISE YOUNG MAN\n",
      "\t1482 words\n",
      "730945 The Bald Man and the King\n",
      "\t3219 words\n",
      "730946 Women are Stronger than Men\n",
      "\t1142 words\n",
      "730947 Axiqar\n",
      "\t3301 words\n",
      "730948 Is there a Man with No Worries?\n",
      "\t993 words\n",
      "730949 Women do Things Best\n",
      "\t1071 words\n",
      "730950 The Dead Rise and Return\n",
      "\t790 words\n",
      "730951 A Pound of Flesh\n",
      "\t915 words\n",
      "730952 The Loan of a Cooking Pot\n",
      "\t190 words\n",
      "730953 Much Ado About Nothing\n",
      "\t392 words\n",
      "730954 A Visit from Harun ar-Rashid\n",
      "\t591 words\n",
      "730955 The Cat’s Dinner\n",
      "\t129 words\n",
      "730956 Ice for Dinner\n",
      "\t108 words\n",
      "730957 Am I dead?\n",
      "\t118 words\n",
      "730958 A Thousand Dinars\n",
      "\t589 words\n",
      "730959 Kindness to a Donkey\n",
      "\t79 words\n",
      "730960 The Stupid Carpenter\n",
      "\t142 words\n",
      "730961 A Close Shave\n",
      "\t91 words\n",
      "730962 A Sweater to Pay Off a Debt\n",
      "\t97 words\n",
      "730963 No Bread Today\n",
      "\t239 words\n",
      "730964 An Orphan Duckling\n",
      "\t72 words\n",
      "730965 Mistaken Identity\n",
      "\t139 words\n",
      "730966 Trickster\n",
      "\t193 words\n",
      "730967 Problems Lighting a Fire\n",
      "\t156 words\n",
      "730968 The Angel of Death\n",
      "\t103 words\n",
      "730969 Stomach Trouble\n",
      "\t46 words\n",
      "730970 A Lost Donkey\n",
      "\t84 words\n",
      "730971 A Lost Ring\n",
      "\t47 words\n",
      "730972 The Purchase of a Donkey\n",
      "\t221 words\n",
      "730973 Lost Money\n",
      "\t62 words\n",
      "730974 The Wife’s Condition\n",
      "\t254 words\n",
      "730975 A Donkey Knows Best\n",
      "\t126 words\n",
      "730976 When Shall I Die?\n",
      "\t189 words\n",
      "730977 I Have Died\n",
      "\t129 words\n",
      "730978 The Fisherman and the Princess\n",
      "\t807 words\n",
      "730979 The Wife who Learns How to Work\n",
      "\t1198 words\n",
      "730980 A Cure for a Husband’s Madness\n",
      "\t1512 words\n",
      "730981 The Bald Child and the Monsters\n",
      "\t1259 words\n",
      "730982 The Wise Young Daughter\n",
      "\t1228 words\n",
      "730983 The Adventures of Ashur\n",
      "\t3294 words\n",
      "730984 A Dragon in the Well\n",
      "\t666 words\n",
      "730985 A Painting of the King Of Iran\n",
      "\t947 words\n",
      "730986 The Adventures of Two Brothers\n",
      "\t2541 words\n",
      "730987 The Adventures of a Princess\n",
      "\t2209 words\n",
      "730988 Two Wicked Daughters-in-law\n",
      "\t788 words\n",
      "730989 A Dutiful Son\n",
      "\t1204 words\n",
      "730990 The Little Prince and the Snake\n",
      "\t284 words\n",
      "730991 The Snake’s Dilemma\n",
      "\t1347 words\n",
      "730992 The Wise Brother\n",
      "\t1991 words\n",
      "730993 The Man who Wanted to Complain to God\n",
      "\t614 words\n",
      "730994 The Giant One-Eyed Demon\n",
      "\t495 words\n",
      "730995 The Cow and The Poor Girl\n",
      "\t671 words\n",
      "730996 A Frog Wants a Husband\n",
      "\t554 words\n",
      "730997 The Bird and the Fox\n",
      "\t259 words\n",
      "730998 The Old Man and the Fish\n",
      "\t630 words\n",
      "730999 Two Birds Fall in Love\n",
      "\t485 words\n",
      "731000 Star-Crossed Lovers\n",
      "\t353 words\n",
      "731001 The Assyrians of Urmi\n",
      "\t2769 words\n",
      "731002 Village Life\n",
      "\t1372 words\n",
      "731003 Agriculture and Village Life\n",
      "\t2487 words\n",
      "731004 Hunting\n",
      "\t1139 words\n",
      "731005 Weddings and Festivals\n",
      "\t880 words\n",
      "731006 Events in 1946 on the Urmi Plain\n",
      "\t639 words\n",
      "731007 Village Life\n",
      "\t1614 words\n",
      "731008 Weddings\n",
      "\t534 words\n",
      "731009 Games\n",
      "\t1010 words\n",
      "731010 Village Life\n",
      "\t2226 words\n",
      "731011 St. Zayya’s Cake Dough\n",
      "\t720 words\n",
      "731012 Nipuxta\n",
      "\t507 words\n",
      "731013 Vineyards\n",
      "\t199 words\n",
      "731014 Village Life\n",
      "\t812 words\n",
      "731015 Village Life\n",
      "\t684 words\n",
      "731016 The Assyrians of Armenia\n",
      "\t786 words\n",
      "731017 Village Life\n",
      "\t3540 words\n"
     ]
    }
   ],
   "source": [
    "print('books and their word counts: \\n')\n",
    "for text in F.otype.s('text'):\n",
    "    text_words = L.d(text, 'word')\n",
    "    print(text, F.title.v(text))\n",
    "    print(f'\\t{len(text_words)} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = F.otype.s('text').start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4195"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(L.d(text, 'word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TALES FROM THE 1001 NIGHTS\n",
      "731561 xa-màlka| kút-yum ðà-brata gawə́rwa.| mbádla qayə́mwa qaṭə̀lwala.| wăzī̀r| xðírre xðìrre,| bnáθa prìqla.| kút-yum ðà,| lìθ.| ʾáwwa wăzī́r ʾíθwale ða-bràta.| ʾa-bráta mə́ra ṭla-wằzir,| ṭla-bába dìya,| mə́ra bábi ʾána nàbəlli| gawrànne ʾáwwa málka| mparqànnux m-áyya qə́ṣṣət.|\n",
      "731562 qìmtɛla| ʾítwala ða-qàṭu,| nubàltəlla mə́nna díya.| nubáltəlla qáṭu mə́nna dìya,| gwìrtəlle málka.| ʾaw-dmìxɛle,| píštɛla mtanóye ða-qə̀ṣṣət| ṭla-qàṭu.|\n",
      "731563 mə́ra ṭla-d-à-qaṭu| mə̀ra| qáṭu lɛ́le rìxɛle| mtányən ða-qə̀ṣṣət.| ʾɛ́-dana mbádla qáyəm málka qaṭə̀lli.| sab-kəmà-ṱ-ile gwára,| ʾaṣə́rta gawə̀rra| mbádla qaṭə̀lla.| yăðána mbádla qaṭə́lli ʾaw-màlka.|  \n",
      "731564 mə́ra ʾíθwa lìθwa,| biš-m-álaha góṛa čú-məndi lìθwa.| — ʾáyya tuníθa ṭla-qàṭu —| mára ʾíθwa xá bàxta,| ʾìtwala| xa-bróna šə́mme díye Kărī̀m-addīn.| mára ʾàwwa,| ʾó Kărī̀m,| bábe mìtle.| bábe díye mìtle,| ʾáyya bàxta| kùt-yum| goyàwa,| maxláwa ṭla-bróna dìya.|\n",
      "731565 qímla mšodə́rra brōn-díya mədràsa.| bróna díya gu-mədrása kút-yum y-awéwa mxáya l-aw-yàla,| šqála čánta d-àwwa,| sràṭa məndiyáne.| mšodə́rra bàr| yə́mme dìye,| mə́ra mùrre| ʾáwwa brònəx| màləple| là-ʾawəð hátxa.|\n",
      "731566 ʾən-ʾáwəð hàtxa,| lɛ̀la spáy,| ṭarðə́xle m-mədràsa.| hóle masqóðe yálət mədràsa.| kízla bróni lá-wuð hátxa mə̀ndi.| qɛ́mi ṭarðìle m-mədrása.|  \n",
      "731567 píšle gu-măḥàlle.| gu-măḥàll-ži| kút-yum gánu kθɛ́θa d-àwwa,| ʾɛ́-ga y-azə́lwa féka d-ăwàha.| y-áwəðwa xràwe gu-măḥálle.| qəm-maqə̀dla măḥálle,| ma-t-wéwa šumàna.|\n",
      "731568 mára ʾo-yála yatùmɛle.| de-maxə̀xle?| bába lìtle.| mò-ʾoðəx bíye díye?| ʾíθwa xa-honàna-wewa.| qəm-qarèle,| mə́re Kărī̀m!| mə́re mò?| Kărīm-addīn mə́re mòdi?|\n",
      "731569 mə́re zonə́xxux xa-xmàra.| ṱ-áθət mə̀nnən| kút-yum l-ṭùra| ṱ-óðəx qɛ̀se| mzàbənna ṭla-yə́mmux.| kút-yum xá-ṭena qɛ́sa xăyítu bìye.| mə́re qà-mo lá?| mə́re ʾáyya b-álaha xòš-məndila.|\n",
      "731570 qímela nášət maḥàlle| júmyela zùze.| zwínela xa-xmàra.| mtúrṣəlle qurṭàna| xaṣə-xmàra.| yíwəlle xa-nằra.| nablìwale,| kút-yum y-asə́qwa mənnáy l-ṭùra.| masqíwale l-ṭùra,| y-áwəð xà-ṭena,| trè-ṭene qɛ́se,| y-áθe mzabə́nwa ṭla-d-àw-u yə́mme díye.| y-axlíwa lə́xma bə̀d-an qɛ́se.|  \n"
     ]
    }
   ],
   "source": [
    "print(F.title.v(text))\n",
    "\n",
    "for sent in F.otype.s('line')[:10]:\n",
    "    print(sent, T.text(sent))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
