{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import pathlib\n",
    "import logging\n",
    "import unicodedata\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from tf.fabric import Fabric\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nena_corpus import html_to_text, parse_metadata\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "files_barwar = pathlib.Path.cwd().glob('texts/bar text *.html')\n",
    "files_urmi_c = pathlib.Path.cwd().glob('texts/cu *.html')\n",
    "\n",
    "# Characters to be replaced\n",
    "replace = {\n",
    "    '\\u2011': '\\u002d',  # U+2011 NON-BREAKING HYPHEN -> U+002D HYPHEN-MINUS\n",
    "    '\\u01dd': '\\u0259',  # U+01DD LATIN SMALL LETTER TURNED E -> U+0259 LATIN SMALL LETTER SCHWA\n",
    "    '\\uf1ea': '\\u003d',  # U+F1EA Deprecated SIL character -> U+003D '=' EQUALS SIGN\n",
    "    '\\u2026': '...',  # U+2026 '…' HORIZONTAL ELLIPSIS -> three dots\n",
    "    'J\\u0335': '\\u0248',  # 'J' + U+0335 COMBINING SHORT STROKE OVERLAY -> U+0248 'Ɉ' LATIN CAPITAL LETTER J WITH STROKE\n",
    "    'J\\u0336': '\\u0248',  # 'J' + U+0336 COMBINING LONG STROKE OVERLAY -> U+0248 'Ɉ' LATIN CAPITAL LETTER J WITH STROKE\n",
    "    '\\u002d\\u032d': '\\u032d\\u002d',  # Switch positions of Hyphen and Circumflex accent below\n",
    "    '\\u2011\\u032d': '\\u032d\\u002d',  # Switch positions of Non-breaking hyphen and Circumflex accent below\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing file bar text A14.html ...\n",
      "INFO:root:Processing file bar text a29.html ...\n",
      "INFO:root:Processing file bar text A49.html ...\n",
      "INFO:root:Processing file bar text a28.html ...\n",
      "INFO:root:Processing file bar text a50-A52.html ...\n",
      "INFO:root:Processing file bar text A45.html ...\n",
      "INFO:root:Processing file bar text a31-A33.html ...\n",
      "INFO:root:Processing file bar text A42-A44.html ...\n",
      "INFO:root:Processing file bar text a25.html ...\n",
      "INFO:root:Processing file bar text a30.html ...\n",
      "INFO:root:Processing file bar text a34.html ...\n",
      "INFO:root:Processing file bar text a19-A23.html ...\n",
      "INFO:root:Processing file bar text a24.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'footer'.\n",
      "DEBUG:root:Text:  7 .\n",
      "INFO:root:Processing file bar text a18.html ...\n",
      "INFO:root:Processing file bar text A37-A40.html ...\n",
      "INFO:root:Processing file bar text a1-A7.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'sdfootnote1'.\n",
      "DEBUG:root:Text:  1 The name Čuxo means ‘one who wears the woolen čuxa garment’. .\n",
      "INFO:root:Processing file bar text a36.html ...\n",
      "INFO:root:Processing file bar text a41.html ...\n",
      "INFO:root:Processing file bar text a8.html ...\n",
      "INFO:root:Processing file bar text a26.html ...\n",
      "INFO:root:Processing file bar text a48.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'footer'.\n",
      "DEBUG:root:Text:  1 .\n",
      "INFO:root:Processing file bar text a46-A47.html ...\n",
      "INFO:root:Processing file bar text a35.html ...\n",
      "INFO:root:Processing file bar text a27.html ...\n",
      "INFO:root:Processing file bar text A9-A13.html ...\n",
      "INFO:root:Processing file bar text a15-A17.html ...\n",
      "INFO:root:Processing file cu vol 4 texts.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "WARNING:root:Unfinished marker: 'R'.\n",
      "DEBUG:root:Urmi_C, A43:17\n",
      "DEBUG:root:Text: ' várdə=da mattúvvəla k̭am-bràto.| ʾáxči cálu labùlola.| +p̂urmìlux k̭a-díyyi?| lublàlun,| lublàlun,| lublàlun,| lublàlun.|'\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text:  .\n",
      "DEBUG:root:Unhandled paragraph type: 'sdfootnote1'.\n",
      "DEBUG:root:Text:  1 In the original recording of the story the speaker used the word camra ‘animal droppings’ here, but subsequently corrected this to calla. .\n",
      "DEBUG:root:Unhandled paragraph type: 'sdfootnote2'.\n",
      "DEBUG:root:Text:  2 Mistake for šənnə +xarayə. .\n",
      "DEBUG:root:Unhandled paragraph type: 'footer'.\n",
      "DEBUG:root:Text:  189 .\n"
     ]
    }
   ],
   "source": [
    "def iterateKey(dictionary):\n",
    "    '''\n",
    "    Auto increments a key from a dictionary.\n",
    "    '''\n",
    "    return max(dictionary.keys(), default=0)+1\n",
    "\n",
    "\n",
    "raw_node_features = collections.defaultdict(lambda:collections.defaultdict(set))\n",
    "raw_oslots = collections.defaultdict(lambda:collections.defaultdict(set))\n",
    "\n",
    "slot = 0\n",
    "\n",
    "this_sentence = 1 # for first iteration since only sentence ends are marked\n",
    "\n",
    "# units:\n",
    "#     book/publication/dialect?\n",
    "#     text\n",
    "#     paragraph\n",
    "#     line/verse\n",
    "#     sentence\n",
    "#     subsentence\n",
    "#     word\n",
    "#     morpheme\n",
    "#     char\n",
    "\n",
    "# oslots\n",
    "# node_features\n",
    "\n",
    "for dialect, files in (('Barwar', files_barwar), ('Urmi_C', files_urmi_c)):\n",
    "    \n",
    "    # TODO At this point record book/publication/dialect?\n",
    "    # E.g. SSLL_2016_Urmi_C, HOS_2008_Barwar?\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        logging.info(f'Processing file {file.name} ...')\n",
    "        \n",
    "        for p in html_to_text(file, replace=replace):\n",
    "            # metadata:\n",
    "            # - dialect\n",
    "            # - file.name\n",
    "            \n",
    "            if p.type.startswith('gp-') and str(p).strip():\n",
    "                # store metadata from headings:\n",
    "                # - text_id\n",
    "                # - title\n",
    "                # - informant\n",
    "                # - place\n",
    "                # - version (if applicable -- only Urmi_C A35)\n",
    "                if p.type.startswith('gp-sectionheading'):\n",
    "                    metadata = {}\n",
    "                for k, v in parse_metadata(p):\n",
    "                    metadata[k] = v\n",
    "            #\n",
    "            elif p.type == 'p':\n",
    "                # regular paragraphs\n",
    "                \n",
    "                # first check if we need to update metadata\n",
    "                # TODO for now we do not store informant, place, and version,\n",
    "                # since those are not always features of a text, but of a section\n",
    "                # of the text, and I do not know how to do that.\n",
    "                # QUESTION -- do we need to add a layer 'subsection'?\n",
    "                if (metadata\n",
    "                    and (not raw_node_features['text_id']\n",
    "                         or raw_node_features['text_id'][this_text] != metadata['text_id'])):\n",
    "                    this_text = iterateKey(raw_oslots['text'])\n",
    "                    raw_node_features['text_id'][this_text] = metadata['text_id']\n",
    "                    raw_node_features['title'][this_text] = metadata['title']\n",
    "                \n",
    "                # increment paragraph\n",
    "                this_paragraph = iterateKey(raw_oslots['paragraph'])\n",
    "                \n",
    "                marker_stack = []\n",
    "                word_end = True\n",
    "                \n",
    "                for text, text_style in p:\n",
    "                    # check if need to increment verse/line\n",
    "                    if text_style == 'verse_no':\n",
    "                        this_line = iterateKey(raw_oslots['line'])\n",
    "                        raw_node_features['line'][this_line] = text.strip(' ()') # TODO int()?\n",
    "                        metadata['verse_no'] = text.strip(' ()')  # TODO Remove from metadata dict?\n",
    "                        continue\n",
    "                        \n",
    "                    elif text_style == 'fn_anchor':\n",
    "                        # TODO handle footnotes in some way, discard for now\n",
    "                        continue\n",
    "                    \n",
    "                    elif text_style == 'comment':\n",
    "                        continue  # TODO handle comments\n",
    "                    \n",
    "                    elif text_style == 'marker':\n",
    "                        if marker_stack and marker_stack[-1] == text:\n",
    "                            marker_stack.pop()\n",
    "                        else:\n",
    "                            marker_stack.append(text)\n",
    "                        continue\n",
    "                    \n",
    "                    elif text_style not in ('', 'foreign'):\n",
    "                        logging.debug(f'Unhandled text_style: {repr(text_style)}, {repr(text)}')\n",
    "                        continue\n",
    "                    \n",
    "                    elif text_style == 'foreign':\n",
    "                        pass  # TODO store feature\n",
    "                    \n",
    "                    else: # text_style == '':\n",
    "                        pass\n",
    "                    \n",
    "                    if (text_style == '' and marker_stack\n",
    "                        and any(c.isalpha() for c in text)\n",
    "                        and not text.isalpha()):\n",
    "                        # In one case, there is no closing marker tag, so force closing the marker\n",
    "                        # Urmi_C A42 9: 'RzdànyəlaR' (p.154, r.28) 'zdàny' roman, 'əla' cursive\n",
    "                        # Urmi_C A43 17: 'ʾe-Rbuk̭ḗṱ' (p. 174, r.14), no closing 'R'\n",
    "                        # Urmi_C B2 16: 'Pʾafšɑ̄rī̀P' (p.250 r.17), inital 'ʾ' cursive\n",
    "                        marker = marker_stack.pop()\n",
    "                        logging.warning(f'Unfinished marker: {repr(marker)}.')\n",
    "                        logging.debug(f'{dialect}, {metadata[\"text_id\"]}:{metadata[\"verse_no\"]}')\n",
    "                        logging.debug(f'Text: {repr(text)}')\n",
    "                    \n",
    "                    # If we got this far, we have a text string,\n",
    "                    # with either text_style '' or 'foreign'.\n",
    "                    # We will iterate over them character by character.\n",
    "                    char = []\n",
    "                    for c in text:\n",
    "                        \n",
    "                        if unicodedata.category(c) == 'Mn':\n",
    "                            # Combine combining characters (and check for loose ones)\n",
    "                            if not char:\n",
    "                                logging.warning(f'String starts with combining character ◌{c}')\n",
    "                                logging.debug(f'{dialect}, {metadata[\"text_id\"]}:{metadata[\"verse_no\"]}')\n",
    "                            char.append(c)\n",
    "                            continue\n",
    "                            \n",
    "                        elif word_end and c.isalpha():\n",
    "                            word_end = False\n",
    "                            this_word = iterateKey(raw_oslots['word'])\n",
    "                            \n",
    "                        elif not word_end and not c.isalpha(): # TODO and not in ('-', '=')?\n",
    "                            word_end = True\n",
    "                        \n",
    "                        # TODO check for sentence, subsentence, morpheme boundaries\n",
    "                            \n",
    "                        elif char:\n",
    "                            \n",
    "                            slot += 1\n",
    "                            raw_node_features['char'][slot] = ''.join(char)\n",
    "                            \n",
    "                            raw_oslots['text'][this_text].add(slot)\n",
    "                            raw_oslots['paragraph'][this_paragraph].add(slot)\n",
    "                            raw_oslots['line'][this_line].add(slot)\n",
    "                            if not word_end:\n",
    "                                raw_oslots['word'][this_word].add(slot)\n",
    "                        \n",
    "                        char = [c]\n",
    "                    \n",
    "                    if char:\n",
    "                        slot += 1\n",
    "                        raw_node_features['char'][slot] = ''.join(char)\n",
    "\n",
    "                        raw_oslots['text'][this_text].add(slot)\n",
    "                        raw_oslots['paragraph'][this_paragraph].add(slot)\n",
    "                        raw_oslots['line'][this_line].add(slot)\n",
    "                        if not word_end:\n",
    "                            raw_oslots['word'][this_word].add(slot)\n",
    "                \n",
    "            else:\n",
    "                logging.debug(f'Unhandled paragraph type: {repr(p.type)}.')\n",
    "                logging.debug(f'Text: {str(p)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindex Objects Above Slot Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "otype2feature = {\n",
    "    'text': {'text_id', 'title'},\n",
    "    'paragraph': {},\n",
    "    'line': {'line'},\n",
    "    'word': {}\n",
    "}\n",
    "\n",
    "node_features = collections.defaultdict(lambda:collections.defaultdict())\n",
    "\n",
    "node_features['char'] = raw_node_features['char'] # add slot features\n",
    "# node_features['trailer'] = raw_node_features['trailer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slot in node_features['char']:\n",
    "    node_features['otype'][slot] = 'char'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features = collections.defaultdict(lambda:collections.defaultdict(set)) # oslots will go here\n",
    "\n",
    "onode = max(raw_node_features['char']) # max slot, incremented +1 in loop\n",
    "\n",
    "for otype in raw_oslots.keys():\n",
    "    for oID, slots in raw_oslots[otype].items():\n",
    "        \n",
    "        # make new object node number\n",
    "        onode += 1\n",
    "        node_features['otype'][onode] = otype\n",
    "        \n",
    "        # remap node features to node number\n",
    "        for feat in otype2feature[otype]:\n",
    "            node_features[feat][onode] = raw_node_features[feat][oID]\n",
    "        edge_features['oslots'][onode] = raw_oslots[otype][oID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['char', 'otype', 'text_id', 'title', 'line'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['oslots'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.0\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "10 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "otext = {\n",
    "    'sectionTypes': 'text,paragraph,line,',\n",
    "    'sectionFeatures': 'text_id,line',\n",
    "#     'fmt:text-orig-full': '{trans}{trailer}'\n",
    "}\n",
    "\n",
    "meta = {'':{'author': 'Geoffrey Khan, Cody Kingham, and Hannes Vlaardingerbroek'},\n",
    "        'oslots':{'edgeValues':False, 'valueType':'int'},\n",
    "        'otype':{'valueType':'str'},\n",
    "        'text':{'valueType':'str'},\n",
    "        'paragraph':{'valueType':'str'},\n",
    "        'line':{'valueType':'str'},\n",
    "        'word':{'valueType':'str'},\n",
    "        'char':{'valueType':'str'},\n",
    "        'text_id':{'valueType':'str'},\n",
    "        'title':{'valueType':'str'},\n",
    "        'otext':otext}\n",
    "\n",
    "TFs = Fabric(locations=['new_tf/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Exporting 5 node and 1 edge and 4 config features to new_tf/:\n",
      "  0.00s VALIDATING oslots feature\n",
      "  0.09s VALIDATING oslots feature\n",
      "  0.09s maxSlot=     495165\n",
      "  0.09s maxNode=     611309\n",
      "  0.12s OK: oslots is valid\n",
      "   |     0.77s T char                 to new_tf\n",
      "   |     0.00s T line                 to new_tf\n",
      "   |     0.21s T otype                to new_tf\n",
      "   |     0.00s T text_id              to new_tf\n",
      "   |     0.00s T title                to new_tf\n",
      "   |     0.48s T oslots               to new_tf\n",
      "   |     0.00s M otext                to new_tf\n",
      "   |     0.00s M paragraph            to new_tf\n",
      "   |     0.00s M text                 to new_tf\n",
      "   |     0.00s M word                 to new_tf\n",
      "  1.60s Exported 5 node features and 1 edge features and 4 config features to new_tf/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFs.save(nodeFeatures=node_features, edgeFeatures=edge_features, metaData=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.0\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "10 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.22s T otype                from new_tf\n",
      "   |     0.00s Not enough info for sections in otext, section functionality will not work\n",
      "   |     0.00s Not enough info for structure in otext, structure functionality will not work\n",
      "   |      |     0.11s C __levels__           from otype, oslots, otext\n",
      "   |      |     3.69s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.27s C __rank__             from otype, __order__\n",
      "   |      |     4.32s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     0.49s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     3.03s C __boundary__         from otype, oslots, __rank__\n",
      "   |     0.00s T text_id              from new_tf\n",
      "   |     0.01s T line                 from new_tf\n",
      "   |     1.29s T char                 from new_tf\n",
      "   |     0.00s T title                from new_tf\n",
      "    15s All features loaded/computed - for details use loadLog()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='new_tf/')\n",
    "\n",
    "N = TF.load('''\n",
    "\n",
    "text_id paragraph line word char otype title\n",
    "\n",
    "''')\n",
    "\n",
    "N.makeAvailableIn(globals())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112933 words in the corpus\n"
     ]
    }
   ],
   "source": [
    "print(len(list(F.otype.s('word'))), 'words in the corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books and their word counts: \n",
      "\n",
      "495166 TALES FROM THE 1001 NIGHTS\n",
      "\t3790 words\n",
      "495167 THE TALE OF RUSTAM (2)\n",
      "\t2038 words\n",
      "495168 THE CROW AND THE CHEESE\n",
      "\t65 words\n",
      "495169 THE TALE OF RUSTAM (1)\n",
      "\t1190 words\n",
      "495170 THE SISISAMBƏR PLANT\n",
      "\t361 words\n",
      "495171 QAṬINA RESCUES HIS NEPHEW FROM LELIΘA\n",
      "\t433 words\n",
      "495172 THE BATTLE WITH YUWANƏS THE ARMENIAN\n",
      "\t728 words\n",
      "495173 THE FOX AND THE STORK\n",
      "\t99 words\n",
      "495174 THE GIANT’S CAVE\n",
      "\t317 words\n",
      "495175 THE FOX AND THE MILLER\n",
      "\t1007 words\n",
      "495176 THE LION WITH A SWOLLEN LEG\n",
      "\t464 words\n",
      "495177 THE FOX AND THE LION\n",
      "\t114 words\n",
      "495178 SOUR GRAPES\n",
      "\t76 words\n",
      "495179 THE CAT AND THE MICE\n",
      "\t120 words\n",
      "495180 THE TALE OF FARXO AND SƏTTIYA\n",
      "\t3034 words\n",
      "495181 THE CRAFTY HIRELING\n",
      "\t1625 words\n",
      "495182 THE GIRL AND THE SEVEN BROTHERS\n",
      "\t935 words\n",
      "495183 THE LELIΘA FROM Č̭ĀL\n",
      "\t299 words\n",
      "495184 THE BEAR AND THE FOX\n",
      "\t462 words\n",
      "495185 THE DAUGHTER OF THE KING\n",
      "\t1547 words\n",
      "495186 THE SALE OF AN OX\n",
      "\t1571 words\n",
      "495187 THE MAN WHO WANTED TO WORK\n",
      "\t1343 words\n",
      "495188 THE TALE OF PARIZADA, WARDA AND NARGIS\n",
      "\t2473 words\n",
      "495189 BABY LELIΘA\n",
      "\t1075 words\n",
      "495190 THE TALE OF NASIMO\n",
      "\t486 words\n",
      "495191 ŠOŠƏT XERE\n",
      "\t424 words\n",
      "495192 THE BROTHER OF GIANTS\n",
      "\t605 words\n",
      "495193 THE WISE DAUGHTER OF THE KING\n",
      "\t483 words\n",
      "495194 The Wise Snake\n",
      "\t934 words\n",
      "495195 The Priest and the Mullah\n",
      "\t404 words\n",
      "495196 The Selfish Neighbour\n",
      "\t188 words\n",
      "495197 A tale of a prince and a princess\n",
      "\t2187 words\n",
      "495198 The Cooking Pot\n",
      "\t312 words\n",
      "495199 A Hundred Gold Coins\n",
      "\t427 words\n",
      "495200 A Man Called Čuxo\n",
      "\t960 words\n",
      "495201 THE STORY WITH NO END\n",
      "\t172 words\n",
      "495202 MEASURE FOR MEASURE\n",
      "\t156 words\n",
      "495203 Gozali and Nozali\n",
      "\t4862 words\n",
      "495204 THE TALE OF MĂMO AND ZINE\n",
      "\t3224 words\n",
      "495205 THE MAN WHO CRIED WOLF\n",
      "\t234 words\n",
      "495206 THE LION KING\n",
      "\t139 words\n",
      "495207 MAN IS TREACHEROUS\n",
      "\t290 words\n",
      "495208 NANNO AND JƏNDO\n",
      "\t795 words\n",
      "495209 THE TALE OF MƏRZA PĂMƏT\n",
      "\t1344 words\n",
      "495210 THE SCORPION AND THE SNAKE\n",
      "\t263 words\n",
      "495211 I AM WORTH THE SAME AS A BLIND WOLF\n",
      "\t637 words\n",
      "495212 DƏMDƏMA\n",
      "\t768 words\n",
      "495213 THE KING WITH FORTY SONS\n",
      "\t3064 words\n",
      "495214 A TALE OF TWO KINGS\n",
      "\t640 words\n",
      "495215 The Monk And The Angel\n",
      "\t866 words\n",
      "495216 THE MONK WHO WANTED TO KNOW WHEN HE WOULD DIE\n",
      "\t439 words\n",
      "495217 THE WISE YOUNG MAN\n",
      "\t1356 words\n",
      "495218 The Bald Man and the King\n",
      "\t3164 words\n",
      "495219 Women are Stronger than Men\n",
      "\t1118 words\n",
      "495220 Axiqar\n",
      "\t3248 words\n",
      "495221 Is there a Man with No Worries?\n",
      "\t961 words\n",
      "495222 Women do Things Best\n",
      "\t1028 words\n",
      "495223 The Dead Rise and Return\n",
      "\t770 words\n",
      "495224 A Pound of Flesh\n",
      "\t893 words\n",
      "495225 The Loan of a Cooking Pot\n",
      "\t186 words\n",
      "495226 Much Ado About Nothing\n",
      "\t390 words\n",
      "495227 A Visit from Harun ar-Rashid\n",
      "\t574 words\n",
      "495228 The Cat’s Dinner\n",
      "\t128 words\n",
      "495229 Ice for Dinner\n",
      "\t106 words\n",
      "495230 Am I dead?\n",
      "\t112 words\n",
      "495231 A Thousand Dinars\n",
      "\t579 words\n",
      "495232 Kindness to a Donkey\n",
      "\t79 words\n",
      "495233 The Stupid Carpenter\n",
      "\t139 words\n",
      "495234 A Close Shave\n",
      "\t85 words\n",
      "495235 A Sweater to Pay Off a Debt\n",
      "\t95 words\n",
      "495236 No Bread Today\n",
      "\t233 words\n",
      "495237 An Orphan Duckling\n",
      "\t71 words\n",
      "495238 Mistaken Identity\n",
      "\t137 words\n",
      "495239 Trickster\n",
      "\t188 words\n",
      "495240 Problems Lighting a Fire\n",
      "\t151 words\n",
      "495241 The Angel of Death\n",
      "\t103 words\n",
      "495242 Stomach Trouble\n",
      "\t46 words\n",
      "495243 A Lost Donkey\n",
      "\t82 words\n",
      "495244 A Lost Ring\n",
      "\t47 words\n",
      "495245 The Purchase of a Donkey\n",
      "\t218 words\n",
      "495246 Lost Money\n",
      "\t60 words\n",
      "495247 The Wife’s Condition\n",
      "\t249 words\n",
      "495248 A Donkey Knows Best\n",
      "\t121 words\n",
      "495249 When Shall I Die?\n",
      "\t185 words\n",
      "495250 I Have Died\n",
      "\t127 words\n",
      "495251 The Fisherman and the Princess\n",
      "\t794 words\n",
      "495252 The Wife who Learns How to Work\n",
      "\t1168 words\n",
      "495253 A Cure for a Husband’s Madness\n",
      "\t1478 words\n",
      "495254 The Bald Child and the Monsters\n",
      "\t1219 words\n",
      "495255 The Wise Young Daughter\n",
      "\t1192 words\n",
      "495256 The Adventures of Ashur\n",
      "\t3173 words\n",
      "495257 A Dragon in the Well\n",
      "\t654 words\n",
      "495258 A Painting of the King Of Iran\n",
      "\t930 words\n",
      "495259 The Adventures of Two Brothers\n",
      "\t2477 words\n",
      "495260 The Adventures of a Princess\n",
      "\t2145 words\n",
      "495261 Two Wicked Daughters-in-law\n",
      "\t763 words\n",
      "495262 A Dutiful Son\n",
      "\t1181 words\n",
      "495263 The Little Prince and the Snake\n",
      "\t279 words\n",
      "495264 The Snake’s Dilemma\n",
      "\t1290 words\n",
      "495265 The Wise Brother\n",
      "\t1929 words\n",
      "495266 The Man who Wanted to Complain to God\n",
      "\t593 words\n",
      "495267 The Giant One-Eyed Demon\n",
      "\t470 words\n",
      "495268 The Cow and The Poor Girl\n",
      "\t639 words\n",
      "495269 A Frog Wants a Husband\n",
      "\t535 words\n",
      "495270 The Bird and the Fox\n",
      "\t253 words\n",
      "495271 The Old Man and the Fish\n",
      "\t608 words\n",
      "495272 Two Birds Fall in Love\n",
      "\t454 words\n",
      "495273 Star-Crossed Lovers\n",
      "\t333 words\n",
      "495274 The Assyrians of Urmi\n",
      "\t2683 words\n",
      "495275 Village Life\n",
      "\t1316 words\n",
      "495276 Agriculture and Village Life\n",
      "\t2331 words\n",
      "495277 Hunting\n",
      "\t1065 words\n",
      "495278 Weddings and Festivals\n",
      "\t820 words\n",
      "495279 Events in 1946 on the Urmi Plain\n",
      "\t624 words\n",
      "495280 Village Life\n",
      "\t1545 words\n",
      "495281 Weddings\n",
      "\t520 words\n",
      "495282 Games\n",
      "\t955 words\n",
      "495283 Village Life\n",
      "\t2132 words\n",
      "495284 St. Zayya’s Cake Dough\n",
      "\t680 words\n",
      "495285 Nipuxta\n",
      "\t471 words\n",
      "495286 Vineyards\n",
      "\t192 words\n",
      "495287 Village Life\n",
      "\t760 words\n",
      "495288 Village Life\n",
      "\t658 words\n",
      "495289 The Assyrians of Armenia\n",
      "\t774 words\n",
      "495290 Village Life\n",
      "\t3352 words\n"
     ]
    }
   ],
   "source": [
    "print('books and their word counts: \\n')\n",
    "for text in F.otype.s('text'):\n",
    "    text_words = L.d(text, 'word')\n",
    "    print(text, F.title.v(text))\n",
    "    print(f'\\t{len(text_words)} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = F.otype.s('text').start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3790"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(L.d(text, 'word'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
